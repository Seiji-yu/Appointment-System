{"version":3,"sources":["../src/otel/utils/redaction.ts","../src/otel/withSpanBaggageKey.ts","../src/otel/initAxiomAI.ts","../package.json","../src/otel/withSpan.ts","../src/otel/utils/wrapperUtils.ts","../src/otel/semconv/attributes.ts","../src/otel/semconv/eval_proposal.ts","../src/otel/startActiveSpan.ts","../src/otel/middleware.ts","../src/otel/utils/contentSanitizer.ts","../src/otel/completionUtils.ts","../src/util/promptUtils.ts","../src/otel/utils/normalized.ts","../src/util/currentUnixTime.ts","../src/otel/streaming/aggregators.ts","../src/otel/AxiomWrappedLanguageModelV1.ts","../src/otel/AxiomWrappedLanguageModelV2.ts","../src/otel/vercel.ts"],"sourcesContent":["import { context, propagation, type Baggage, type Span } from '@opentelemetry/api';\nimport { WITHSPAN_REDACTION_POLICY_KEY } from '../withSpanBaggageKey';\n\ntype CaptureMessageContent = 'full' | 'off';\n\nexport type AxiomAIRedactionPolicy = {\n  captureMessageContent?: CaptureMessageContent;\n  mirrorToolPayloadOnToolSpan?: boolean;\n};\n\nexport const RedactionPolicy = {\n  /**\n   * Includes message content on chat spans, and mirrors tool\n   * payload on tool spans for more convenient querying.\n   */\n  AxiomDefault: {\n    captureMessageContent: 'full',\n    mirrorToolPayloadOnToolSpan: true,\n  },\n  /**\n   * Redacts message content on chat spans, and does not put\n   * tool payload on tool spans.\n   */\n  OpenTelemetryDefault: {\n    captureMessageContent: 'off',\n    mirrorToolPayloadOnToolSpan: false,\n  },\n} as const satisfies Record<string, AxiomAIRedactionPolicy>;\n\n// Global key to store redaction policy across all execution contexts\nexport const AXIOM_AI_REDACTION_KEY = Symbol.for('__axiom_ai_redaction__');\n\n/**\n * Get the globally stored redaction policy\n * @returns The global redaction policy or undefined if not set\n */\nfunction getGlobalRedactionPolicy(): AxiomAIRedactionPolicy | undefined {\n  return (globalThis as any)[AXIOM_AI_REDACTION_KEY];\n}\n\n/**\n * Resolves the effective redaction policy by merging global and per-call policies.\n * Per-call policies take precedence over global policies.\n *\n * @param globalPolicy - The global redaction policy from initAxiomAI\n * @param localPolicy - The per-call redaction policy from withSpan or middleware\n * @returns The effective redaction policy with all fields resolved\n */\nfunction getEffectiveRedactionPolicy(\n  globalPolicy?: AxiomAIRedactionPolicy,\n  localPolicy?: AxiomAIRedactionPolicy,\n): AxiomAIRedactionPolicy {\n  // Per-call policy overrides global policy, with defaults\n  return {\n    captureMessageContent:\n      localPolicy?.captureMessageContent ??\n      globalPolicy?.captureMessageContent ??\n      RedactionPolicy.AxiomDefault.captureMessageContent,\n    mirrorToolPayloadOnToolSpan:\n      localPolicy?.mirrorToolPayloadOnToolSpan ??\n      globalPolicy?.mirrorToolPayloadOnToolSpan ??\n      RedactionPolicy.AxiomDefault.mirrorToolPayloadOnToolSpan,\n  };\n}\n\n/**\n * Get the active redaction policy\n */\nexport function getRedactionPolicy() {\n  return getEffectiveRedactionPolicy(getGlobalRedactionPolicy(), getPerCallRedactionPolicy());\n}\n\n/**\n * Conditionally sets a span attribute based on the capture message content policy.\n * When policy is 'off', the attribute is not set at all.\n *\n * @param span - The OpenTelemetry span to set the attribute on\n * @param attribute - The attribute name/key\n * @param value - The attribute value\n * @param captureMessageContent - The capture policy ('full' sets attribute, 'off' skips it)\n */\nexport function handleMaybeRedactedAttribute(\n  span: Span,\n  attribute: string,\n  value: any,\n  captureMessageContent?: CaptureMessageContent,\n): void {\n  if (captureMessageContent === 'full') {\n    span.setAttribute(attribute, value);\n  }\n\n  // For 'off', don't set the attribute at all\n  // Future: Could add callback-based redaction here\n}\n\n/**\n * Extracts the per-call redaction policy from OpenTelemetry baggage context.\n * This allows middleware and tools to access redaction policies passed via withSpan.\n *\n * @returns The per-call redaction policy or undefined if not set\n */\nfunction getPerCallRedactionPolicy(): AxiomAIRedactionPolicy | undefined {\n  const baggage: Baggage = propagation.getBaggage(context.active()) || propagation.createBaggage();\n  const serializedPolicy = baggage.getEntry(WITHSPAN_REDACTION_POLICY_KEY)?.value;\n\n  if (!serializedPolicy) {\n    return undefined;\n  }\n\n  try {\n    return JSON.parse(serializedPolicy) as AxiomAIRedactionPolicy;\n  } catch (error) {\n    console.warn('[AxiomAI] Failed to parse redaction policy from baggage:', error);\n    return undefined;\n  }\n}\n","/**\n * We need a way to know that we're inside `withSpan`\n * Because we don't own `generateText` and similar functions,\n * we use OTel Baggage to propagate this information. Another\n * consideration might be to use AsyncLocalStorage in Node and\n * some kind of KV in workerd.\n */\nexport const WITHSPAN_BAGGAGE_KEY = '__withspan_gen_ai_call';\nexport const WITHSPAN_REDACTION_POLICY_KEY = '__withspan_redaction_policy';\n","import type { Tracer } from '@opentelemetry/api';\nimport { trace } from '@opentelemetry/api';\nimport packageJson from '../../package.json';\nimport { AXIOM_AI_REDACTION_KEY, type AxiomAIRedactionPolicy } from './utils/redaction';\n\n// Global key to store tracer scope information across all execution contexts\nconst AXIOM_AI_SCOPE_KEY = Symbol.for('__axiom_ai_scope__');\n\ninterface TracerScope {\n  name: string;\n  version?: string;\n}\n\n/**\n * Extract scope information from a tracer, with fallback to package.json\n */\nfunction extractTracerScope(tracer: Tracer): TracerScope {\n  const tracerAny = tracer as any;\n\n  // Guard access to private fields with optional chaining\n  // Note: These are internal OTEL fields that may change in future versions\n  // _instrumentationScope is modern, instrumentationLibrary is legacy (<1.16)\n  const name =\n    tracerAny._instrumentationScope?.name ||\n    tracerAny.instrumentationLibrary?.name ||\n    packageJson.name;\n\n  const version =\n    tracerAny._instrumentationScope?.version ||\n    tracerAny.instrumentationLibrary?.version ||\n    packageJson.version;\n\n  return { name, version };\n}\n\n/**\n * Register this in your `instrumentation.ts` to set up axiom.\n * This function stores the tracer's scope information globally to enable Context Propagation\n * and Instrumentation Scope. The tracer will be available across all execution contexts including Next.js.\n *\n * This function is idempotent - calling it multiple times with the same scope has no additional cost.\n *\n * @param config\n * @param config.tracer - The tracer that you are using in your application.\n * @param config.redactionPolicy - Optional redaction policy to control what data is captured in spans.\n */\nexport function initAxiomAI(config: { tracer: Tracer; redactionPolicy?: AxiomAIRedactionPolicy }) {\n  const newScope = extractTracerScope(config.tracer);\n  const existingScope = (globalThis as any)[AXIOM_AI_SCOPE_KEY] as TracerScope | undefined;\n\n  // Check if already initialized with same scope (idempotent behavior)\n  if (\n    existingScope &&\n    existingScope.name === newScope.name &&\n    existingScope.version === newScope.version\n  ) {\n    return;\n  }\n\n  // Warn about double initialization with different scopes\n  if (existingScope) {\n    console.warn(\n      '[AxiomAI] initAxiomAI() called multiple times with different scopes. ' +\n        `Previous: ${existingScope.name}@${existingScope.version}, ` +\n        `New: ${newScope.name}@${newScope.version}`,\n    );\n  }\n\n  // Store scope information globally (works across Next.js contexts)\n  (globalThis as any)[AXIOM_AI_SCOPE_KEY] = newScope;\n\n  // Store redaction policy globally if provided\n  if (config.redactionPolicy) {\n    (globalThis as any)[AXIOM_AI_REDACTION_KEY] = config.redactionPolicy;\n  }\n}\n\n/**\n * Get a tracer using the globally stored scope information\n * Fall back to package.json defaults if not set\n */\nexport function getGlobalTracer(): Tracer {\n  // Get stored scope information or fall back to package defaults\n  const scope = (globalThis as any)[AXIOM_AI_SCOPE_KEY] as TracerScope | undefined;\n\n  // Warn if initAxiomAI was never called\n  if (!scope) {\n    const DEBUG = process.env.AXIOM_DEBUG === 'true';\n    if (!DEBUG) {\n      console.warn(\n        '[AxiomAI] AXIOM_AI_SCOPE_KEY is undefined. This probably means that ' +\n          'initAxiomAI() was never called. ' +\n          'Make sure to call initAxiomAI({ tracer }) in your instrumentation setup.',\n      );\n    }\n  }\n\n  let { name, version } = scope || { name: packageJson.name, version: packageJson.version };\n\n  if (!name || !version) {\n    name = packageJson.name;\n    version = packageJson.version;\n    if (!name || !version) {\n      name = 'axiom';\n      version = 'unknown';\n    }\n  }\n\n  // Use OpenTelemetry's standard global provider mechanism\n  return trace.getTracer(name, version);\n}\n\n/**\n * Reset AxiomAI configuration (useful for testing)\n */\nexport function resetAxiomAI() {\n  (globalThis as any)[AXIOM_AI_SCOPE_KEY] = undefined;\n  (globalThis as any)[AXIOM_AI_REDACTION_KEY] = undefined;\n}\n","{\n  \"name\": \"axiom\",\n  \"version\": \"0.22.0\",\n  \"type\": \"module\",\n  \"author\": \"Axiom, Inc.\",\n  \"contributors\": [\n    \"Islam Shehata <islam@axiom.co>\",\n    \"Chris Ehrlich <chris@axiom.co>\",\n    \"Gabriel de Andrade <gabriel@axiom.co>\"\n  ],\n  \"scripts\": {\n    \"dev\": \"tsup --watch\",\n    \"build\": \"tsup && chmod +x dist/bin.js\",\n    \"format\": \"prettier --write .\",\n    \"format:check\": \"prettier --check .\",\n    \"lint\": \"eslint './**/*.{js,ts}'\",\n    \"typecheck\": \"tsc --noEmit\",\n    \"test\": \"vitest run\",\n    \"test:watch\": \"vitest --watch\",\n    \"publint\": \"npx publint\"\n  },\n  \"types\": \"./dist/index.d.ts\",\n  \"main\": \"./dist/index.cjs\",\n  \"module\": \"./dist/index.js\",\n  \"bin\": {\n    \"axiom\": \"./dist/bin.js\"\n  },\n  \"exports\": {\n    \"./ai\": {\n      \"import\": {\n        \"types\": \"./dist/index.d.ts\",\n        \"default\": \"./dist/index.js\"\n      },\n      \"require\": {\n        \"types\": \"./dist/index.d.cts\",\n        \"default\": \"./dist/index.cjs\"\n      }\n    },\n    \"./ai/evals\": {\n      \"import\": {\n        \"types\": \"./dist/evals.d.ts\",\n        \"default\": \"./dist/evals.js\"\n      },\n      \"require\": {\n        \"types\": \"./dist/evals.d.cts\",\n        \"default\": \"./dist/evals.cjs\"\n      }\n    },\n    \"./ai/config\": {\n      \"import\": {\n        \"types\": \"./dist/config.d.ts\",\n        \"default\": \"./dist/config.js\"\n      },\n      \"require\": {\n        \"types\": \"./dist/config.d.cts\",\n        \"default\": \"./dist/config.cjs\"\n      }\n    }\n  },\n  \"keywords\": [\n    \"axiom\",\n    \"logging\",\n    \"ai\",\n    \"otel\",\n    \"opentelemetry\"\n  ],\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/axiomhq/ai.git\",\n    \"directory\": \"packages/ai\"\n  },\n  \"license\": \"MIT\",\n  \"dependencies\": {\n    \"@next/env\": \"^15.4.2\",\n    \"@opentelemetry/auto-instrumentations-node\": \"^0.60.1\",\n    \"@opentelemetry/context-async-hooks\": \"^2.0.1\",\n    \"@opentelemetry/exporter-trace-otlp-http\": \"^0.202.0\",\n    \"@opentelemetry/resources\": \"^2.0.1\",\n    \"@opentelemetry/sdk-trace-node\": \"^2.0.1\",\n    \"@opentelemetry/semantic-conventions\": \"^1.37.0\",\n    \"@sinclair/typebox\": \"^0.34.37\",\n    \"commander\": \"^14.0.0\",\n    \"handlebars\": \"^4.7.8\",\n    \"nanoid\": \"^5.1.5\"\n  },\n  \"peerDependencies\": {\n    \"@opentelemetry/api\": \"^1.9.0\",\n    \"zod\": \"^3.25.0 || ^4.0.0\"\n  },\n  \"devDependencies\": {\n    \"@ai-sdk/anthropicv1\": \"npm:@ai-sdk/anthropic@^1.2.12\",\n    \"@ai-sdk/anthropicv2\": \"npm:@ai-sdk/anthropic@2.0.0-beta.9\",\n    \"@ai-sdk/openaiv1\": \"npm:@ai-sdk/openai@^1.3.23\",\n    \"@ai-sdk/openaiv2\": \"npm:@ai-sdk/openai@2.0.0-beta.12\",\n    \"@ai-sdk/providerv1\": \"npm:@ai-sdk/provider@^1.1.3\",\n    \"@ai-sdk/providerv2\": \"npm:@ai-sdk/provider@2.0.0-beta.1\",\n    \"@opentelemetry/api\": \"^1.9.0\",\n    \"@opentelemetry/core\": \"^2.0.1\",\n    \"@opentelemetry/sdk-trace-base\": \"^2.0.1\",\n    \"@opentelemetry/sdk-trace-node\": \"^2.0.1\",\n    \"@repo/eslint-config\": \"workspace:*\",\n    \"@types/node\": \"^22.15.29\",\n    \"@vitest/coverage-v8\": \"^3.2.4\",\n    \"aiv4\": \"npm:ai@^4.3.19\",\n    \"aiv5\": \"npm:ai@^5.0.0\",\n    \"c12\": \"^2.0.4\",\n    \"defu\": \"^6.1.4\",\n    \"esbuild\": \"^0.25.8\",\n    \"eslint\": \"catalog:\",\n    \"prettier\": \"catalog:\",\n    \"tinyrainbow\": \"^2.0.0\",\n    \"tsup\": \"catalog:\",\n    \"typescript\": \"catalog:\",\n    \"vitest\": \"catalog:\",\n    \"zod\": \"catalog:\"\n  },\n  \"files\": [\n    \"dist\"\n  ],\n  \"packageManager\": \"pnpm@10.16.1\"\n}\n","import {\n  context,\n  propagation,\n  trace,\n  SpanStatusCode,\n  type Span,\n  type Baggage,\n  type Tracer,\n} from '@opentelemetry/api';\n\nimport { WITHSPAN_BAGGAGE_KEY, WITHSPAN_REDACTION_POLICY_KEY } from './withSpanBaggageKey';\nimport { getTracer } from './utils/wrapperUtils';\nimport type { AxiomAIRedactionPolicy } from './utils/redaction';\n\n/**\n * Metadata for categorizing and tracking spans within the AI application.\n */\ntype WithSpanMeta = {\n  /** High-level capability being performed (e.g., 'text_generation', 'chat', 'analysis') */\n  capability: string;\n  /** Specific step within the capability (e.g., 'generate_response', 'summarize', 'extract') */\n  step: string;\n};\n\n/**\n * Wrap Vercel AI SDK functions like `generateText` and `streamText` in an OpenTelemetry span.\n *\n * Automatically detects and handles different response types:\n * - **Response streams**: Keeps span alive during entire stream consumption\n * - **Streaming objects**: Warns about incorrect usage patterns\n * - **Regular objects**: Ends span immediately after function completion\n *\n * The span name will be updated by the AI SDK middleware from 'gen_ai.call_llm'\n * to a model-specific name like 'chat gpt-4o-mini' when used with wrapped models.\n *\n * @param meta - Span metadata for categorization and tracking\n * @param meta.capability - High-level capability being performed (e.g., 'customer_support', 'meeting_summarizer')\n * @param meta.step - Specific step within the capability (e.g., 'categorize_message', 'transcribe_audio')\n * @param fn - Function to execute within the span context. Receives the span as a parameter so you can add additional attributes.\n * @param opts - Optional configuration\n * @param opts.tracer - Custom OpenTelemetry tracer instance. Defaults to the tracer provided by `initAxiomAI`.\n * @param opts.timeoutMs - Timeout for abandoned streams. Defaults to 600,000 (10 minutes).\n * @param opts.redactionPolicy - Optional redaction policy to override global policy for this span.\n *\n * @returns Promise that resolves to the same value as the wrapped function\n *\n * @example \n * // Non-streaming usage\n * const result = await withSpan(\n *   { capability: 'text_generation', step: 'generate' },\n *   async (span) => {\n *     span.setAttribute('user.id', userId); // can set attributes on the span\n *     const result = await generateObject({ model, prompt });\n *     // can do something with the result here, eg set additional attributes\n *     return result\n *   }\n * );\n *\n * @example \n * // Streaming usage with `@ai-sdk/react` in the frontend\n * ```ts\n * const response = withSpan(\n *   { capability: 'chat', step: 'stream_chat' },\n *   async (span) => {\n *     span.setAttribute('user.id', userId);\n *     const result = streamText({ model, messages });\n *     return result.toUIMessageStreamResponse();\n *   }\n * );\n * ```\n * \n * @example \n * // Streaming usage with express\n * ```ts\n * await withSpan(\n *   { capability: 'chat', step: 'stream_chat' },\n *   async (span) => {\n *     span.setAttribute('user.id', userId);\n *\n *     const { textStream } = streamText({ model, messages });\n *\n *     // Keep span open during entire stream consumption\n *     for await (const chunk of textStream) {\n *       res.write(chunk);\n *     }\n *   }\n * );\n\n * res.end();\n * ```\n */\nexport function withSpan<Return>(\n  meta: WithSpanMeta,\n  fn: (span: Span) => Promise<Return>,\n  opts?: {\n    tracer?: Tracer;\n    timeoutMs?: number;\n    redactionPolicy?: AxiomAIRedactionPolicy;\n  },\n): Promise<Return> {\n  const tracer = opts?.tracer ?? getTracer();\n\n  // Create span manually to control its lifecycle\n  const span = tracer.startSpan('gen_ai.call_llm');\n  const spanContext = trace.setSpan(context.active(), span);\n\n  return context.with(spanContext, async () => {\n    if (!span.isRecording()) {\n      const provider = trace.getTracerProvider();\n      const providerIsNoOp = provider.constructor.name === 'NoopTracerProvider';\n\n      // We don't warn for other non-recording cases (sampling=DROP, etc.) as those may be intentional\n      if (providerIsNoOp) {\n        const DEBUG = process.env.AXIOM_DEBUG === 'true';\n        if (!DEBUG) {\n          console.warn(\n            '[AxiomAI] No TracerProvider registered - spans are no-op. Make sure to call initAxiomAI() after your OpenTelemetry SDK has started.',\n          );\n        }\n      }\n    }\n\n    const bag: Baggage = propagation.createBaggage({\n      capability: { value: meta.capability },\n      step: { value: meta.step },\n      // TODO: maybe we can just check the active span name instead?\n      [WITHSPAN_BAGGAGE_KEY]: { value: 'true' }, // Mark that we're inside withSpan\n      // Store serialized redaction policy if provided\n      ...(opts?.redactionPolicy && {\n        [WITHSPAN_REDACTION_POLICY_KEY]: { value: JSON.stringify(opts.redactionPolicy) },\n      }),\n    });\n\n    const ctx = propagation.setBaggage(context.active(), bag);\n\n    let spanEnded = false;\n    const safeEndSpan = () => {\n      if (!spanEnded) {\n        spanEnded = true;\n        span.end();\n      }\n    };\n\n    // Timeout fallback for abandoned streams\n    const timeoutMs = opts?.timeoutMs ?? 600_000; // 10 minutes default\n    const timeoutId = setTimeout(() => {\n      safeEndSpan();\n    }, timeoutMs);\n\n    try {\n      const result = await context.with(ctx, () => fn(span));\n\n      // Auto-detect Response streams and keep span alive during consumption\n      if (result instanceof Response && result.body) {\n        // Check if body is already locked\n        if (result.body.locked) {\n          console.warn('[AxiomAI] Response body is already locked, cannot instrument stream');\n          clearTimeout(timeoutId);\n          safeEndSpan();\n          return result;\n        }\n\n        const originalReader = result.body.getReader();\n        const wrappedStream = new ReadableStream({\n          async pull(controller) {\n            try {\n              const { value, done } = await context.with(ctx, () => originalReader.read());\n              if (done) {\n                originalReader.releaseLock?.();\n                clearTimeout(timeoutId);\n                span.setStatus({ code: SpanStatusCode.OK });\n                safeEndSpan();\n                controller.close();\n              } else {\n                controller.enqueue(value);\n              }\n            } catch (err) {\n              originalReader.releaseLock?.();\n              clearTimeout(timeoutId);\n              span.recordException(err as Error);\n              span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: err instanceof Error ? err.message : String(err),\n              });\n              safeEndSpan();\n              controller.error(err);\n            }\n          },\n          async cancel(reason: unknown) {\n            try {\n              originalReader.releaseLock?.();\n              clearTimeout(timeoutId);\n              if (reason instanceof Error) {\n                span.recordException(reason);\n              } else if (reason) {\n                span.recordException({ message: String(reason), name: 'CancelError' });\n              }\n              span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: reason instanceof Error ? reason.message : String(reason),\n              });\n              safeEndSpan();\n              await originalReader.cancel(reason);\n            } catch (_err) {\n              // Ignore cancel errors\n            }\n          },\n        });\n\n        return new Response(wrappedStream, {\n          status: result.status,\n          statusText: result.statusText,\n          headers: result.headers,\n        }) as Return;\n      }\n\n      // Auto-detect Vercel AI SDK streaming objects (streamText returns object with textStream)\n      if (result && typeof result === 'object' && 'textStream' in result) {\n        console.warn(\n          '[AxiomAI] Detected streaming object with textStream. For proper span lifecycle, call .toUIMessageStreamResponse() or similar inside withSpan, not after.',\n        );\n        clearTimeout(timeoutId);\n        safeEndSpan(); // End span immediately to prevent memory leak\n        return result;\n      }\n\n      // Non-stream path: end span immediately\n      clearTimeout(timeoutId);\n      span.setStatus({ code: SpanStatusCode.OK });\n      safeEndSpan();\n      return result;\n    } catch (err) {\n      clearTimeout(timeoutId);\n      span.recordException(err as Error);\n      span.setStatus({\n        code: SpanStatusCode.ERROR,\n        message: err instanceof Error ? err.message : String(err),\n      });\n      safeEndSpan();\n      throw err;\n    }\n  });\n}\n","import {\n  trace,\n  context,\n  propagation,\n  type Span,\n  SpanStatusCode,\n  type AttributeValue,\n  type Tracer,\n} from '@opentelemetry/api';\nimport { Attr, SCHEMA_BASE_URL, SCHEMA_VERSION } from '../semconv/attributes';\nimport { createStartActiveSpan } from '../startActiveSpan';\nimport { WITHSPAN_BAGGAGE_KEY } from '../withSpanBaggageKey';\n\nimport { getGlobalTracer } from '../initAxiomAI';\n// Removed import of createGenAISpanName since it's no longer exported\nimport packageJson from '../../../package.json';\n\n/**\n * Classifies errors into low-cardinality types for OpenTelemetry error.type attribute\n * Reference: OTel spec § 7.22.5 for error.type guidelines\n *\n * Uses explicit mapping for useful error types, avoiding generic built-in errors\n * that are not actionable for observability dashboards.\n *\n * @returns string for actionable error types, undefined for unclassifiable errors\n */\nfunction classifyError(err: unknown): string | undefined {\n  if (err == null) return undefined;\n\n  if (err instanceof Error) {\n    const name = err.name.toLowerCase();\n\n    // Explicit mapping for actionable error types\n    if (name.includes('timeout')) return 'timeout';\n    if (name.includes('abort')) return 'timeout'; // AbortError often means timeout\n    if (name.includes('network') || name.includes('fetch')) return 'network';\n    if (name.includes('validation')) return 'validation';\n    if (name.includes('auth')) return 'authentication';\n    if (name.includes('parse') || name.includes('json')) return 'parsing';\n    if (name.includes('permission') || name.includes('forbidden')) return 'authorization';\n    if (name.includes('rate') && name.includes('limit')) return 'rate_limit';\n    if (name.includes('quota') || name.includes('limit')) return 'quota_exceeded';\n\n    // Skip generic built-in errors (TypeError, ReferenceError, etc.)\n    // They're not useful for observability dashboards\n    return undefined;\n  }\n\n  return undefined; // Handles primitives thrown as errors\n}\n\n/**\n * Classifies tool-specific errors using duck-typing for cross-vendor compatibility\n * Handles node-fetch version differences and external API error patterns\n *\n * @param err The error to classify\n * @param span The span to set error attributes on\n */\nexport function classifyToolError(err: unknown, span: Span): void {\n  // Enhanced error handling for OpenTelemetry compliance\n  if (err instanceof Error) {\n    span.recordException(err); // Error objects are compatible with Exception interface\n  } else {\n    // Convert primitives to compatible format\n    span.recordException({\n      message: String(err),\n      name: 'UnknownError',\n    });\n  }\n\n  span.setStatus({\n    code: SpanStatusCode.ERROR,\n    message: err instanceof Error ? err.message : String(err),\n  });\n\n  let errorType = 'unknown';\n  let statusCode: string | number | undefined;\n\n  // Duck-type check for common error patterns (don't rely on inheritance)\n  if (err && typeof err === 'object') {\n    const errObj = err as any;\n    const name = errObj.name?.toLowerCase() || '';\n    const message = errObj.message?.toLowerCase() || '';\n\n    if (name.includes('timeout') || name.includes('abort') || message.includes('timeout')) {\n      errorType = 'timeout';\n    } else if (\n      name.includes('validation') ||\n      errObj.code === 'VALIDATION_ERROR' ||\n      message.includes('validation')\n    ) {\n      errorType = 'validation';\n    } else if (\n      name.includes('fetch') ||\n      name.includes('network') ||\n      message.includes('network') ||\n      message.includes('fetch failed')\n    ) {\n      errorType = 'network';\n      // Handle both node-fetch v2 (.code) and v3 (.status) patterns\n      statusCode = errObj.status || errObj.code;\n    } else if (\n      name.includes('auth') ||\n      message.includes('auth') ||\n      message.includes('unauthorized')\n    ) {\n      errorType = 'authentication';\n    } else if (\n      name.includes('permission') ||\n      name.includes('forbidden') ||\n      message.includes('forbidden')\n    ) {\n      errorType = 'authorization';\n    } else if (\n      name.includes('rate') &&\n      (name.includes('limit') || message.includes('rate limit'))\n    ) {\n      errorType = 'rate_limit';\n    } else if (\n      name.includes('quota') ||\n      message.includes('quota') ||\n      message.includes('limit exceeded')\n    ) {\n      errorType = 'quota_exceeded';\n    } else if (\n      name.includes('parse') ||\n      name.includes('json') ||\n      message.includes('json') ||\n      message.includes('parse')\n    ) {\n      errorType = 'parsing';\n    }\n  }\n\n  // MANDATORY: Standard OpenTelemetry error attributes\n  span.setAttribute(Attr.Error.Type, errorType);\n  if (err instanceof Error && err.message) {\n    span.setAttribute(Attr.Error.Message, err.message);\n  }\n\n  // Standard HTTP attributes for network errors\n  if (statusCode !== undefined) {\n    span.setAttribute(Attr.HTTP.Response.StatusCode, statusCode as AttributeValue);\n  }\n}\n\n/**\n * Check if the current tracer provider is a no-op\n * Uses safer detection that works with bundling/minification\n */\nfunction isNoOpTracerProvider(): boolean {\n  const provider = trace.getTracerProvider();\n\n  // Check constructor name (may fail with bundling/minification)\n  if (provider.constructor.name === 'NoopTracerProvider') {\n    return true;\n  }\n\n  // Check if getTracer method exists before calling it (for test mocks)\n  if (typeof (provider as any).getTracer !== 'function') {\n    return true;\n  }\n\n  return false;\n}\n\n/**\n * Gets the appropriate tracer instance using global scope or fallbacks\n */\nexport function getTracer(): Tracer {\n  const tracer = getGlobalTracer();\n\n  if (isNoOpTracerProvider()) {\n    const DEBUG = process.env.AXIOM_DEBUG === 'true';\n    if (!DEBUG) {\n      console.warn(\n        '[AxiomAI] No TracerProvider registered - spans will be no-op. ' +\n          'Make sure to call initAxiomAI() after your OpenTelemetry SDK has started (sdk.start()).',\n      );\n    }\n  }\n\n  return tracer;\n}\n\n/**\n * Creates a standardized span name for GenAI operations\n */\nfunction createGenAISpanName(operation: string, suffix?: string): string {\n  return suffix ? `${operation} ${suffix}` : operation;\n}\n\n/**\n * Common span context interface for both V1 and V2\n */\nexport interface CommonSpanContext {\n  originalPrompt: any[];\n  rawCall?: any;\n}\n\n/**\n * Sets common scope attributes on a span from baggage\n */\nexport function setScopeAttributes(span: Span): void {\n  const bag = propagation.getActiveBaggage();\n\n  if (bag) {\n    const capability = bag.getEntry('capability')?.value;\n    if (capability) {\n      span.setAttribute(Attr.GenAI.Capability.Name, capability);\n    }\n\n    const step = bag.getEntry('step')?.value;\n    if (step) {\n      span.setAttribute(Attr.GenAI.Step.Name, step);\n    }\n  }\n}\n\n/**\n * Sets Axiom-specific base attributes on a span\n */\nexport function setAxiomBaseAttributes(span: Span): void {\n  span.setAttributes({\n    [Attr.Axiom.GenAI.SchemaURL]: `${SCHEMA_BASE_URL}${SCHEMA_VERSION}`,\n    [Attr.Axiom.GenAI.SDK.Name]: packageJson.name,\n    [Attr.Axiom.GenAI.SDK.Version]: packageJson.version,\n  });\n}\n\n/**\n * Sets common base attributes on a span\n */\nexport function setBaseAttributes(span: Span, provider: string, modelId: string): void {\n  span.setAttributes({\n    [Attr.GenAI.Operation.Name]: Attr.GenAI.Operation.Name_Values.Chat,\n    [Attr.GenAI.Request.Model]: modelId,\n  });\n\n  const systemValue = mapVercelSDKProviderToOTelProvider(provider);\n  if (systemValue) {\n    span.setAttribute(Attr.GenAI.Provider.Name, systemValue);\n  }\n\n  setAxiomBaseAttributes(span);\n}\n\n/**\n * Sets common request parameter attributes on a span\n */\nexport function setRequestParameterAttributes(\n  span: Span,\n  params: {\n    maxTokens?: number;\n    frequencyPenalty?: number;\n    presencePenalty?: number;\n    temperature?: number;\n    topP?: number;\n    topK?: number;\n    seed?: number;\n    stopSequences?: string[];\n  },\n): void {\n  const {\n    maxTokens,\n    frequencyPenalty,\n    presencePenalty,\n    temperature,\n    topP,\n    topK,\n    seed,\n    stopSequences,\n  } = params;\n\n  if (maxTokens !== undefined) {\n    span.setAttribute(Attr.GenAI.Request.MaxTokens, maxTokens);\n  }\n  if (frequencyPenalty !== undefined) {\n    span.setAttribute(Attr.GenAI.Request.FrequencyPenalty, frequencyPenalty);\n  }\n  if (presencePenalty !== undefined) {\n    span.setAttribute(Attr.GenAI.Request.PresencePenalty, presencePenalty);\n  }\n  if (temperature !== undefined) {\n    span.setAttribute(Attr.GenAI.Request.Temperature, temperature);\n  }\n  if (topP !== undefined) {\n    span.setAttribute(Attr.GenAI.Request.TopP, topP);\n  }\n  if (topK !== undefined) {\n    span.setAttribute(Attr.GenAI.Request.TopK, topK);\n  }\n  if (seed !== undefined) {\n    span.setAttribute(Attr.GenAI.Request.Seed, seed);\n  }\n  if (stopSequences && stopSequences.length > 0) {\n    span.setAttribute(Attr.GenAI.Request.StopSequences, JSON.stringify(stopSequences));\n  }\n}\n\n/**\n * Creates a child span for stream processing\n * This is used to capture errors that occur during stream processing,\n * after the parent span has ended\n */\nexport function createStreamChildSpan(parentSpan: Span, operationName: string): Span {\n  const tracer = getTracer();\n\n  // Create child span by setting parent context\n  const spanContext = trace.setSpan(context.active(), parentSpan);\n  const childSpan = tracer.startSpan(operationName, undefined, spanContext);\n\n  return childSpan;\n}\n\n/**\n * Enhanced error handling for child spans with OpenTelemetry compliance\n */\nexport function handleStreamError(span: Span, err: unknown): void {\n  // Enhanced error handling for OpenTelemetry compliance\n  if (err instanceof Error) {\n    span.recordException(err); // Error objects are compatible with Exception interface\n  } else {\n    // Convert primitives to compatible format\n    span.recordException({\n      message: String(err),\n      name: 'UnknownError',\n    });\n  }\n\n  span.setStatus({\n    code: SpanStatusCode.ERROR,\n    message: err instanceof Error ? err.message : String(err),\n  });\n\n  // MANDATORY: Add OpenTelemetry error attributes for cross-vendor compatibility\n  const errorType = classifyError(err);\n  span.setAttribute(Attr.Error.Type, errorType ?? 'unknown');\n\n  // OPTIONAL: Add human-readable error message\n  if (err instanceof Error && err.message) {\n    span.setAttribute(Attr.Error.Message, err.message);\n  }\n\n  // For Vercel AI SDK specific errors, add HTTP status if available\n  if (err && typeof err === 'object' && 'status' in err) {\n    span.setAttribute(Attr.HTTP.Response.StatusCode, err.status as AttributeValue);\n  }\n}\n\n/**\n * Common span handling logic for both V1 and V2\n */\nexport async function withSpanHandling<T>(\n  modelId: string,\n  operation: (span: Span, context: CommonSpanContext) => Promise<T>,\n): Promise<T> {\n  const bag = propagation.getActiveBaggage();\n  const isWithinWithSpan = bag?.getEntry(WITHSPAN_BAGGAGE_KEY)?.value === 'true';\n\n  const context: CommonSpanContext = {\n    originalPrompt: [],\n    rawCall: undefined,\n  };\n\n  if (isWithinWithSpan) {\n    // Reuse existing span created by withSpan\n    const activeSpan = trace.getActiveSpan();\n    if (!activeSpan) {\n      throw new Error('Expected active span when within withSpan');\n    }\n    activeSpan.updateName(createGenAISpanName(Attr.GenAI.Operation.Name_Values.Chat, modelId));\n\n    try {\n      return await operation(activeSpan, context);\n    } catch (err) {\n      // Enhanced error handling for OpenTelemetry compliance\n      if (err instanceof Error) {\n        activeSpan.recordException(err); // Error objects are compatible with Exception interface\n      } else {\n        // Convert primitives to compatible format\n        activeSpan.recordException({\n          message: String(err),\n          name: 'UnknownError',\n        });\n      }\n\n      activeSpan.setStatus({\n        code: SpanStatusCode.ERROR,\n        message: err instanceof Error ? err.message : String(err),\n      });\n\n      // MANDATORY: Add OpenTelemetry error attributes for cross-vendor compatibility\n      const errorType = classifyError(err);\n      activeSpan.setAttribute(Attr.Error.Type, errorType ?? 'unknown');\n\n      // OPTIONAL: Add human-readable error message\n      if (err instanceof Error && err.message) {\n        activeSpan.setAttribute(Attr.Error.Message, err.message);\n      }\n\n      // For Vercel AI SDK specific errors, add HTTP status if available\n      if (err && typeof err === 'object' && 'status' in err) {\n        activeSpan.setAttribute(Attr.HTTP.Response.StatusCode, err.status as AttributeValue);\n      }\n\n      throw err;\n    }\n  } else {\n    // Create new span only if not within withSpan\n    const tracer = getTracer();\n    const startActiveSpan = createStartActiveSpan(tracer);\n    const name = createGenAISpanName(Attr.GenAI.Operation.Name_Values.Chat, modelId);\n\n    return startActiveSpan(name, null, (span) => operation(span, context), {\n      onError: (err, span) => {\n        // Enhanced error handling for OpenTelemetry compliance\n        // MANDATORY: Add OpenTelemetry error attributes for cross-vendor compatibility\n        const errorType = classifyError(err);\n        span.setAttribute(Attr.Error.Type, errorType ?? 'unknown');\n\n        // OPTIONAL: Add human-readable error message\n        if (err instanceof Error && err.message) {\n          span.setAttribute(Attr.Error.Message, err.message);\n        }\n\n        // For Vercel AI SDK specific errors, add HTTP status if available\n        if (err && typeof err === 'object' && 'status' in err) {\n          span.setAttribute(Attr.HTTP.Response.StatusCode, err.status as AttributeValue);\n        }\n      },\n    });\n  }\n}\n\n/**\n * Sets common response attributes on a span\n */\nexport function setResponseAttributes(\n  span: Span,\n  response: {\n    id?: string;\n    modelId?: string;\n    usage?: {\n      inputTokens?: number;\n      outputTokens?: number;\n      promptTokens?: number;\n      completionTokens?: number;\n    };\n    finishReason?: string;\n  },\n): void {\n  if (response.id) {\n    span.setAttribute(Attr.GenAI.Response.ID, response.id);\n  }\n  if (response.modelId) {\n    span.setAttribute(Attr.GenAI.Response.Model, response.modelId);\n  }\n\n  if (response.usage) {\n    // Handle both V1 and V2 usage formats\n    const inputTokens = response.usage.inputTokens ?? response.usage.promptTokens;\n    const outputTokens = response.usage.outputTokens ?? response.usage.completionTokens;\n\n    if (inputTokens !== undefined) {\n      span.setAttribute(Attr.GenAI.Usage.InputTokens, inputTokens);\n    }\n    if (outputTokens !== undefined) {\n      span.setAttribute(Attr.GenAI.Usage.OutputTokens, outputTokens);\n    }\n  }\n\n  if (response.finishReason) {\n    span.setAttribute(Attr.GenAI.Response.FinishReasons, JSON.stringify([response.finishReason]));\n  }\n}\n\n/**\n * Determines output type from response format - V1 version\n */\nexport function determineOutputTypeV1(options: {\n  responseFormat?: { type?: string };\n  mode?: { type?: string };\n}): string | undefined {\n  if (options.responseFormat?.type) {\n    switch (options.responseFormat.type) {\n      case 'json':\n        return Attr.GenAI.Output.Type_Values.Json;\n      case 'text':\n        return Attr.GenAI.Output.Type_Values.Text;\n    }\n  }\n\n  if (options.mode?.type === 'object-json' || options.mode?.type === 'object-tool') {\n    return Attr.GenAI.Output.Type_Values.Json;\n  }\n\n  if (options.mode?.type === 'regular') {\n    return Attr.GenAI.Output.Type_Values.Text;\n  }\n\n  return undefined;\n}\n\n/**\n * Determines output type from response format - V2 version\n */\nexport function determineOutputTypeV2(options: {\n  responseFormat?: { type?: string };\n}): string | undefined {\n  if (options.responseFormat?.type) {\n    switch (options.responseFormat.type) {\n      case 'json':\n        return Attr.GenAI.Output.Type_Values.Json;\n      case 'text':\n        return Attr.GenAI.Output.Type_Values.Text;\n    }\n  }\n\n  return undefined;\n}\n\n/**\n * Maps AI SDK provider IDs to OpenTelemetry gen_ai.provider.name values\n *\n * @param vercelSDKProvider - The provider ID from the AI SDK\n * @returns The corresponding `gen_ai.provider.name` value, or `undefined` if no match is found\n */\nexport function mapVercelSDKProviderToOTelProvider(vercelSDKProvider: string): string | undefined {\n  if (vercelSDKProvider === 'openai-compatible') {\n    // we don't know the real provider\n    return undefined;\n  }\n\n  // exact matches\n  switch (vercelSDKProvider) {\n    case 'amazon-bedrock':\n      return Attr.GenAI.Provider.Name_Values.AWSBedrock;\n    case 'anthropic':\n    case 'anthropic.messages':\n      return Attr.GenAI.Provider.Name_Values.Anthropic;\n    case 'assemblyai':\n    case 'assemblyai.transcription':\n      return Attr.GenAI.Provider.Name_Values.AssemblyAI;\n    case 'deepgram':\n    case 'deepgram.transcription':\n      return Attr.GenAI.Provider.Name_Values.Deepgram;\n    case 'gateway': // `import { gateway } from 'ai'`\n      return Attr.GenAI.Provider.Name_Values.Vercel;\n    case 'gladia':\n    case 'gladia.transcription':\n      return Attr.GenAI.Provider.Name_Values.Gladia;\n    case 'google':\n    case 'google.generative-ai':\n      return Attr.GenAI.Provider.Name_Values.GCPGemini;\n    case 'groq':\n      return Attr.GenAI.Provider.Name_Values.Groq;\n    case 'mistral':\n      return Attr.GenAI.Provider.Name_Values.MistralAI;\n    case 'openai':\n      return Attr.GenAI.Provider.Name_Values.OpenAI;\n    case 'perplexity':\n      return Attr.GenAI.Provider.Name_Values.Perplexity;\n    case 'replicate':\n      return Attr.GenAI.Provider.Name_Values.Replicate;\n    case 'revai':\n    case 'revai.transcription':\n      return Attr.GenAI.Provider.Name_Values.RevAI;\n    case 'togetherai':\n      return Attr.GenAI.Provider.Name_Values.TogetherAI;\n    case 'xai':\n      return Attr.GenAI.Provider.Name_Values.XAI;\n\n    // startswith + fall through\n    default: {\n      if (vercelSDKProvider.startsWith('azure.')) {\n        return Attr.GenAI.Provider.Name_Values.AzureAIOpenAI;\n      }\n      if (vercelSDKProvider.startsWith('cerebras.')) {\n        return Attr.GenAI.Provider.Name_Values.Cerebras;\n      }\n      if (vercelSDKProvider.startsWith('cohere.')) {\n        return Attr.GenAI.Provider.Name_Values.Cohere;\n      }\n      if (vercelSDKProvider.startsWith('deepinfra.')) {\n        return Attr.GenAI.Provider.Name_Values.DeepInfra;\n      }\n      if (vercelSDKProvider.startsWith('deepseek.')) {\n        return Attr.GenAI.Provider.Name_Values.Deepseek;\n      }\n      if (vercelSDKProvider.startsWith('elevenlabs.')) {\n        return Attr.GenAI.Provider.Name_Values.ElevenLabs;\n      }\n      if (vercelSDKProvider.startsWith('fal.')) {\n        return Attr.GenAI.Provider.Name_Values.Fal;\n      }\n      if (vercelSDKProvider.startsWith('fireworks.')) {\n        return Attr.GenAI.Provider.Name_Values.Fireworks;\n      }\n      if (vercelSDKProvider.startsWith('google.vertex.')) {\n        return Attr.GenAI.Provider.Name_Values.GCPVertexAI;\n      }\n      if (vercelSDKProvider.startsWith('groq.')) {\n        return Attr.GenAI.Provider.Name_Values.Groq;\n      }\n      if (vercelSDKProvider.startsWith('hume.')) {\n        return Attr.GenAI.Provider.Name_Values.Hume;\n      }\n      if (vercelSDKProvider.startsWith('lmnt.')) {\n        return Attr.GenAI.Provider.Name_Values.Lmnt;\n      }\n      if (vercelSDKProvider.startsWith('luma.')) {\n        return Attr.GenAI.Provider.Name_Values.Luma;\n      }\n      if (vercelSDKProvider.startsWith('mistral.')) {\n        return Attr.GenAI.Provider.Name_Values.MistralAI;\n      }\n      if (vercelSDKProvider.startsWith('openai.')) {\n        return Attr.GenAI.Provider.Name_Values.OpenAI;\n      }\n      if (vercelSDKProvider.startsWith('vercel.')) {\n        return Attr.GenAI.Provider.Name_Values.Vercel;\n      }\n      if (vercelSDKProvider.startsWith('vertex.anthropic.')) {\n        return Attr.GenAI.Provider.Name_Values.GCPVertexAI;\n      }\n      if (vercelSDKProvider.startsWith('xai.')) {\n        return Attr.GenAI.Provider.Name_Values.XAI;\n      }\n\n      // most other openai-compatible providers use {providerName}.{chat|completion|embedding|image}\n      const s = vercelSDKProvider.split('.');\n      if (s.length === 2) {\n        return s[0];\n      }\n\n      // For unknown providers, don't set the attribute\n      return undefined;\n    }\n  }\n}\n","import {\n  ATTR_ERROR_TYPE,\n  ATTR_HTTP_RESPONSE_STATUS_CODE,\n} from '@opentelemetry/semantic-conventions';\n\nimport {\n  ATTR_EVAL_CASE_INDEX,\n  ATTR_EVAL_CASE_EXPECTED,\n  ATTR_EVAL_CASE_INPUT,\n  ATTR_EVAL_CASE_OUTPUT,\n  ATTR_EVAL_CASE_METADATA,\n  ATTR_EVAL_CASE_SCORES,\n  ATTR_EVAL_SCORE_PASSED,\n  ATTR_EVAL_SCORE_VALUE,\n  ATTR_EVAL_SCORE_NAME,\n  ATTR_EVAL_SCORE_THRESHOLD,\n  ATTR_EVAL_SCORE_METADATA,\n  ATTR_EVAL_TASK_TYPE,\n  ATTR_EVAL_TASK_NAME,\n  ATTR_EVAL_TASK_OUTPUT,\n  ATTR_EVAL_COLLECTION_NAME,\n  ATTR_EVAL_COLLECTION_SIZE,\n  ATTR_EVAL_ID,\n  ATTR_EVAL_BASELINE_ID,\n  ATTR_EVAL_BASELINE_NAME,\n  ATTR_EVAL_NAME,\n  ATTR_EVAL_TAGS,\n  ATTR_EVAL_TYPE,\n  ATTR_EVAL_COLLECTION_ID,\n  ATTR_EVAL_USER_NAME,\n  ATTR_EVAL_USER_EMAIL,\n  ATTR_EVAL_VERSION,\n} from './eval_proposal';\n\nimport {\n  ATTR_ERROR_MESSAGE,\n  ATTR_GEN_AI_AGENT_DESCRIPTION,\n  ATTR_GEN_AI_AGENT_ID,\n  ATTR_GEN_AI_AGENT_NAME,\n  ATTR_GEN_AI_CONVERSATION_ID,\n  ATTR_GEN_AI_INPUT_MESSAGES,\n  ATTR_GEN_AI_OPERATION_NAME,\n  ATTR_GEN_AI_OUTPUT_MESSAGES,\n  ATTR_GEN_AI_OUTPUT_TYPE,\n  ATTR_GEN_AI_PROVIDER_NAME,\n  ATTR_GEN_AI_REQUEST_CHOICE_COUNT,\n  ATTR_GEN_AI_REQUEST_ENCODING_FORMATS,\n  ATTR_GEN_AI_REQUEST_FREQUENCY_PENALTY,\n  ATTR_GEN_AI_REQUEST_MAX_TOKENS,\n  ATTR_GEN_AI_REQUEST_MODEL,\n  ATTR_GEN_AI_REQUEST_PRESENCE_PENALTY,\n  ATTR_GEN_AI_REQUEST_SEED,\n  ATTR_GEN_AI_REQUEST_STOP_SEQUENCES,\n  ATTR_GEN_AI_REQUEST_TEMPERATURE,\n  ATTR_GEN_AI_REQUEST_TOP_K,\n  ATTR_GEN_AI_REQUEST_TOP_P,\n  ATTR_GEN_AI_RESPONSE_FINISH_REASONS,\n  ATTR_GEN_AI_RESPONSE_ID,\n  ATTR_GEN_AI_RESPONSE_MODEL,\n  ATTR_GEN_AI_TOOL_CALL_ID,\n  ATTR_GEN_AI_TOOL_DESCRIPTION,\n  ATTR_GEN_AI_TOOL_NAME,\n  ATTR_GEN_AI_TOOL_TYPE,\n  ATTR_GEN_AI_USAGE_INPUT_TOKENS,\n  ATTR_GEN_AI_USAGE_OUTPUT_TOKENS,\n  GEN_AI_OPERATION_NAME_VALUE_CHAT,\n  GEN_AI_OPERATION_NAME_VALUE_CREATE_AGENT,\n  GEN_AI_OPERATION_NAME_VALUE_EMBEDDINGS,\n  GEN_AI_OPERATION_NAME_VALUE_EXECUTE_TOOL,\n  GEN_AI_OPERATION_NAME_VALUE_GENERATE_CONTENT,\n  GEN_AI_OPERATION_NAME_VALUE_INVOKE_AGENT,\n  GEN_AI_OUTPUT_TYPE_VALUE_IMAGE,\n  GEN_AI_OUTPUT_TYPE_VALUE_JSON,\n  GEN_AI_OUTPUT_TYPE_VALUE_SPEECH,\n  GEN_AI_OUTPUT_TYPE_VALUE_TEXT,\n  GEN_AI_PROVIDER_NAME_VALUE_ANTHROPIC,\n  GEN_AI_PROVIDER_NAME_VALUE_AWS_BEDROCK,\n  GEN_AI_PROVIDER_NAME_VALUE_AZURE_AI_INFERENCE,\n  GEN_AI_PROVIDER_NAME_VALUE_AZURE_AI_OPENAI,\n  GEN_AI_PROVIDER_NAME_VALUE_COHERE,\n  GEN_AI_PROVIDER_NAME_VALUE_DEEPSEEK,\n  GEN_AI_PROVIDER_NAME_VALUE_GCP_GEMINI,\n  GEN_AI_PROVIDER_NAME_VALUE_GCP_GEN_AI,\n  GEN_AI_PROVIDER_NAME_VALUE_GCP_VERTEX_AI,\n  GEN_AI_PROVIDER_NAME_VALUE_GROQ,\n  GEN_AI_PROVIDER_NAME_VALUE_IBM_WATSONX_AI,\n  GEN_AI_PROVIDER_NAME_VALUE_MISTRAL_AI,\n  GEN_AI_PROVIDER_NAME_VALUE_OPENAI,\n  GEN_AI_PROVIDER_NAME_VALUE_PERPLEXITY,\n  GEN_AI_PROVIDER_NAME_VALUE_X_AI,\n} from '@opentelemetry/semantic-conventions/incubating';\n\nexport const SCHEMA_VERSION = '0.0.2';\nexport const SCHEMA_BASE_URL = 'https://axiom.co/ai/schemas/';\n\n/**\n * PROPRIETARY ATTRIBUTES (o11y)\n *\n * @see: https://axiom.co/docs/ai-engineering/semantic-conventions\n */\n\nconst ATTR_AXIOM_GEN_AI_SCHEMA_URL = 'axiom.gen_ai.schema_url';\nconst ATTR_AXIOM_GEN_AI_SDK_NAME = 'axiom.gen_ai.sdk.name';\nconst ATTR_AXIOM_GEN_AI_SDK_VERSION = 'axiom.gen_ai.sdk.version';\nconst ATTR_GEN_AI_CAPABILITY_NAME = 'gen_ai.capability.name';\nconst ATTR_GEN_AI_STEP_NAME = 'gen_ai.step.name';\nconst ATTR_GEN_AI_TOOL_ARGUMENTS = 'gen_ai.tool.arguments'; // deprecated by OTel\nconst ATTR_GEN_AI_TOOL_MESSAGE = 'gen_ai.tool.message'; // deprecated by OTel\n\nconst GEN_AI_PROVIDER_NAME_VALUE_ASSEMBLYAI = 'assemblyai';\nconst GEN_AI_PROVIDER_NAME_VALUE_CEREBRAS = 'cerebras';\nconst GEN_AI_PROVIDER_NAME_VALUE_DEEPGRAM = 'deepgram';\nconst GEN_AI_PROVIDER_NAME_VALUE_DEEPINFRA = 'deepinfra';\nconst GEN_AI_PROVIDER_NAME_VALUE_ELEVENLABS = 'elevenlabs';\nconst GEN_AI_PROVIDER_NAME_VALUE_FAL = 'fal';\nconst GEN_AI_PROVIDER_NAME_VALUE_FIREWORKS = 'fireworks';\nconst GEN_AI_PROVIDER_NAME_VALUE_GLADIA = 'gladia';\nconst GEN_AI_PROVIDER_NAME_VALUE_HUME = 'hume';\nconst GEN_AI_PROVIDER_NAME_VALUE_LMNT = 'lmnt';\nconst GEN_AI_PROVIDER_NAME_VALUE_LUMA = 'luma';\nconst GEN_AI_PROVIDER_NAME_VALUE_REPLICATE = 'replicate';\nconst GEN_AI_PROVIDER_NAME_VALUE_REVAI = 'revai';\nconst GEN_AI_PROVIDER_NAME_VALUE_TOGETHERAI = 'togetherai';\nconst GEN_AI_PROVIDER_NAME_VALUE_VERCEL = 'vercel';\n\n/**\n * When adding something new here, please:\n * 1. Make sure it doesn't already exist as part of OTel Semantic Conventions (use that instead)\n * 2. Make sure to use standard naming schema, ie snake_case\n * 3. If a specific feature has an attribute you would like to use, extract it to the shared section\n *\n * Also Experimental Attributes should always be imported here and then used from the CustomAttributes object\n * because they are unstable.\n *\n * @see: https://github.com/open-telemetry/opentelemetry-js/tree/c89cb38d0fec39d54cf3fcb35c429a8129e9c909/semantic-conventions#unstable-semconv\n */\nexport const Attr = {\n  __EXPERIMENTAL_Flag: (flagName: string) => `flag.${flagName}`,\n  __EXPERIMENTAL_Fact: (factName: string) => `fact.${factName}`,\n  Axiom: {\n    GenAI: {\n      SchemaURL: ATTR_AXIOM_GEN_AI_SCHEMA_URL,\n      SDK: {\n        Name: ATTR_AXIOM_GEN_AI_SDK_NAME,\n        Version: ATTR_AXIOM_GEN_AI_SDK_VERSION,\n      },\n    },\n  },\n  GenAI: {\n    PromptMetadata: {\n      ID: 'axiom.gen_ai.prompt.id',\n      Name: 'axiom.gen_ai.prompt.name',\n      Slug: 'axiom.gen_ai.prompt.slug',\n      Version: 'axiom.gen_ai.prompt.version',\n    },\n    /**\n     * These two are used to identify the span\n     */\n    Capability: {\n      Name: ATTR_GEN_AI_CAPABILITY_NAME,\n    },\n    Step: {\n      Name: ATTR_GEN_AI_STEP_NAME,\n    },\n    Provider: {\n      Name: ATTR_GEN_AI_PROVIDER_NAME,\n      Name_Values: {\n        Anthropic: GEN_AI_PROVIDER_NAME_VALUE_ANTHROPIC,\n        AssemblyAI: GEN_AI_PROVIDER_NAME_VALUE_ASSEMBLYAI,\n        AWSBedrock: GEN_AI_PROVIDER_NAME_VALUE_AWS_BEDROCK,\n        AzureAIInference: GEN_AI_PROVIDER_NAME_VALUE_AZURE_AI_INFERENCE,\n        AzureAIOpenAI: GEN_AI_PROVIDER_NAME_VALUE_AZURE_AI_OPENAI,\n        Cerebras: GEN_AI_PROVIDER_NAME_VALUE_CEREBRAS,\n        Cohere: GEN_AI_PROVIDER_NAME_VALUE_COHERE,\n        Deepgram: GEN_AI_PROVIDER_NAME_VALUE_DEEPGRAM,\n        DeepInfra: GEN_AI_PROVIDER_NAME_VALUE_DEEPINFRA,\n        Deepseek: GEN_AI_PROVIDER_NAME_VALUE_DEEPSEEK,\n        ElevenLabs: GEN_AI_PROVIDER_NAME_VALUE_ELEVENLABS,\n        Fal: GEN_AI_PROVIDER_NAME_VALUE_FAL,\n        Fireworks: GEN_AI_PROVIDER_NAME_VALUE_FIREWORKS,\n        GCPGemini: GEN_AI_PROVIDER_NAME_VALUE_GCP_GEMINI,\n        GCPGenAI: GEN_AI_PROVIDER_NAME_VALUE_GCP_GEN_AI,\n        GCPVertexAI: GEN_AI_PROVIDER_NAME_VALUE_GCP_VERTEX_AI,\n        Gladia: GEN_AI_PROVIDER_NAME_VALUE_GLADIA,\n        Groq: GEN_AI_PROVIDER_NAME_VALUE_GROQ,\n        Hume: GEN_AI_PROVIDER_NAME_VALUE_HUME,\n        IBMWatsonxAI: GEN_AI_PROVIDER_NAME_VALUE_IBM_WATSONX_AI,\n        Lmnt: GEN_AI_PROVIDER_NAME_VALUE_LMNT,\n        Luma: GEN_AI_PROVIDER_NAME_VALUE_LUMA,\n        MistralAI: GEN_AI_PROVIDER_NAME_VALUE_MISTRAL_AI,\n        OpenAI: GEN_AI_PROVIDER_NAME_VALUE_OPENAI,\n        Perplexity: GEN_AI_PROVIDER_NAME_VALUE_PERPLEXITY,\n        Replicate: GEN_AI_PROVIDER_NAME_VALUE_REPLICATE,\n        RevAI: GEN_AI_PROVIDER_NAME_VALUE_REVAI,\n        TogetherAI: GEN_AI_PROVIDER_NAME_VALUE_TOGETHERAI,\n        Vercel: GEN_AI_PROVIDER_NAME_VALUE_VERCEL,\n        XAI: GEN_AI_PROVIDER_NAME_VALUE_X_AI,\n      },\n    },\n    /**\n     * Regular attributes\n     */\n    Agent: {\n      Description: ATTR_GEN_AI_AGENT_DESCRIPTION, // not yet used by axiom-ai\n      ID: ATTR_GEN_AI_AGENT_ID, // not yet used by axiom-ai\n      Name: ATTR_GEN_AI_AGENT_NAME, // not yet used by axiom-ai\n    },\n    Conversation: {\n      ID: ATTR_GEN_AI_CONVERSATION_ID, // not yet used by axiom-ai, anyway probably needs to be provided by user\n    },\n    Input: {\n      Messages: ATTR_GEN_AI_INPUT_MESSAGES,\n    },\n    Operation: {\n      Name: ATTR_GEN_AI_OPERATION_NAME,\n      Name_Values: {\n        /**\n         * Note that \"text_completion\" is deprecated in favor of \"chat\" for both OpenAI and Anthropic\n         */\n        Chat: GEN_AI_OPERATION_NAME_VALUE_CHAT,\n        CreateAgent: GEN_AI_OPERATION_NAME_VALUE_CREATE_AGENT,\n        Embeddings: GEN_AI_OPERATION_NAME_VALUE_EMBEDDINGS,\n        ExecuteTool: GEN_AI_OPERATION_NAME_VALUE_EXECUTE_TOOL,\n        GenerateContent: GEN_AI_OPERATION_NAME_VALUE_GENERATE_CONTENT,\n        InvokeAgent: GEN_AI_OPERATION_NAME_VALUE_INVOKE_AGENT,\n      },\n    },\n    Output: {\n      Messages: ATTR_GEN_AI_OUTPUT_MESSAGES,\n      Type: ATTR_GEN_AI_OUTPUT_TYPE,\n      Type_Values: {\n        Text: GEN_AI_OUTPUT_TYPE_VALUE_TEXT,\n        Json: GEN_AI_OUTPUT_TYPE_VALUE_JSON,\n        Image: GEN_AI_OUTPUT_TYPE_VALUE_IMAGE,\n        Speech: GEN_AI_OUTPUT_TYPE_VALUE_SPEECH,\n      },\n    },\n    /**\n     * The provider that is hosting the model, eg AWS Bedrock\n     * There doesn't seem to be a semconv for this\n     */\n    Request: {\n      ChoiceCount: ATTR_GEN_AI_REQUEST_CHOICE_COUNT, // not yet used by axiom-ai\n      EncodingFormats: ATTR_GEN_AI_REQUEST_ENCODING_FORMATS, // not yet used by axiom-ai\n      FrequencyPenalty: ATTR_GEN_AI_REQUEST_FREQUENCY_PENALTY,\n      MaxTokens: ATTR_GEN_AI_REQUEST_MAX_TOKENS,\n      /**\n       * The model you asked for\n       */\n      Model: ATTR_GEN_AI_REQUEST_MODEL,\n      PresencePenalty: ATTR_GEN_AI_REQUEST_PRESENCE_PENALTY,\n      Seed: ATTR_GEN_AI_REQUEST_SEED,\n      StopSequences: ATTR_GEN_AI_REQUEST_STOP_SEQUENCES,\n      Temperature: ATTR_GEN_AI_REQUEST_TEMPERATURE,\n      TopK: ATTR_GEN_AI_REQUEST_TOP_K,\n      TopP: ATTR_GEN_AI_REQUEST_TOP_P,\n    },\n    Response: {\n      FinishReasons: ATTR_GEN_AI_RESPONSE_FINISH_REASONS,\n      ID: ATTR_GEN_AI_RESPONSE_ID,\n      /**\n       * The model that was actually used (might be different bc routing) - only ever get this from the response, otherwise omit\n       */\n      Model: ATTR_GEN_AI_RESPONSE_MODEL, // somehow not landing on the span for google models? check up on this...\n    },\n    Tool: {\n      CallID: ATTR_GEN_AI_TOOL_CALL_ID,\n      Description: ATTR_GEN_AI_TOOL_DESCRIPTION,\n      Name: ATTR_GEN_AI_TOOL_NAME,\n      Type: ATTR_GEN_AI_TOOL_TYPE,\n      /**\n       * Note, OTel Semantic Convention suggest only putting tool inputs/outputs on the parent chat span\n       * But we at least want to give users THE OPTION to put them on the tool spans themselves as well\n       * Because it enables a lot of things with querying\n       * @see https://github.com/open-telemetry/semantic-conventions/releases/tag/v1.37.0\n       */\n      Arguments: ATTR_GEN_AI_TOOL_ARGUMENTS,\n      /**\n       * Note, OTel Semantic Convention suggest only putting tool inputs/outputs on the parent chat span\n       * But we at least want to give users THE OPTION to put them on the tool spans themselves as well\n       * Because it enables a lot of things with querying\n       * @see https://github.com/open-telemetry/semantic-conventions/releases/tag/v1.37.0\n       */\n      Message: ATTR_GEN_AI_TOOL_MESSAGE,\n    },\n    Usage: {\n      InputTokens: ATTR_GEN_AI_USAGE_INPUT_TOKENS,\n      OutputTokens: ATTR_GEN_AI_USAGE_OUTPUT_TOKENS,\n    },\n  },\n  Eval: {\n    ID: ATTR_EVAL_ID,\n    Name: ATTR_EVAL_NAME,\n    Version: ATTR_EVAL_VERSION,\n    Type: ATTR_EVAL_TYPE,\n    BaselineID: ATTR_EVAL_BASELINE_ID,\n    BaselineName: ATTR_EVAL_BASELINE_NAME,\n    Tags: ATTR_EVAL_TAGS,\n    Collection: {\n      ID: ATTR_EVAL_COLLECTION_ID,\n      Name: ATTR_EVAL_COLLECTION_NAME,\n      Size: ATTR_EVAL_COLLECTION_SIZE,\n    },\n    Case: {\n      Index: ATTR_EVAL_CASE_INDEX,\n      Input: ATTR_EVAL_CASE_INPUT,\n      Output: ATTR_EVAL_CASE_OUTPUT,\n      Expected: ATTR_EVAL_CASE_EXPECTED,\n      Scores: ATTR_EVAL_CASE_SCORES,\n      Metadata: ATTR_EVAL_CASE_METADATA,\n    },\n    Task: {\n      Output: ATTR_EVAL_TASK_OUTPUT,\n      Name: ATTR_EVAL_TASK_NAME,\n      Type: ATTR_EVAL_TASK_TYPE,\n    },\n    Score: {\n      Name: ATTR_EVAL_SCORE_NAME,\n      Value: ATTR_EVAL_SCORE_VALUE,\n      Threshold: ATTR_EVAL_SCORE_THRESHOLD,\n      Passed: ATTR_EVAL_SCORE_PASSED,\n      Metadata: ATTR_EVAL_SCORE_METADATA,\n    },\n    User: {\n      Name: ATTR_EVAL_USER_NAME,\n      Email: ATTR_EVAL_USER_EMAIL,\n    },\n  },\n  Error: {\n    Type: ATTR_ERROR_TYPE,\n    Message: ATTR_ERROR_MESSAGE,\n  },\n  HTTP: {\n    Response: {\n      StatusCode: ATTR_HTTP_RESPONSE_STATUS_CODE,\n    },\n  },\n} as const;\n","// experiment\nexport const ATTR_EVAL_ID = 'eval.id' as const;\nexport const ATTR_EVAL_NAME = 'eval.name' as const;\nexport const ATTR_EVAL_VERSION = 'eval.version' as const;\nexport const ATTR_EVAL_TYPE = 'eval.type' as const;\nexport const ATTR_EVAL_TAGS = 'eval.tags' as const;\nexport const ATTR_EVAL_BASELINE_ID = 'eval.baseline.id' as const;\nexport const ATTR_EVAL_BASELINE_NAME = 'eval.baseline.name' as const;\n// collection\nexport const ATTR_EVAL_COLLECTION_ID = 'eval.collection.id' as const;\nexport const ATTR_EVAL_COLLECTION_SIZE = 'eval.collection.size' as const;\nexport const ATTR_EVAL_COLLECTION_NAME = 'eval.collection.name' as const;\n// case\nexport const ATTR_EVAL_CASE_INDEX = 'eval.case.index' as const;\nexport const ATTR_EVAL_CASE_INPUT = 'eval.case.input' as const;\nexport const ATTR_EVAL_CASE_OUTPUT = 'eval.case.output' as const;\nexport const ATTR_EVAL_CASE_EXPECTED = 'eval.case.expected' as const;\nexport const ATTR_EVAL_CASE_SCORES = 'eval.case.scores' as const;\nexport const ATTR_EVAL_CASE_METADATA = 'eval.case.metadata' as const;\n// task\nexport const ATTR_EVAL_TASK_OUTPUT = 'eval.task.output' as const;\nexport const ATTR_EVAL_TASK_NAME = 'eval.task.name' as const;\nexport const ATTR_EVAL_TASK_TYPE = 'eval.task.type' as const;\n// score\nexport const ATTR_EVAL_SCORE_NAME = 'eval.score.name' as const;\nexport const ATTR_EVAL_SCORE_VALUE = 'eval.score.value' as const;\nexport const ATTR_EVAL_SCORE_THRESHOLD = 'eval.score.threshold' as const;\nexport const ATTR_EVAL_SCORE_PASSED = 'eval.score.passed' as const;\nexport const ATTR_EVAL_SCORE_SCORER = 'eval.score.scorer' as const;\nexport const ATTR_EVAL_SCORE_METADATA = 'eval.score.metadata' as const;\n// user\nexport const ATTR_EVAL_USER_NAME = 'eval.user.name';\nexport const ATTR_EVAL_USER_EMAIL = 'eval.user.email';\n","import { type Span, type SpanOptions, SpanStatusCode, type Tracer } from '@opentelemetry/api';\n\ninterface Callbacks {\n  onSuccess?: (span: Span) => void;\n  onError?: (error: unknown, span: Span) => void;\n  onFinally?: (span: Span) => void;\n}\n\nexport const createStartActiveSpan =\n  (tracer: Tracer) =>\n  async <T>(\n    name: string,\n    options: SpanOptions | null,\n    fn: (span: Span) => Promise<T>,\n    callbacks?: Callbacks,\n  ): Promise<T> => {\n    return tracer.startActiveSpan(name, { ...(options ?? {}) }, async (span) => {\n      try {\n        const result = await fn(span);\n\n        callbacks?.onSuccess?.(span);\n\n        return result;\n      } catch (error) {\n        callbacks?.onError?.(error, span);\n\n        if (error instanceof Error) {\n          span.recordException(error);\n          span.setStatus({\n            code: SpanStatusCode.ERROR,\n            message: error.message,\n          });\n        }\n\n        throw error;\n      } finally {\n        callbacks?.onFinally?.(span);\n        span.end();\n      }\n    });\n  };\n","import {\n  type LanguageModelV1,\n  type LanguageModelV1CallOptions,\n  type LanguageModelV1Prompt,\n  type LanguageModelV1StreamPart,\n} from '@ai-sdk/providerv1';\nimport {\n  type LanguageModelV2,\n  type LanguageModelV2CallOptions,\n  type LanguageModelV2Middleware,\n  type LanguageModelV2StreamPart,\n  type LanguageModelV2Content,\n  type LanguageModelV2ToolCall,\n  type LanguageModelV2Usage,\n  type LanguageModelV2ResponseMetadata,\n  type LanguageModelV2FinishReason,\n  type LanguageModelV2Prompt,\n} from '@ai-sdk/providerv2';\nimport { type LanguageModelV1Middleware } from 'aiv4';\n\nimport { type Span } from '@opentelemetry/api';\nimport { Attr } from './semconv/attributes';\nimport type { OpenAIMessage } from './vercelTypes';\nimport { createSimpleCompletion } from './completionUtils';\nimport {\n  appendToolCalls,\n  extractToolResultsFromPromptV2,\n  extractToolResultsFromRawPrompt,\n} from '../util/promptUtils';\nimport { sanitizeMultimodalContent } from './utils/contentSanitizer';\nimport {\n  setScopeAttributes,\n  setBaseAttributes,\n  setRequestParameterAttributes,\n  withSpanHandling,\n  determineOutputTypeV1,\n  determineOutputTypeV2,\n  createStreamChildSpan,\n  handleStreamError,\n  type CommonSpanContext,\n} from './utils/wrapperUtils';\nimport {\n  promptV1ToOpenAI,\n  promptV2ToOpenAI,\n  normalizeV1ToolCalls,\n  normalizeV2ToolCalls,\n} from './utils/normalized';\nimport {\n  ToolCallAggregator,\n  TextAggregator,\n  StreamStats,\n  ToolCallAggregatorV2,\n  TextAggregatorV2,\n  StreamStatsV2,\n} from './streaming/aggregators';\nimport type { AxiomPromptMetadata } from '../types/metadata';\nimport { getRedactionPolicy, handleMaybeRedactedAttribute } from './utils/redaction';\n\nexport interface AxiomTelemetryConfig {\n  // Future configuration options can be added here\n}\n\ninterface GenAiSpanContextV1 extends CommonSpanContext {\n  originalPrompt: OpenAIMessage[];\n  rawCall?: {\n    rawPrompt?: any[];\n    rawSettings?: any;\n  };\n}\n\ninterface GenAiSpanContextV2 extends CommonSpanContext {\n  originalPrompt: OpenAIMessage[];\n  originalV2Prompt: any[];\n}\n\nconst appendPromptMetadataToSpan = (\n  span: Span,\n  messages: LanguageModelV1Prompt | LanguageModelV2Prompt,\n) => {\n  const lastMessage = messages?.[messages.length - 1];\n\n  let axiomMeta: AxiomPromptMetadata | undefined;\n\n  if ('providerMetadata' in lastMessage) {\n    axiomMeta = lastMessage?.providerMetadata?._axiomMeta as AxiomPromptMetadata | undefined;\n  } else if ('providerOptions' in lastMessage) {\n    axiomMeta = lastMessage?.providerOptions?._axiomMeta as AxiomPromptMetadata | undefined;\n  }\n\n  if (axiomMeta) {\n    if (axiomMeta.id) span.setAttribute(Attr.GenAI.PromptMetadata.ID, axiomMeta.id);\n    if (axiomMeta.name) span.setAttribute(Attr.GenAI.PromptMetadata.Name, axiomMeta.name);\n    if (axiomMeta.slug) span.setAttribute(Attr.GenAI.PromptMetadata.Slug, axiomMeta.slug);\n    if (axiomMeta.version) span.setAttribute(Attr.GenAI.PromptMetadata.Version, axiomMeta.version);\n  }\n};\n\n/**\n * Creates Axiom telemetry middleware for LanguageModelV1\n */\nexport function axiomAIMiddlewareV1(/* _config?: AxiomTelemetryConfig */): LanguageModelV1Middleware {\n  return {\n    wrapGenerate: async ({ doGenerate, params, model }) => {\n      return withSpanHandling(model.modelId, async (span, commonContext) => {\n        const context: GenAiSpanContextV1 = {\n          ...commonContext,\n          originalPrompt: [],\n          rawCall: undefined,\n        };\n\n        appendPromptMetadataToSpan(span, params.prompt);\n\n        // Pre-call setup\n        setScopeAttributes(span);\n        setPreCallAttributesV1(span, params, context, model);\n\n        const res = await doGenerate();\n\n        // Store rawCall data in context for access in post-call processing\n        context.rawCall = res.rawCall as { rawPrompt?: any[]; rawSettings?: any };\n\n        // Post-call processing\n        await setPostCallAttributesV1(span, res, context, model);\n\n        return res;\n      });\n    },\n\n    wrapStream: async ({ doStream, params, model }) => {\n      return withSpanHandling(model.modelId, async (span, commonContext) => {\n        const context: GenAiSpanContextV1 = {\n          ...commonContext,\n          originalPrompt: [],\n          rawCall: undefined,\n        };\n\n        appendPromptMetadataToSpan(span, params.prompt);\n\n        // Pre-call setup\n        setScopeAttributes(span);\n        setPreCallAttributesV1(span, params, context, model);\n\n        const { stream, ...head } = await doStream();\n\n        // Create child span for stream processing\n        const childSpan = createStreamChildSpan(span, `chat ${model.modelId} stream`);\n\n        const stats = new StreamStats();\n        const toolAggregator = new ToolCallAggregator();\n        const textAggregator = new TextAggregator();\n\n        return {\n          ...head,\n          stream: stream.pipeThrough(\n            new TransformStream({\n              transform(chunk: LanguageModelV1StreamPart, controller) {\n                try {\n                  stats.feed(chunk);\n                  toolAggregator.handleChunk(chunk);\n                  textAggregator.feed(chunk);\n\n                  controller.enqueue(chunk);\n                } catch (err) {\n                  handleStreamError(childSpan, err);\n                  childSpan.end();\n                  controller.error(err);\n                }\n              },\n              async flush(controller) {\n                try {\n                  await setPostCallAttributesV1(\n                    span,\n                    {\n                      ...head,\n                      ...stats.result,\n                      toolCalls:\n                        toolAggregator.result.length > 0 ? toolAggregator.result : undefined,\n                      text: textAggregator.text,\n                    },\n                    context,\n                    model,\n                  );\n\n                  childSpan.end();\n                  controller.terminate();\n                } catch (err) {\n                  handleStreamError(childSpan, err);\n                  childSpan.end();\n                  controller.error(err);\n                }\n              },\n            }),\n          ),\n        };\n      });\n    },\n  };\n}\n\n/**\n * Creates unified Axiom telemetry middleware that works with both V1 and V2 models\n */\nexport function axiomAIMiddleware(config: { model: LanguageModelV1 }): LanguageModelV1Middleware;\nexport function axiomAIMiddleware(config: { model: LanguageModelV2 }): LanguageModelV2Middleware;\nexport function axiomAIMiddleware(config: { model: LanguageModelV1 | LanguageModelV2 }) {\n  if (config.model.specificationVersion === 'v1') {\n    return axiomAIMiddlewareV1();\n  } else if (config.model.specificationVersion === 'v2') {\n    return axiomAIMiddlewareV2();\n  } else {\n    console.warn(\n      // @ts-expect-error - not allowed at type level, but users can still do it...\n      `Unsupported model specification version: ${JSON.stringify(config.model.specificationVersion)}. Creating no-op middleware instead.`,\n    );\n    return {};\n  }\n}\n\n/**\n * Creates Axiom telemetry middleware for LanguageModelV2\n */\nexport function axiomAIMiddlewareV2(/* _config?: AxiomTelemetryConfig */): LanguageModelV2Middleware {\n  return {\n    wrapGenerate: async ({ doGenerate, params, model }) => {\n      return withSpanHandling(model.modelId, async (span, commonContext) => {\n        const context: GenAiSpanContextV2 = {\n          ...commonContext,\n          originalPrompt: [],\n          originalV2Prompt: [],\n        };\n\n        appendPromptMetadataToSpan(span, params.prompt);\n\n        // Pre-call setup\n        setScopeAttributes(span);\n        setPreCallAttributesV2(span, params, context, model);\n\n        const res = await doGenerate();\n\n        // Post-call processing\n        await setPostCallAttributesV2(span, res, context, model);\n\n        return res;\n      });\n    },\n\n    wrapStream: async ({ doStream, params, model }) => {\n      return withSpanHandling(model.modelId, async (span, commonContext) => {\n        const context: GenAiSpanContextV2 = {\n          ...commonContext,\n          originalPrompt: [],\n          originalV2Prompt: [],\n        };\n\n        appendPromptMetadataToSpan(span, params.prompt);\n\n        // Pre-call setup\n        setScopeAttributes(span);\n        setPreCallAttributesV2(span, params, context, model);\n\n        const ret = await doStream();\n\n        // Create child span for stream processing\n        const childSpan = createStreamChildSpan(span, `chat ${model.modelId} stream`);\n\n        const stats = new StreamStatsV2();\n        const toolAggregator = new ToolCallAggregatorV2();\n        const textAggregator = new TextAggregatorV2();\n\n        return {\n          ...ret,\n          stream: ret.stream.pipeThrough(\n            new TransformStream({\n              transform(chunk: LanguageModelV2StreamPart, controller) {\n                try {\n                  stats.feed(chunk);\n                  toolAggregator.handleChunk(chunk);\n                  textAggregator.feed(chunk);\n\n                  controller.enqueue(chunk);\n                } catch (err) {\n                  handleStreamError(childSpan, err);\n                  childSpan.end();\n                  controller.error(err);\n                }\n              },\n              async flush(controller) {\n                try {\n                  const streamResult = {\n                    ...stats.result,\n                    content: [\n                      ...(textAggregator.text\n                        ? [{ type: 'text' as const, text: textAggregator.text }]\n                        : []),\n                      ...toolAggregator.result,\n                    ],\n                  };\n\n                  await setPostCallAttributesV2(span, streamResult, context, model);\n\n                  childSpan.end();\n                  controller.terminate();\n                } catch (err) {\n                  handleStreamError(childSpan, err);\n                  childSpan.end();\n                  controller.error(err);\n                }\n              },\n            }),\n          ),\n        };\n      });\n    },\n  };\n}\n\n// V1 helper functions (extracted from AxiomWrappedLanguageModelV1)\nfunction setPreCallAttributesV1(\n  span: Span,\n  options: LanguageModelV1CallOptions,\n  context: GenAiSpanContextV1,\n  model: LanguageModelV1,\n) {\n  const redactionPolicy = getRedactionPolicy();\n\n  const {\n    prompt,\n    maxTokens,\n    frequencyPenalty,\n    presencePenalty,\n    temperature,\n    topP,\n    topK,\n    seed,\n    stopSequences,\n    responseFormat,\n    mode,\n  } = options;\n\n  // Set prompt attributes (full conversation history)\n  const processedPrompt = promptV1ToOpenAI(prompt);\n  context.originalPrompt = processedPrompt;\n\n  handleMaybeRedactedAttribute(\n    span,\n    Attr.GenAI.Input.Messages,\n    JSON.stringify(sanitizeMultimodalContent(processedPrompt)),\n    redactionPolicy.captureMessageContent,\n  );\n\n  setBaseAttributes(span, model.provider, model.modelId);\n\n  const outputType = determineOutputTypeV1({ responseFormat, mode });\n  if (outputType) {\n    span.setAttribute(Attr.GenAI.Output.Type, outputType);\n  }\n\n  setRequestParameterAttributes(span, {\n    maxTokens,\n    frequencyPenalty,\n    presencePenalty,\n    temperature,\n    topP,\n    topK,\n    seed,\n    stopSequences,\n  });\n}\n\nasync function setPostCallAttributesV1(\n  span: Span,\n  result: any,\n  context: GenAiSpanContextV1,\n  _model: LanguageModelV1,\n) {\n  const redactionPolicy = getRedactionPolicy();\n\n  // Update prompt to include tool calls and tool results if they exist\n  if (result.toolCalls && result.toolCalls.length > 0) {\n    const originalPrompt = context.originalPrompt || [];\n\n    // Normalize the tool calls to the common format\n    const normalizedToolCalls = normalizeV1ToolCalls(result.toolCalls);\n\n    // Note: rawCall might not be available in middleware, handle gracefully\n    const toolResultsMap = context.rawCall?.rawPrompt\n      ? extractToolResultsFromRawPrompt(context.rawCall.rawPrompt as any[])\n      : new Map();\n\n    const updatedPrompt = appendToolCalls(\n      originalPrompt,\n      normalizedToolCalls,\n      toolResultsMap,\n      result.text,\n    );\n\n    handleMaybeRedactedAttribute(\n      span,\n      Attr.GenAI.Input.Messages,\n      JSON.stringify(sanitizeMultimodalContent(updatedPrompt)),\n      redactionPolicy.captureMessageContent,\n    );\n  }\n\n  // Create simple completion array with just assistant text\n  if (result.text) {\n    const completion = createSimpleCompletion({\n      text: result.text,\n    });\n    handleMaybeRedactedAttribute(\n      span,\n      Attr.GenAI.Output.Messages,\n      JSON.stringify(completion),\n      redactionPolicy.captureMessageContent,\n    );\n  }\n\n  if (result.response?.id) {\n    span.setAttribute(Attr.GenAI.Response.ID, result.response.id);\n  }\n  if (result.response?.modelId) {\n    span.setAttribute(Attr.GenAI.Response.Model, result.response.modelId);\n  }\n\n  if (result.usage?.promptTokens) {\n    if (Number.isNaN(result.usage.promptTokens)) {\n      console.warn(\n        'usage.promptTokens is NaN. You might need to enable `compatibility: strict`. See: https://github.com/vercel/ai/discussions/1882',\n        result.usage.promptTokens,\n      );\n    } else {\n      span.setAttribute(Attr.GenAI.Usage.InputTokens, result.usage.promptTokens);\n    }\n  }\n\n  if (result.usage?.completionTokens) {\n    if (Number.isNaN(result.usage.completionTokens)) {\n      console.warn(\n        'usage.completionTokens is NaN. You might need to enable `compatibility: strict`. See: https://github.com/vercel/ai/discussions/1882',\n        result.usage.completionTokens,\n      );\n    } else {\n      span.setAttribute(Attr.GenAI.Usage.OutputTokens, result.usage.completionTokens);\n    }\n  }\n\n  if (result.finishReason) {\n    span.setAttribute(Attr.GenAI.Response.FinishReasons, JSON.stringify([result.finishReason]));\n  }\n}\n\n// V2 helper functions (extracted from AxiomWrappedLanguageModelV2)\nfunction setPreCallAttributesV2(\n  span: Span,\n  options: LanguageModelV2CallOptions,\n  context: GenAiSpanContextV2,\n  model: LanguageModelV2,\n) {\n  const redactionPolicy = getRedactionPolicy();\n\n  setBaseAttributes(span, model.provider, model.modelId);\n\n  const outputType = determineOutputTypeV2(options);\n  if (outputType) {\n    span.setAttribute(Attr.GenAI.Output.Type, outputType);\n  }\n\n  setRequestParameterAttributes(span, {\n    maxTokens: options.maxOutputTokens,\n    frequencyPenalty: options.frequencyPenalty,\n    presencePenalty: options.presencePenalty,\n    temperature: options.temperature,\n    topP: options.topP,\n    topK: options.topK,\n    seed: options.seed,\n    stopSequences: options.stopSequences,\n  });\n\n  const processedPrompt = promptV2ToOpenAI(options.prompt);\n\n  // Store both the original V2 prompt and processed prompt for later use\n  context.originalV2Prompt = options.prompt;\n  context.originalPrompt = processedPrompt;\n\n  handleMaybeRedactedAttribute(\n    span,\n    Attr.GenAI.Input.Messages,\n    JSON.stringify(sanitizeMultimodalContent(processedPrompt)),\n    redactionPolicy.captureMessageContent,\n  );\n}\n\nasync function setPostCallAttributesV2(\n  span: Span,\n  result: {\n    response?: LanguageModelV2ResponseMetadata;\n    finishReason?: LanguageModelV2FinishReason;\n    usage?: LanguageModelV2Usage;\n    content?: Array<LanguageModelV2Content>;\n  },\n  context: GenAiSpanContextV2,\n  _model: LanguageModelV2,\n) {\n  const redactionPolicy = getRedactionPolicy();\n\n  // Check if we have tool calls in this response\n  const toolCalls = result.content?.filter(\n    (c) => c.type === 'tool-call',\n  ) as LanguageModelV2ToolCall[];\n\n  // Only set response metadata once per span to prevent overwriting when generateText() makes multiple calls\n  const alreadySet = (span as any).attributes?.[Attr.GenAI.Response.FinishReasons] !== undefined;\n\n  if (!alreadySet) {\n    if (result.response?.id) {\n      span.setAttribute(Attr.GenAI.Response.ID, result.response.id);\n    }\n    if (result.response?.modelId) {\n      span.setAttribute(Attr.GenAI.Response.Model, result.response.modelId);\n    }\n\n    if (result.usage?.inputTokens !== undefined) {\n      span.setAttribute(Attr.GenAI.Usage.InputTokens, result.usage.inputTokens);\n    }\n    if (result.usage?.outputTokens !== undefined) {\n      span.setAttribute(Attr.GenAI.Usage.OutputTokens, result.usage.outputTokens);\n    }\n  }\n\n  // Update prompt to include tool calls and tool results if they exist\n  if (toolCalls && toolCalls.length > 0) {\n    const originalPrompt = context.originalPrompt || [];\n\n    const normalizedToolCalls = normalizeV2ToolCalls(toolCalls);\n\n    // Extract real tool results from the original V2 prompt structure\n    const toolResultsMap = extractToolResultsFromPromptV2(context.originalV2Prompt || []);\n\n    // Extract assistant text content from the response\n    const textContent = result.content?.find((c) => c.type === 'text');\n    const assistantText = textContent?.type === 'text' ? textContent.text : undefined;\n\n    // Use the standard prompt utility to append tool calls\n    const updatedPrompt = appendToolCalls(\n      originalPrompt,\n      normalizedToolCalls,\n      toolResultsMap,\n      assistantText,\n    );\n\n    // Update the prompt attribute with the complete conversation history\n    handleMaybeRedactedAttribute(\n      span,\n      Attr.GenAI.Input.Messages,\n      JSON.stringify(sanitizeMultimodalContent(updatedPrompt)),\n      redactionPolicy.captureMessageContent,\n    );\n  }\n\n  // Process tool calls and create child spans\n  if (result.content && result.content.length > 0) {\n    await processToolCallsAndCreateSpansV2(span, result.content);\n  } else if (result.finishReason) {\n    // For non-tool responses, still create completion array\n    const completion = createSimpleCompletion({\n      text: '',\n    });\n    handleMaybeRedactedAttribute(\n      span,\n      Attr.GenAI.Output.Messages,\n      JSON.stringify(completion),\n      redactionPolicy.captureMessageContent,\n    );\n  }\n\n  // Store finish reason separately as per semantic conventions (only on first call to prevent overwriting)\n  if (result.finishReason && !alreadySet) {\n    span.setAttribute(Attr.GenAI.Response.FinishReasons, JSON.stringify([result.finishReason]));\n  }\n}\n\nasync function processToolCallsAndCreateSpansV2(\n  parentSpan: Span,\n  content: Array<LanguageModelV2Content>,\n): Promise<void> {\n  const redactionPolicy = getRedactionPolicy();\n\n  // Extract text and tool calls from content\n  const textContent = content.find((c) => c.type === 'text');\n  const assistantText = textContent?.type === 'text' ? textContent.text : undefined;\n  const toolCalls = content.filter((c) => c.type === 'tool-call') as LanguageModelV2ToolCall[];\n\n  // Only set completion for final responses without tool calls\n  if (toolCalls.length === 0) {\n    // Create completion with multimodal content support\n    const completion = [\n      {\n        role: 'assistant' as const,\n        content: sanitizeMultimodalContent(\n          content.length === 1 && assistantText ? assistantText : content,\n        ),\n      },\n    ];\n\n    // Set completion array as span attribute\n    handleMaybeRedactedAttribute(\n      parentSpan,\n      Attr.GenAI.Output.Messages,\n      JSON.stringify(completion),\n      redactionPolicy.captureMessageContent,\n    );\n  }\n}\n","/**\n * Utilities for sanitizing multimodal content in telemetry data\n * Replaces large binary content with metadata while preserving structure\n */\n\nimport { createHash } from 'crypto';\n\ninterface ImageMetadata {\n  format?: string;\n  size_bytes?: number;\n  hash: string;\n  is_data_url: boolean;\n  dimensions?: string;\n}\n\n/**\n * Extracts metadata from an image URL (data URL or external URL)\n */\nfunction extractImageMetadata(url: string): ImageMetadata {\n  if (url.startsWith('data:')) {\n    // Parse data URL: data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQ...\n    const [header, base64Data] = url.split(',');\n    const formatMatch = header.match(/data:image\\/(\\w+)/);\n    const format = formatMatch?.[1];\n\n    // Estimate size from base64 data\n    const sizeBytes = base64Data ? Math.floor((base64Data.length * 3) / 4) : 0;\n\n    // Create a short hash of the content for identification\n    const hash = base64Data\n      ? createHash('sha256').update(base64Data).digest('hex').slice(0, 16)\n      : 'unknown';\n\n    return {\n      format,\n      size_bytes: sizeBytes,\n      hash,\n      is_data_url: true,\n    };\n  } else {\n    // External URL - create hash of the URL itself\n    const hash = createHash('sha256').update(url).digest('hex').slice(0, 16);\n    return {\n      hash,\n      is_data_url: false,\n    };\n  }\n}\n\n/**\n * Sanitizes an image URL by replacing large data URLs with metadata\n */\nfunction sanitizeImageUrl(url: string, detail?: string) {\n  const metadata = extractImageMetadata(url);\n\n  if (metadata.is_data_url) {\n    // Replace data URL with reference\n    const formatPart = metadata.format ? `:${metadata.format}` : '';\n    const sizePart = metadata.size_bytes ? `:${metadata.size_bytes}b` : '';\n    return {\n      url: `[IMAGE${formatPart}${sizePart}:${metadata.hash}]`,\n      detail,\n      ...metadata,\n    };\n  } else {\n    // Keep external URLs but add metadata\n    return {\n      url,\n      detail,\n      ...metadata,\n    };\n  }\n}\n\ntype SanitizedContent<T> = T extends readonly unknown[] ? unknown[] : T;\n\n/**\n * Sanitizes any multimodal content for telemetry purposes\n * This is the main function that should be used throughout the codebase\n */\nexport function sanitizeMultimodalContent<T>(content: T): SanitizedContent<T> {\n  if (Array.isArray(content)) {\n    return content.map((part) => {\n      if (part && typeof part === 'object' && 'type' in part && part.type === 'image_url') {\n        const imagePart = part;\n        if (imagePart.image_url?.url) {\n          return {\n            ...part,\n            image_url: sanitizeImageUrl(imagePart.image_url.url, imagePart.image_url.detail),\n          };\n        }\n      }\n      return part;\n    }) as SanitizedContent<T>;\n  }\n\n  return content as SanitizedContent<T>;\n}\n","/**\n * Utility functions for formatting tool calls in completion array format\n */\n\nimport type { LanguageModelV1FunctionToolCall } from '@ai-sdk/providerv1';\nimport { sanitizeMultimodalContent } from './utils/contentSanitizer';\nimport type {\n  CompletionArray,\n  FormatToolCallsOptions,\n  FormattedCompletionResult,\n} from './completionTypes';\nimport type { OpenAIMessage, OpenAIAssistantMessage, OpenAIToolMessage } from './vercelTypes';\n\n/**\n * Converts OpenAI messages to completion array format\n */\nfunction convertToCompletionMessages(messages: OpenAIMessage[]): OpenAIMessage[] {\n  return messages.map((message): OpenAIMessage => {\n    switch (message.role) {\n      case 'system':\n        return {\n          role: 'system',\n          content: message.content,\n        };\n\n      case 'user':\n        return {\n          role: 'user',\n          content: sanitizeMultimodalContent(message.content) as string | any[],\n        };\n\n      case 'assistant':\n        return {\n          role: 'assistant',\n          content: sanitizeMultimodalContent(message.content) as string | null,\n          tool_calls: message.tool_calls?.map((toolCall) => ({\n            id: toolCall.id,\n            type: 'function' as const,\n            function: {\n              name: toolCall.function.name,\n              arguments: toolCall.function.arguments,\n            },\n          })),\n        };\n\n      case 'tool':\n        return {\n          role: 'tool',\n          content: message.content,\n          tool_call_id: message.tool_call_id,\n        };\n\n      default:\n        throw new Error(`Unknown message role: ${(message as any).role}`);\n    }\n  });\n}\n\n/**\n * Creates tool result messages from tool execution results\n */\nfunction createToolResultMessages(\n  toolResults: Array<{\n    toolCallId: string;\n    result: unknown;\n  }>,\n): OpenAIToolMessage[] {\n  return toolResults.map((result) => ({\n    role: 'tool' as const,\n    content: typeof result.result === 'string' ? result.result : JSON.stringify(result.result),\n    tool_call_id: result.toolCallId,\n  }));\n}\n\n/**\n * Main function to format tool calls in completion array format\n * Transforms AI SDK tool calls into the completion array structure\n */\nexport function formatToolCallsInCompletion(\n  options: FormatToolCallsOptions,\n): FormattedCompletionResult {\n  const { promptMessages = [], text, toolCalls = [], toolResults = [] } = options;\n\n  // Convert prompt messages to completion format\n  const historyMessages = convertToCompletionMessages(promptMessages);\n\n  // Create assistant message with tool calls\n  const assistantMessage: OpenAIAssistantMessage = {\n    role: 'assistant',\n    content: text ?? (toolCalls.length > 0 ? null : ''),\n  };\n\n  // Add tool calls if present\n  if (toolCalls.length > 0) {\n    assistantMessage.tool_calls = toolCalls.map((toolCall) => ({\n      id: toolCall.id,\n      type: 'function' as const,\n      function: {\n        name: toolCall.toolName,\n        arguments: toolCall.args,\n      },\n    }));\n  }\n\n  // Create tool result messages\n  const toolMessages = createToolResultMessages(toolResults);\n\n  // Build complete completion array\n  const completion: CompletionArray = [...historyMessages, assistantMessage, ...toolMessages];\n\n  return {\n    completion,\n    assistantMessage,\n    toolMessages,\n  };\n}\n\n/**\n * Creates a simple completion array with just assistant text response\n * Used for V1 model wrapper where tool calls are handled separately\n */\nexport function createSimpleCompletion({ text }: { text?: string }): CompletionArray {\n  // Create assistant message with text only\n  const assistantMessage: OpenAIAssistantMessage = {\n    role: 'assistant',\n    content: text ?? '',\n  };\n\n  return [assistantMessage];\n}\n\n/**\n * Formats V2 tool calls for completion array\n * Convenience function for V2 model wrapper\n */\nexport function formatV2ToolCallsInCompletion({\n  promptMessages = [],\n  text,\n  toolCalls = [],\n}: {\n  promptMessages?: OpenAIMessage[];\n  text?: string;\n  toolCalls?: Array<{\n    toolCallId: string;\n    toolName: string;\n    args: unknown;\n  }>;\n}): CompletionArray {\n  // Convert prompt messages\n  const historyMessages = convertToCompletionMessages(promptMessages);\n\n  // Create assistant message\n  const assistantMessage: OpenAIAssistantMessage = {\n    role: 'assistant',\n    content: text ?? (toolCalls.length > 0 ? null : ''),\n  };\n\n  // Add tool calls if present\n  if (toolCalls.length > 0) {\n    assistantMessage.tool_calls = toolCalls.map((toolCall) => ({\n      id: toolCall.toolCallId,\n      type: 'function' as const,\n      function: {\n        name: toolCall.toolName,\n        arguments:\n          typeof toolCall.args === 'string' ? toolCall.args : JSON.stringify(toolCall.args),\n      },\n    }));\n  }\n\n  return [...historyMessages, assistantMessage];\n}\n\n/**\n * Aggregates tool call chunks for streaming responses\n * Handles partial tool calls and builds complete tool call objects\n */\nexport function aggregateStreamingToolCalls(\n  chunks: Array<{\n    toolCallId?: string;\n    toolName?: string;\n    argsTextDelta?: string;\n  }>,\n): LanguageModelV1FunctionToolCall[] {\n  const toolCallMap = new Map<\n    string,\n    {\n      toolCallId: string;\n      toolName: string;\n      args: string;\n    }\n  >();\n\n  for (const chunk of chunks) {\n    if (!chunk.toolCallId) continue;\n\n    const existing = toolCallMap.get(chunk.toolCallId);\n    if (existing) {\n      // Append args delta\n      existing.args += chunk.argsTextDelta || '';\n    } else {\n      // Create new tool call entry\n      toolCallMap.set(chunk.toolCallId, {\n        toolCallId: chunk.toolCallId,\n        toolName: chunk.toolName || '',\n        args: chunk.argsTextDelta || '',\n      });\n    }\n  }\n\n  return Array.from(toolCallMap.values()).map((call) => ({\n    ...call,\n    toolCallType: 'function' as const,\n  }));\n}\n","import type { LanguageModelV1FunctionToolCall } from '@ai-sdk/providerv1';\nimport type { NormalizedToolCall } from '../otel/utils/normalized';\nimport type { LanguageModelV2Prompt } from '@ai-sdk/providerv2';\nimport type { OpenAIMessage } from '../otel/vercelTypes';\n\nexport type ToolResultMap = Map<string, unknown>;\n\n/**\n * Appends tool calls and their results to a conversation prompt.\n *\n * This function takes an existing conversation prompt and adds:\n * 1. An assistant message containing the tool calls\n * 2. Tool result messages for each tool call with results\n *\n * @param prompt - The existing conversation prompt\n * @param toolCalls - The tool calls made by the assistant\n * @param toolResults - Map of tool names to their results\n * @param assistantContent - Optional assistant message content to include with tool calls\n * @returns Updated prompt with tool calls and results appended\n */\nexport function appendToolCalls(\n  prompt: OpenAIMessage[],\n  toolCalls: LanguageModelV1FunctionToolCall[] | NormalizedToolCall[],\n  toolResults: ToolResultMap,\n  assistantContent?: string | null,\n): OpenAIMessage[] {\n  const updatedPrompt = [...prompt];\n\n  // Add assistant message with tool calls\n  updatedPrompt.push({\n    role: 'assistant',\n    content: assistantContent || null,\n    tool_calls: toolCalls.map((toolCall) => ({\n      id: toolCall.toolCallId,\n      function: {\n        name: toolCall.toolName,\n        arguments:\n          typeof toolCall.args === 'string' ? toolCall.args : JSON.stringify(toolCall.args),\n      },\n      type: 'function',\n    })),\n  });\n\n  // Add tool result messages with real data\n  for (const toolCall of toolCalls) {\n    const realToolResult = toolResults.get(toolCall.toolName);\n\n    if (realToolResult) {\n      updatedPrompt.push({\n        role: 'tool',\n        tool_call_id: toolCall.toolCallId,\n        content: JSON.stringify(realToolResult),\n      });\n    }\n  }\n\n  return updatedPrompt;\n}\n\n/**\n * Extracts tool results from a raw prompt array.\n *\n * Searches through different message formats to find tool results:\n * - Google AI format: user messages with functionResponse parts\n * - OpenAI format: tool role messages (future enhancement)\n *\n * @param rawPrompt - The raw prompt array from the model provider\n * @returns Map of tool names to their results\n */\n// TODO: @cje - This should be typed based on the specific provider's raw prompt format\n// but it needs to handle multiple providers (Google AI, OpenAI, etc.)\nexport function extractToolResultsFromRawPrompt(rawPrompt: any[]): Map<string, unknown> {\n  const toolResultsMap = new Map<string, unknown>();\n\n  if (!Array.isArray(rawPrompt)) {\n    return toolResultsMap;\n  }\n\n  // Look for tool results in different message formats\n  for (const message of rawPrompt) {\n    // Google AI format: user message with functionResponse parts\n    if (message?.role === 'user' && Array.isArray(message.parts)) {\n      for (const part of message.parts) {\n        if (part?.functionResponse) {\n          const functionResponse = part.functionResponse;\n          if (functionResponse.name && functionResponse.response) {\n            // Store by function name since that's what we have access to\n            toolResultsMap.set(\n              functionResponse.name,\n              functionResponse.response.content || functionResponse.response,\n            );\n          }\n        }\n      }\n    }\n\n    // OpenAI format: tool role messages with tool_call_id\n    if (message?.role === 'tool' && message?.tool_call_id && message?.content) {\n      // For OpenAI format, we'd need to map back from tool_call_id to tool name\n      // This is more complex as we'd need to track the tool calls first\n      // For now, we'll skip this but it could be implemented later\n    }\n  }\n\n  return toolResultsMap;\n}\n\n/**\n * Extracts tool results from a V2 prompt structure.\n *\n * V2 prompts use a \"parts\" array structure where:\n * - Tool calls are in assistant messages as 'tool-call' parts\n * - Tool results are in 'tool' role messages as 'tool-result' parts with 'output' property\n *\n * @param prompt - The V2 prompt array\n * @returns Map of tool names to their results\n */\nexport function extractToolResultsFromPromptV2(\n  prompt: LanguageModelV2Prompt,\n): Map<string, unknown> {\n  const idToName = new Map<string, string>();\n  const results = new Map<string, unknown>();\n\n  // 1. Collect tool-call ids → names from assistant messages\n  for (const message of prompt) {\n    if (message.role === 'assistant' && Array.isArray(message.content)) {\n      for (const part of message.content) {\n        if (part.type === 'tool-call') {\n          idToName.set(part.toolCallId, part.toolName);\n        }\n      }\n    }\n  }\n\n  // 2. Collect tool results from tool role messages\n  for (const message of prompt) {\n    if (message.role === 'tool' && Array.isArray(message.content)) {\n      for (const part of message.content) {\n        // In V2, tool result parts have toolCallId and result properties\n        if (part.toolCallId && part.output !== undefined) {\n          const toolName = idToName.get(part.toolCallId);\n          if (toolName) {\n            results.set(toolName, part.output);\n          }\n        }\n      }\n    }\n  }\n\n  return results;\n}\n","import type {\n  LanguageModelV1Prompt,\n  LanguageModelV1FunctionToolCall,\n  LanguageModelV1TextPart,\n  LanguageModelV1ToolCallPart,\n} from '@ai-sdk/providerv1';\nimport type {\n  LanguageModelV2Prompt,\n  LanguageModelV2ToolCall,\n  LanguageModelV2TextPart,\n  LanguageModelV2ToolCallPart,\n  LanguageModelV2ToolResultOutput,\n} from '@ai-sdk/providerv2';\nimport type { OpenAIMessage, OpenAIContentPart } from '../vercelTypes';\n\n/**\n * Normalized tool call interface that can represent both V1 and V2 tool calls\n */\nexport interface NormalizedToolCall {\n  toolCallId: string;\n  toolName: string;\n  args: string; // Always a JSON string for consistency\n  toolCallType: 'function';\n}\n\n/**\n * Normalized result interface for both V1 and V2 generation results\n */\nexport interface NormalizedResult {\n  text?: string;\n  toolCalls?: NormalizedToolCall[];\n  response?: { id?: string; modelId?: string };\n  usage?: {\n    promptTokens?: number;\n    completionTokens?: number;\n    inputTokens?: number;\n    outputTokens?: number;\n  };\n  finishReason?: string;\n}\n\n/**\n * Normalizes a V1 tool call to the common format\n */\nfunction normalizeV1ToolCall(toolCall: LanguageModelV1FunctionToolCall): NormalizedToolCall {\n  return {\n    toolCallId: toolCall.toolCallId,\n    toolName: toolCall.toolName,\n    args: typeof toolCall.args === 'string' ? toolCall.args : JSON.stringify(toolCall.args),\n    toolCallType: 'function',\n  };\n}\n\n/**\n * Normalizes a V2 tool call to the common format\n */\nfunction normalizeV2ToolCall(toolCall: LanguageModelV2ToolCall): NormalizedToolCall {\n  return {\n    toolCallId: toolCall.toolCallId,\n    toolName: toolCall.toolName,\n    args:\n      typeof toolCall.input === 'string'\n        ? toolCall.input.replace(/:\\s+/g, ':')\n        : JSON.stringify(toolCall.input),\n    toolCallType: 'function',\n  };\n}\n\n/**\n * Normalizes an array of V1 tool calls\n */\nexport function normalizeV1ToolCalls(\n  toolCalls: LanguageModelV1FunctionToolCall[],\n): NormalizedToolCall[] {\n  return toolCalls.map(normalizeV1ToolCall);\n}\n\n/**\n * Normalizes an array of V2 tool calls\n */\nexport function normalizeV2ToolCalls(toolCalls: LanguageModelV2ToolCall[]): NormalizedToolCall[] {\n  return toolCalls.map(normalizeV2ToolCall);\n}\n\n/**\n * Converts a V1 prompt to OpenAI message format\n */\nexport function promptV1ToOpenAI(prompt: LanguageModelV1Prompt): OpenAIMessage[] {\n  const results: OpenAIMessage[] = [];\n\n  for (const message of prompt) {\n    switch (message.role) {\n      case 'system':\n        results.push({\n          role: 'system',\n          content: message.content,\n        });\n        break;\n\n      case 'assistant':\n        const textPart = message.content.find((part) => part.type === 'text') as\n          | LanguageModelV1TextPart\n          | undefined;\n        const toolCallParts = message.content.filter(\n          (part) => part.type === 'tool-call',\n        ) as LanguageModelV1ToolCallPart[];\n\n        results.push({\n          role: 'assistant',\n          content: textPart?.text || null,\n          ...(toolCallParts.length > 0\n            ? {\n                tool_calls: toolCallParts.map((part) => ({\n                  id: part.toolCallId,\n                  function: {\n                    name: part.toolName,\n                    arguments: JSON.stringify(part.args),\n                  },\n                  type: 'function',\n                })),\n              }\n            : {}),\n        });\n        break;\n\n      case 'user':\n        results.push({\n          role: 'user',\n          content: message.content.map((part): OpenAIContentPart => {\n            switch (part.type) {\n              case 'text':\n                return {\n                  type: 'text',\n                  text: part.text,\n                };\n              case 'image':\n                return {\n                  type: 'image_url',\n                  image_url: {\n                    url: part.image.toString(),\n                  },\n                };\n              default:\n                // Convert unknown content types to text for compatibility\n                return {\n                  type: 'text',\n                  text:\n                    `[${part.type}]` +\n                    (typeof part === 'object' && part !== null\n                      ? JSON.stringify(part)\n                      : String(part)),\n                };\n            }\n          }),\n        });\n        break;\n\n      case 'tool':\n        for (const part of message.content) {\n          results.push({\n            role: 'tool',\n            tool_call_id: part.toolCallId,\n            content: JSON.stringify(part.result),\n          });\n        }\n        break;\n    }\n  }\n\n  return results;\n}\n\n/**\n * Converts a V2 prompt to OpenAI message format\n */\nexport function promptV2ToOpenAI(prompt: LanguageModelV2Prompt): OpenAIMessage[] {\n  const results: OpenAIMessage[] = [];\n\n  for (const message of prompt) {\n    switch (message.role) {\n      case 'system':\n        results.push({\n          role: 'system',\n          content: message.content,\n        });\n        break;\n\n      case 'assistant':\n        const textContent = message.content.find(\n          (part): part is LanguageModelV2TextPart => part.type === 'text',\n        );\n        const toolCalls = message.content.filter(\n          (part): part is LanguageModelV2ToolCallPart => part.type === 'tool-call',\n        );\n\n        results.push({\n          role: 'assistant',\n          content: textContent?.text || null,\n          ...(toolCalls.length > 0\n            ? {\n                tool_calls: toolCalls.map((part) => ({\n                  id: part.toolCallId,\n                  function: {\n                    name: part.toolName,\n                    arguments:\n                      typeof part.input === 'string' ? part.input : JSON.stringify(part.input),\n                  },\n                  type: 'function',\n                })),\n              }\n            : {}),\n        });\n        break;\n\n      case 'user':\n        results.push({\n          role: 'user',\n          content: message.content.map((part: any) => {\n            switch (part.type) {\n              case 'text':\n                return {\n                  type: 'text',\n                  text: part.text,\n                };\n              case 'image':\n                return {\n                  type: 'image_url',\n                  image_url: {\n                    url: part.image.toString(),\n                  },\n                };\n              default:\n                // Handle unknown content types by passing them through\n                return part as any;\n            }\n          }),\n        });\n        break;\n\n      case 'tool':\n        for (const part of message.content) {\n          results.push({\n            role: 'tool',\n            tool_call_id: part.toolCallId,\n            content: formatV2ToolCallOutput(part.output),\n          });\n        }\n        break;\n    }\n  }\n\n  return results;\n}\n\nfunction formatV2ToolCallOutput(output: LanguageModelV2ToolResultOutput) {\n  switch (output.type) {\n    case 'text':\n      return output.value;\n    case 'json':\n      return typeof output.value === 'string' ? output.value : JSON.stringify(output.value);\n    case 'error-text':\n      return output.value;\n    case 'error-json':\n      return typeof output.value === 'string' ? output.value : JSON.stringify(output.value);\n    case 'content':\n      return JSON.stringify(output.value);\n  }\n}\n","export function currentUnixTime(): number {\n  return Date.now() / 1000;\n}\n","import {\n  type LanguageModelV1StreamPart,\n  type LanguageModelV1FunctionToolCall,\n  type LanguageModelV1FinishReason,\n} from '@ai-sdk/providerv1';\n\nimport {\n  type LanguageModelV2StreamPart,\n  type LanguageModelV2ToolCall,\n  type LanguageModelV2FinishReason,\n  type LanguageModelV2Usage,\n  type LanguageModelV2ResponseMetadata,\n} from '@ai-sdk/providerv2';\n\nimport { currentUnixTime } from '../../util/currentUnixTime';\n\n// V1-specific aggregators (the original ones)\nexport class ToolCallAggregator {\n  private readonly calls: Record<string, LanguageModelV1FunctionToolCall> = {};\n\n  handleChunk(chunk: LanguageModelV1StreamPart): void {\n    switch (chunk.type) {\n      case 'tool-call':\n        this.calls[chunk.toolCallId] = {\n          toolCallType: chunk.toolCallType,\n          toolCallId: chunk.toolCallId,\n          toolName: chunk.toolName,\n          args: chunk.args,\n        };\n        break;\n      case 'tool-call-delta':\n        if (!this.calls[chunk.toolCallId]) {\n          this.calls[chunk.toolCallId] = {\n            toolCallType: chunk.toolCallType,\n            toolCallId: chunk.toolCallId,\n            toolName: chunk.toolName,\n            args: '',\n          };\n        }\n        this.calls[chunk.toolCallId].args += chunk.argsTextDelta;\n        break;\n    }\n  }\n\n  get result(): LanguageModelV1FunctionToolCall[] {\n    return Object.values(this.calls);\n  }\n}\n\nexport class TextAggregator {\n  private content = '';\n\n  feed(chunk: LanguageModelV1StreamPart): void {\n    if (chunk.type === 'text-delta') {\n      this.content += chunk.textDelta;\n    }\n  }\n\n  get text(): string | undefined {\n    return this.content || undefined;\n  }\n}\n\nexport class StreamStats {\n  private startTime: number;\n  private timeToFirstToken?: number;\n  private _usage?: { promptTokens: number; completionTokens: number };\n  private _finishReason?: LanguageModelV1FinishReason;\n  private _responseId?: string;\n  private _responseModelId?: string;\n\n  constructor() {\n    this.startTime = currentUnixTime();\n  }\n\n  feed(chunk: LanguageModelV1StreamPart): void {\n    // Track time to first token on any chunk\n    if (this.timeToFirstToken === undefined) {\n      this.timeToFirstToken = currentUnixTime() - this.startTime;\n    }\n\n    switch (chunk.type) {\n      case 'response-metadata':\n        if (chunk.id) {\n          this._responseId = chunk.id;\n        }\n        if (chunk.modelId) {\n          this._responseModelId = chunk.modelId;\n        }\n\n        break;\n      case 'finish':\n        this._usage = chunk.usage;\n        this._finishReason = chunk.finishReason;\n        break;\n    }\n  }\n\n  get result() {\n    return {\n      response:\n        this._responseId || this._responseModelId\n          ? {\n              id: this._responseId,\n              modelId: this._responseModelId,\n            }\n          : undefined,\n      finishReason: this._finishReason,\n      usage: this._usage,\n    };\n  }\n\n  get firstTokenTime(): number | undefined {\n    return this.timeToFirstToken;\n  }\n}\n\n// V2-specific aggregators\nexport class ToolCallAggregatorV2 {\n  private readonly calls: Record<string, LanguageModelV2ToolCall> = {};\n\n  handleChunk(chunk: LanguageModelV2StreamPart): void {\n    if (chunk.type === 'tool-call') {\n      this.calls[chunk.toolCallId] = chunk;\n    }\n  }\n\n  get result(): LanguageModelV2ToolCall[] {\n    return Object.values(this.calls);\n  }\n}\n\nexport class TextAggregatorV2 {\n  private content = '';\n\n  feed(chunk: LanguageModelV2StreamPart): void {\n    // TODO: @cje - is this enough?\n    switch (chunk.type) {\n      case 'text-start':\n        this.content = '';\n        break;\n      case 'text-delta':\n        this.content += chunk.delta;\n        break;\n      case 'text-end':\n        break;\n    }\n  }\n\n  get text(): string | undefined {\n    return this.content || undefined;\n  }\n}\n\nexport class StreamStatsV2 {\n  private startTime: number;\n  private timeToFirstToken?: number;\n  private _usage?: LanguageModelV2Usage;\n  private _finishReason?: LanguageModelV2FinishReason;\n  private _responseMetadata?: LanguageModelV2ResponseMetadata;\n\n  constructor() {\n    this.startTime = currentUnixTime();\n  }\n\n  feed(chunk: LanguageModelV2StreamPart): void {\n    // Track time to first token on any chunk\n    if (this.timeToFirstToken === undefined) {\n      this.timeToFirstToken = currentUnixTime() - this.startTime;\n    }\n\n    switch (chunk.type) {\n      case 'response-metadata':\n        this._responseMetadata = {\n          id: chunk.id,\n          modelId: chunk.modelId,\n          timestamp: chunk.timestamp,\n        };\n        break;\n      case 'finish':\n        this._usage = chunk.usage;\n        this._finishReason = chunk.finishReason;\n        break;\n    }\n  }\n\n  get result() {\n    return {\n      response: this._responseMetadata,\n      finishReason: this._finishReason,\n      usage: this._usage,\n    };\n  }\n\n  get firstTokenTime(): number | undefined {\n    return this.timeToFirstToken;\n  }\n}\n","import { type LanguageModelV1, type LanguageModelV1CallOptions } from '@ai-sdk/providerv1';\nimport { axiomAIMiddlewareV1 } from './middleware';\n\nexport function isLanguageModelV1(model: unknown): model is LanguageModelV1 {\n  return (\n    model != null &&\n    typeof model === 'object' &&\n    'specificationVersion' in model &&\n    'provider' in model &&\n    'modelId' in model &&\n    (model as any).specificationVersion === 'v1' &&\n    typeof (model as any).provider === 'string' &&\n    typeof (model as any).modelId === 'string'\n  );\n}\n\n/**\n * Wraps a LanguageModelV1 to provide OpenTelemetry instrumentation.\n *\n * Internally uses Axiom's telemetry middleware while maintaining a simple class-based API.\n *\n * @example\n * ```typescript\n * import { AxiomWrappedLanguageModelV1 } from '@axiom/ai';\n * import { openai } from '@ai-sdk/openai';\n *\n * const model = new AxiomWrappedLanguageModelV1(openai('gpt-3.5-turbo'));\n * ```\n *\n * For advanced use cases, you can also use the middleware directly:\n * ```typescript\n * import { wrapLanguageModel } from 'ai';\n * import { createAxiomTelemetryV1 } from '@axiom/ai';\n *\n * const model = wrapLanguageModel({\n *   model: yourV1Model,\n *   middleware: createAxiomTelemetryV1(),\n * });\n * ```\n */\nexport class AxiomWrappedLanguageModelV1 {\n  constructor(model: LanguageModelV1) {\n    const middleware = axiomAIMiddlewareV1();\n\n    // Return the wrapped model directly from constructor\n    return {\n      specificationVersion: model.specificationVersion,\n      provider: model.provider,\n      modelId: model.modelId,\n      defaultObjectGenerationMode: model.defaultObjectGenerationMode,\n      supportsImageUrls: model.supportsImageUrls,\n      supportsStructuredOutputs: model.supportsStructuredOutputs,\n      supportsUrl: model.supportsUrl?.bind(model),\n\n      doGenerate: async (params: LanguageModelV1CallOptions) => {\n        return middleware.wrapGenerate!({\n          doGenerate: () => model.doGenerate(params),\n          doStream: () => model.doStream(params),\n          params,\n          model,\n        });\n      },\n\n      doStream: async (params: LanguageModelV1CallOptions) => {\n        return middleware.wrapStream!({\n          doGenerate: () => model.doGenerate(params),\n          doStream: () => model.doStream(params),\n          params,\n          model,\n        });\n      },\n    } as LanguageModelV1;\n  }\n}\n","import { type LanguageModelV2, type LanguageModelV2CallOptions } from '@ai-sdk/providerv2';\nimport { axiomAIMiddlewareV2 } from './middleware';\n\nexport function isLanguageModelV2(model: any): model is LanguageModelV2 {\n  return (\n    model?.specificationVersion === 'v2' &&\n    typeof model?.provider === 'string' &&\n    typeof model?.modelId === 'string'\n  );\n}\n\n/**\n * Wraps a LanguageModelV2 to provide OpenTelemetry instrumentation.\n *\n * Internally uses Axiom's telemetry middleware while maintaining a simple class-based API.\n *\n * @example\n * ```typescript\n * import { AxiomWrappedLanguageModelV2 } from '@axiom/ai';\n * import { anthropic } from '@ai-sdk/anthropic';\n *\n * const model = new AxiomWrappedLanguageModelV2(anthropic('claude-3-haiku-20240307'));\n * ```\n *\n * For advanced use cases, you can also use the middleware directly:\n * ```typescript\n * import { wrapLanguageModel } from 'ai';\n * import { createAxiomTelemetryV2 } from '@axiom/ai';\n *\n * const model = wrapLanguageModel({\n *   model: yourV2Model,\n *   middleware: createAxiomTelemetryV2(),\n * });\n * ```\n */\nexport class AxiomWrappedLanguageModelV2 {\n  constructor(model: LanguageModelV2) {\n    const middleware = axiomAIMiddlewareV2();\n\n    // Return the wrapped model directly from constructor\n    return {\n      specificationVersion: model.specificationVersion,\n      provider: model.provider,\n      modelId: model.modelId,\n      supportedUrls: model.supportedUrls,\n\n      doGenerate: async (params: LanguageModelV2CallOptions) => {\n        return middleware.wrapGenerate!({\n          doGenerate: () => model.doGenerate(params),\n          doStream: () => model.doStream(params),\n          params,\n          model,\n        });\n      },\n\n      doStream: async (params: LanguageModelV2CallOptions) => {\n        return middleware.wrapStream!({\n          doGenerate: () => model.doGenerate(params),\n          doStream: () => model.doStream(params),\n          params,\n          model,\n        });\n      },\n    } as LanguageModelV2;\n  }\n}\n","import { type LanguageModelV1 } from '@ai-sdk/providerv1';\nimport { type LanguageModelV2 } from '@ai-sdk/providerv2';\n\nimport { AxiomWrappedLanguageModelV1, isLanguageModelV1 } from './AxiomWrappedLanguageModelV1';\nimport { AxiomWrappedLanguageModelV2, isLanguageModelV2 } from './AxiomWrappedLanguageModelV2';\n\n/**\n * Wraps an AI SDK model to provide OpenTelemetry instrumentation.\n *\n * Supports both AI SDK v4 (LanguageModelV1) and v5 (LanguageModelV2) models.\n *\n * @param model - Language model implementing LanguageModelV1 or LanguageModelV2 interface\n * @returns Wrapped model with identical interface but added instrumentation\n */\nexport function wrapAISDKModel<T extends LanguageModelV1 | LanguageModelV2>(model: T): T {\n  if (isLanguageModelV2(model)) {\n    return new AxiomWrappedLanguageModelV2(model) as never as T;\n  } else if (isLanguageModelV1(model)) {\n    return new AxiomWrappedLanguageModelV1(model) as never as T;\n  } else {\n    console.warn('Unsupported AI SDK model. Not wrapping.');\n    return model;\n  }\n}\n"],"mappings":";;;;;AAAA,SAAS,SAAS,mBAA4C;;;ACOvD,IAAM,uBAAuB;AAC7B,IAAM,gCAAgC;;;ADEtC,IAAM,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA,EAK7B,cAAc;AAAA,IACZ,uBAAuB;AAAA,IACvB,6BAA6B;AAAA,EAC/B;AAAA;AAAA;AAAA;AAAA;AAAA,EAKA,sBAAsB;AAAA,IACpB,uBAAuB;AAAA,IACvB,6BAA6B;AAAA,EAC/B;AACF;AAGO,IAAM,yBAAyB,OAAO,IAAI,wBAAwB;AAMzE,SAAS,2BAA+D;AACtE,SAAQ,WAAmB,sBAAsB;AACnD;AAUA,SAAS,4BACP,cACA,aACwB;AAExB,SAAO;AAAA,IACL,uBACE,aAAa,yBACb,cAAc,yBACd,gBAAgB,aAAa;AAAA,IAC/B,6BACE,aAAa,+BACb,cAAc,+BACd,gBAAgB,aAAa;AAAA,EACjC;AACF;AAKO,SAAS,qBAAqB;AACnC,SAAO,4BAA4B,yBAAyB,GAAG,0BAA0B,CAAC;AAC5F;AAWO,SAAS,6BACd,MACA,WACA,OACA,uBACM;AACN,MAAI,0BAA0B,QAAQ;AACpC,SAAK,aAAa,WAAW,KAAK;AAAA,EACpC;AAIF;AAQA,SAAS,4BAAgE;AACvE,QAAM,UAAmB,YAAY,WAAW,QAAQ,OAAO,CAAC,KAAK,YAAY,cAAc;AAC/F,QAAM,mBAAmB,QAAQ,SAAS,6BAA6B,GAAG;AAE1E,MAAI,CAAC,kBAAkB;AACrB,WAAO;AAAA,EACT;AAEA,MAAI;AACF,WAAO,KAAK,MAAM,gBAAgB;AAAA,EACpC,SAAS,OAAO;AACd,YAAQ,KAAK,4DAA4D,KAAK;AAC9E,WAAO;AAAA,EACT;AACF;;;AElHA,SAAS,aAAa;;;ACDtB;AAAA,EACE,MAAQ;AAAA,EACR,SAAW;AAAA,EACX,MAAQ;AAAA,EACR,QAAU;AAAA,EACV,cAAgB;AAAA,IACd;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAAA,EACA,SAAW;AAAA,IACT,KAAO;AAAA,IACP,OAAS;AAAA,IACT,QAAU;AAAA,IACV,gBAAgB;AAAA,IAChB,MAAQ;AAAA,IACR,WAAa;AAAA,IACb,MAAQ;AAAA,IACR,cAAc;AAAA,IACd,SAAW;AAAA,EACb;AAAA,EACA,OAAS;AAAA,EACT,MAAQ;AAAA,EACR,QAAU;AAAA,EACV,KAAO;AAAA,IACL,OAAS;AAAA,EACX;AAAA,EACA,SAAW;AAAA,IACT,QAAQ;AAAA,MACN,QAAU;AAAA,QACR,OAAS;AAAA,QACT,SAAW;AAAA,MACb;AAAA,MACA,SAAW;AAAA,QACT,OAAS;AAAA,QACT,SAAW;AAAA,MACb;AAAA,IACF;AAAA,IACA,cAAc;AAAA,MACZ,QAAU;AAAA,QACR,OAAS;AAAA,QACT,SAAW;AAAA,MACb;AAAA,MACA,SAAW;AAAA,QACT,OAAS;AAAA,QACT,SAAW;AAAA,MACb;AAAA,IACF;AAAA,IACA,eAAe;AAAA,MACb,QAAU;AAAA,QACR,OAAS;AAAA,QACT,SAAW;AAAA,MACb;AAAA,MACA,SAAW;AAAA,QACT,OAAS;AAAA,QACT,SAAW;AAAA,MACb;AAAA,IACF;AAAA,EACF;AAAA,EACA,UAAY;AAAA,IACV;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAAA,EACA,YAAc;AAAA,IACZ,MAAQ;AAAA,IACR,KAAO;AAAA,IACP,WAAa;AAAA,EACf;AAAA,EACA,SAAW;AAAA,EACX,cAAgB;AAAA,IACd,aAAa;AAAA,IACb,6CAA6C;AAAA,IAC7C,sCAAsC;AAAA,IACtC,2CAA2C;AAAA,IAC3C,4BAA4B;AAAA,IAC5B,iCAAiC;AAAA,IACjC,uCAAuC;AAAA,IACvC,qBAAqB;AAAA,IACrB,WAAa;AAAA,IACb,YAAc;AAAA,IACd,QAAU;AAAA,EACZ;AAAA,EACA,kBAAoB;AAAA,IAClB,sBAAsB;AAAA,IACtB,KAAO;AAAA,EACT;AAAA,EACA,iBAAmB;AAAA,IACjB,uBAAuB;AAAA,IACvB,uBAAuB;AAAA,IACvB,oBAAoB;AAAA,IACpB,oBAAoB;AAAA,IACpB,sBAAsB;AAAA,IACtB,sBAAsB;AAAA,IACtB,sBAAsB;AAAA,IACtB,uBAAuB;AAAA,IACvB,iCAAiC;AAAA,IACjC,iCAAiC;AAAA,IACjC,uBAAuB;AAAA,IACvB,eAAe;AAAA,IACf,uBAAuB;AAAA,IACvB,MAAQ;AAAA,IACR,MAAQ;AAAA,IACR,KAAO;AAAA,IACP,MAAQ;AAAA,IACR,SAAW;AAAA,IACX,QAAU;AAAA,IACV,UAAY;AAAA,IACZ,aAAe;AAAA,IACf,MAAQ;AAAA,IACR,YAAc;AAAA,IACd,QAAU;AAAA,IACV,KAAO;AAAA,EACT;AAAA,EACA,OAAS;AAAA,IACP;AAAA,EACF;AAAA,EACA,gBAAkB;AACpB;;;ADlHA,IAAM,qBAAqB,OAAO,IAAI,oBAAoB;AAU1D,SAAS,mBAAmB,QAA6B;AACvD,QAAM,YAAY;AAKlB,QAAM,OACJ,UAAU,uBAAuB,QACjC,UAAU,wBAAwB,QAClC,gBAAY;AAEd,QAAM,UACJ,UAAU,uBAAuB,WACjC,UAAU,wBAAwB,WAClC,gBAAY;AAEd,SAAO,EAAE,MAAM,QAAQ;AACzB;AAaO,SAAS,YAAY,QAAsE;AAChG,QAAM,WAAW,mBAAmB,OAAO,MAAM;AACjD,QAAM,gBAAiB,WAAmB,kBAAkB;AAG5D,MACE,iBACA,cAAc,SAAS,SAAS,QAChC,cAAc,YAAY,SAAS,SACnC;AACA;AAAA,EACF;AAGA,MAAI,eAAe;AACjB,YAAQ;AAAA,MACN,kFACe,cAAc,IAAI,IAAI,cAAc,OAAO,UAChD,SAAS,IAAI,IAAI,SAAS,OAAO;AAAA,IAC7C;AAAA,EACF;AAGA,EAAC,WAAmB,kBAAkB,IAAI;AAG1C,MAAI,OAAO,iBAAiB;AAC1B,IAAC,WAAmB,sBAAsB,IAAI,OAAO;AAAA,EACvD;AACF;AAMO,SAAS,kBAA0B;AAExC,QAAM,QAAS,WAAmB,kBAAkB;AAGpD,MAAI,CAAC,OAAO;AACV,UAAM,QAAQ,QAAQ,IAAI,gBAAgB;AAC1C,QAAI,CAAC,OAAO;AACV,cAAQ;AAAA,QACN;AAAA,MAGF;AAAA,IACF;AAAA,EACF;AAEA,MAAI,EAAE,MAAM,QAAQ,IAAI,SAAS,EAAE,MAAM,gBAAY,MAAM,SAAS,gBAAY,QAAQ;AAExF,MAAI,CAAC,QAAQ,CAAC,SAAS;AACrB,WAAO,gBAAY;AACnB,cAAU,gBAAY;AACtB,QAAI,CAAC,QAAQ,CAAC,SAAS;AACrB,aAAO;AACP,gBAAU;AAAA,IACZ;AAAA,EACF;AAGA,SAAO,MAAM,UAAU,MAAM,OAAO;AACtC;AAKO,SAAS,eAAe;AAC7B,EAAC,WAAmB,kBAAkB,IAAI;AAC1C,EAAC,WAAmB,sBAAsB,IAAI;AAChD;;;AEtHA;AAAA,EACE,WAAAA;AAAA,EACA,eAAAC;AAAA,EACA,SAAAC;AAAA,EACA,kBAAAC;AAAA,OAIK;;;ACRP;AAAA,EACE,SAAAC;AAAA,EACA,WAAAC;AAAA,EACA,eAAAC;AAAA,EAEA,kBAAAC;AAAA,OAGK;;;ACRP;AAAA,EACE;AAAA,EACA;AAAA,OACK;;;ACFA,IAAM,eAAe;AACrB,IAAM,iBAAiB;AACvB,IAAM,oBAAoB;AAC1B,IAAM,iBAAiB;AACvB,IAAM,iBAAiB;AACvB,IAAM,wBAAwB;AAC9B,IAAM,0BAA0B;AAEhC,IAAM,0BAA0B;AAChC,IAAM,4BAA4B;AAClC,IAAM,4BAA4B;AAElC,IAAM,uBAAuB;AAC7B,IAAM,uBAAuB;AAC7B,IAAM,wBAAwB;AAC9B,IAAM,0BAA0B;AAChC,IAAM,wBAAwB;AAC9B,IAAM,0BAA0B;AAEhC,IAAM,wBAAwB;AAC9B,IAAM,sBAAsB;AAC5B,IAAM,sBAAsB;AAE5B,IAAM,uBAAuB;AAC7B,IAAM,wBAAwB;AAC9B,IAAM,4BAA4B;AAClC,IAAM,yBAAyB;AAE/B,IAAM,2BAA2B;AAEjC,IAAM,sBAAsB;AAC5B,IAAM,uBAAuB;;;ADEpC;AAAA,EACE;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,OACK;AAEA,IAAM,iBAAiB;AACvB,IAAM,kBAAkB;AAQ/B,IAAM,+BAA+B;AACrC,IAAM,6BAA6B;AACnC,IAAM,gCAAgC;AACtC,IAAM,8BAA8B;AACpC,IAAM,wBAAwB;AAC9B,IAAM,6BAA6B;AACnC,IAAM,2BAA2B;AAEjC,IAAM,wCAAwC;AAC9C,IAAM,sCAAsC;AAC5C,IAAM,sCAAsC;AAC5C,IAAM,uCAAuC;AAC7C,IAAM,wCAAwC;AAC9C,IAAM,iCAAiC;AACvC,IAAM,uCAAuC;AAC7C,IAAM,oCAAoC;AAC1C,IAAM,kCAAkC;AACxC,IAAM,kCAAkC;AACxC,IAAM,kCAAkC;AACxC,IAAM,uCAAuC;AAC7C,IAAM,mCAAmC;AACzC,IAAM,wCAAwC;AAC9C,IAAM,oCAAoC;AAanC,IAAM,OAAO;AAAA,EAClB,qBAAqB,CAAC,aAAqB,QAAQ,QAAQ;AAAA,EAC3D,qBAAqB,CAAC,aAAqB,QAAQ,QAAQ;AAAA,EAC3D,OAAO;AAAA,IACL,OAAO;AAAA,MACL,WAAW;AAAA,MACX,KAAK;AAAA,QACH,MAAM;AAAA,QACN,SAAS;AAAA,MACX;AAAA,IACF;AAAA,EACF;AAAA,EACA,OAAO;AAAA,IACL,gBAAgB;AAAA,MACd,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,IACX;AAAA;AAAA;AAAA;AAAA,IAIA,YAAY;AAAA,MACV,MAAM;AAAA,IACR;AAAA,IACA,MAAM;AAAA,MACJ,MAAM;AAAA,IACR;AAAA,IACA,UAAU;AAAA,MACR,MAAM;AAAA,MACN,aAAa;AAAA,QACX,WAAW;AAAA,QACX,YAAY;AAAA,QACZ,YAAY;AAAA,QACZ,kBAAkB;AAAA,QAClB,eAAe;AAAA,QACf,UAAU;AAAA,QACV,QAAQ;AAAA,QACR,UAAU;AAAA,QACV,WAAW;AAAA,QACX,UAAU;AAAA,QACV,YAAY;AAAA,QACZ,KAAK;AAAA,QACL,WAAW;AAAA,QACX,WAAW;AAAA,QACX,UAAU;AAAA,QACV,aAAa;AAAA,QACb,QAAQ;AAAA,QACR,MAAM;AAAA,QACN,MAAM;AAAA,QACN,cAAc;AAAA,QACd,MAAM;AAAA,QACN,MAAM;AAAA,QACN,WAAW;AAAA,QACX,QAAQ;AAAA,QACR,YAAY;AAAA,QACZ,WAAW;AAAA,QACX,OAAO;AAAA,QACP,YAAY;AAAA,QACZ,QAAQ;AAAA,QACR,KAAK;AAAA,MACP;AAAA,IACF;AAAA;AAAA;AAAA;AAAA,IAIA,OAAO;AAAA,MACL,aAAa;AAAA;AAAA,MACb,IAAI;AAAA;AAAA,MACJ,MAAM;AAAA;AAAA,IACR;AAAA,IACA,cAAc;AAAA,MACZ,IAAI;AAAA;AAAA,IACN;AAAA,IACA,OAAO;AAAA,MACL,UAAU;AAAA,IACZ;AAAA,IACA,WAAW;AAAA,MACT,MAAM;AAAA,MACN,aAAa;AAAA;AAAA;AAAA;AAAA,QAIX,MAAM;AAAA,QACN,aAAa;AAAA,QACb,YAAY;AAAA,QACZ,aAAa;AAAA,QACb,iBAAiB;AAAA,QACjB,aAAa;AAAA,MACf;AAAA,IACF;AAAA,IACA,QAAQ;AAAA,MACN,UAAU;AAAA,MACV,MAAM;AAAA,MACN,aAAa;AAAA,QACX,MAAM;AAAA,QACN,MAAM;AAAA,QACN,OAAO;AAAA,QACP,QAAQ;AAAA,MACV;AAAA,IACF;AAAA;AAAA;AAAA;AAAA;AAAA,IAKA,SAAS;AAAA,MACP,aAAa;AAAA;AAAA,MACb,iBAAiB;AAAA;AAAA,MACjB,kBAAkB;AAAA,MAClB,WAAW;AAAA;AAAA;AAAA;AAAA,MAIX,OAAO;AAAA,MACP,iBAAiB;AAAA,MACjB,MAAM;AAAA,MACN,eAAe;AAAA,MACf,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,IACR;AAAA,IACA,UAAU;AAAA,MACR,eAAe;AAAA,MACf,IAAI;AAAA;AAAA;AAAA;AAAA,MAIJ,OAAO;AAAA;AAAA,IACT;AAAA,IACA,MAAM;AAAA,MACJ,QAAQ;AAAA,MACR,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAON,WAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOX,SAAS;AAAA,IACX;AAAA,IACA,OAAO;AAAA,MACL,aAAa;AAAA,MACb,cAAc;AAAA,IAChB;AAAA,EACF;AAAA,EACA,MAAM;AAAA,IACJ,IAAI;AAAA,IACJ,MAAM;AAAA,IACN,SAAS;AAAA,IACT,MAAM;AAAA,IACN,YAAY;AAAA,IACZ,cAAc;AAAA,IACd,MAAM;AAAA,IACN,YAAY;AAAA,MACV,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,MAAM;AAAA,IACR;AAAA,IACA,MAAM;AAAA,MACJ,OAAO;AAAA,MACP,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,UAAU;AAAA,MACV,QAAQ;AAAA,MACR,UAAU;AAAA,IACZ;AAAA,IACA,MAAM;AAAA,MACJ,QAAQ;AAAA,MACR,MAAM;AAAA,MACN,MAAM;AAAA,IACR;AAAA,IACA,OAAO;AAAA,MACL,MAAM;AAAA,MACN,OAAO;AAAA,MACP,WAAW;AAAA,MACX,QAAQ;AAAA,MACR,UAAU;AAAA,IACZ;AAAA,IACA,MAAM;AAAA,MACJ,MAAM;AAAA,MACN,OAAO;AAAA,IACT;AAAA,EACF;AAAA,EACA,OAAO;AAAA,IACL,MAAM;AAAA,IACN,SAAS;AAAA,EACX;AAAA,EACA,MAAM;AAAA,IACJ,UAAU;AAAA,MACR,YAAY;AAAA,IACd;AAAA,EACF;AACF;;;AEjVA,SAAsC,sBAAmC;AAQlE,IAAM,wBACX,CAAC,WACD,OACE,MACA,SACA,IACA,cACe;AACf,SAAO,OAAO,gBAAgB,MAAM,EAAE,GAAI,WAAW,CAAC,EAAG,GAAG,OAAO,SAAS;AAC1E,QAAI;AACF,YAAM,SAAS,MAAM,GAAG,IAAI;AAE5B,iBAAW,YAAY,IAAI;AAE3B,aAAO;AAAA,IACT,SAAS,OAAO;AACd,iBAAW,UAAU,OAAO,IAAI;AAEhC,UAAI,iBAAiB,OAAO;AAC1B,aAAK,gBAAgB,KAAK;AAC1B,aAAK,UAAU;AAAA,UACb,MAAM,eAAe;AAAA,UACrB,SAAS,MAAM;AAAA,QACjB,CAAC;AAAA,MACH;AAEA,YAAM;AAAA,IACR,UAAE;AACA,iBAAW,YAAY,IAAI;AAC3B,WAAK,IAAI;AAAA,IACX;AAAA,EACF,CAAC;AACH;;;AHdF,SAAS,cAAc,KAAkC;AACvD,MAAI,OAAO,KAAM,QAAO;AAExB,MAAI,eAAe,OAAO;AACxB,UAAM,OAAO,IAAI,KAAK,YAAY;AAGlC,QAAI,KAAK,SAAS,SAAS,EAAG,QAAO;AACrC,QAAI,KAAK,SAAS,OAAO,EAAG,QAAO;AACnC,QAAI,KAAK,SAAS,SAAS,KAAK,KAAK,SAAS,OAAO,EAAG,QAAO;AAC/D,QAAI,KAAK,SAAS,YAAY,EAAG,QAAO;AACxC,QAAI,KAAK,SAAS,MAAM,EAAG,QAAO;AAClC,QAAI,KAAK,SAAS,OAAO,KAAK,KAAK,SAAS,MAAM,EAAG,QAAO;AAC5D,QAAI,KAAK,SAAS,YAAY,KAAK,KAAK,SAAS,WAAW,EAAG,QAAO;AACtE,QAAI,KAAK,SAAS,MAAM,KAAK,KAAK,SAAS,OAAO,EAAG,QAAO;AAC5D,QAAI,KAAK,SAAS,OAAO,KAAK,KAAK,SAAS,OAAO,EAAG,QAAO;AAI7D,WAAO;AAAA,EACT;AAEA,SAAO;AACT;AASO,SAAS,kBAAkB,KAAc,MAAkB;AAEhE,MAAI,eAAe,OAAO;AACxB,SAAK,gBAAgB,GAAG;AAAA,EAC1B,OAAO;AAEL,SAAK,gBAAgB;AAAA,MACnB,SAAS,OAAO,GAAG;AAAA,MACnB,MAAM;AAAA,IACR,CAAC;AAAA,EACH;AAEA,OAAK,UAAU;AAAA,IACb,MAAMC,gBAAe;AAAA,IACrB,SAAS,eAAe,QAAQ,IAAI,UAAU,OAAO,GAAG;AAAA,EAC1D,CAAC;AAED,MAAI,YAAY;AAChB,MAAI;AAGJ,MAAI,OAAO,OAAO,QAAQ,UAAU;AAClC,UAAM,SAAS;AACf,UAAM,OAAO,OAAO,MAAM,YAAY,KAAK;AAC3C,UAAM,UAAU,OAAO,SAAS,YAAY,KAAK;AAEjD,QAAI,KAAK,SAAS,SAAS,KAAK,KAAK,SAAS,OAAO,KAAK,QAAQ,SAAS,SAAS,GAAG;AACrF,kBAAY;AAAA,IACd,WACE,KAAK,SAAS,YAAY,KAC1B,OAAO,SAAS,sBAChB,QAAQ,SAAS,YAAY,GAC7B;AACA,kBAAY;AAAA,IACd,WACE,KAAK,SAAS,OAAO,KACrB,KAAK,SAAS,SAAS,KACvB,QAAQ,SAAS,SAAS,KAC1B,QAAQ,SAAS,cAAc,GAC/B;AACA,kBAAY;AAEZ,mBAAa,OAAO,UAAU,OAAO;AAAA,IACvC,WACE,KAAK,SAAS,MAAM,KACpB,QAAQ,SAAS,MAAM,KACvB,QAAQ,SAAS,cAAc,GAC/B;AACA,kBAAY;AAAA,IACd,WACE,KAAK,SAAS,YAAY,KAC1B,KAAK,SAAS,WAAW,KACzB,QAAQ,SAAS,WAAW,GAC5B;AACA,kBAAY;AAAA,IACd,WACE,KAAK,SAAS,MAAM,MACnB,KAAK,SAAS,OAAO,KAAK,QAAQ,SAAS,YAAY,IACxD;AACA,kBAAY;AAAA,IACd,WACE,KAAK,SAAS,OAAO,KACrB,QAAQ,SAAS,OAAO,KACxB,QAAQ,SAAS,gBAAgB,GACjC;AACA,kBAAY;AAAA,IACd,WACE,KAAK,SAAS,OAAO,KACrB,KAAK,SAAS,MAAM,KACpB,QAAQ,SAAS,MAAM,KACvB,QAAQ,SAAS,OAAO,GACxB;AACA,kBAAY;AAAA,IACd;AAAA,EACF;AAGA,OAAK,aAAa,KAAK,MAAM,MAAM,SAAS;AAC5C,MAAI,eAAe,SAAS,IAAI,SAAS;AACvC,SAAK,aAAa,KAAK,MAAM,SAAS,IAAI,OAAO;AAAA,EACnD;AAGA,MAAI,eAAe,QAAW;AAC5B,SAAK,aAAa,KAAK,KAAK,SAAS,YAAY,UAA4B;AAAA,EAC/E;AACF;AAMA,SAAS,uBAAgC;AACvC,QAAM,WAAWC,OAAM,kBAAkB;AAGzC,MAAI,SAAS,YAAY,SAAS,sBAAsB;AACtD,WAAO;AAAA,EACT;AAGA,MAAI,OAAQ,SAAiB,cAAc,YAAY;AACrD,WAAO;AAAA,EACT;AAEA,SAAO;AACT;AAKO,SAAS,YAAoB;AAClC,QAAM,SAAS,gBAAgB;AAE/B,MAAI,qBAAqB,GAAG;AAC1B,UAAM,QAAQ,QAAQ,IAAI,gBAAgB;AAC1C,QAAI,CAAC,OAAO;AACV,cAAQ;AAAA,QACN;AAAA,MAEF;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;AAKA,SAAS,oBAAoB,WAAmB,QAAyB;AACvE,SAAO,SAAS,GAAG,SAAS,IAAI,MAAM,KAAK;AAC7C;AAaO,SAAS,mBAAmB,MAAkB;AACnD,QAAM,MAAMC,aAAY,iBAAiB;AAEzC,MAAI,KAAK;AACP,UAAM,aAAa,IAAI,SAAS,YAAY,GAAG;AAC/C,QAAI,YAAY;AACd,WAAK,aAAa,KAAK,MAAM,WAAW,MAAM,UAAU;AAAA,IAC1D;AAEA,UAAM,OAAO,IAAI,SAAS,MAAM,GAAG;AACnC,QAAI,MAAM;AACR,WAAK,aAAa,KAAK,MAAM,KAAK,MAAM,IAAI;AAAA,IAC9C;AAAA,EACF;AACF;AAKO,SAAS,uBAAuB,MAAkB;AACvD,OAAK,cAAc;AAAA,IACjB,CAAC,KAAK,MAAM,MAAM,SAAS,GAAG,GAAG,eAAe,GAAG,cAAc;AAAA,IACjE,CAAC,KAAK,MAAM,MAAM,IAAI,IAAI,GAAG,gBAAY;AAAA,IACzC,CAAC,KAAK,MAAM,MAAM,IAAI,OAAO,GAAG,gBAAY;AAAA,EAC9C,CAAC;AACH;AAKO,SAAS,kBAAkB,MAAY,UAAkB,SAAuB;AACrF,OAAK,cAAc;AAAA,IACjB,CAAC,KAAK,MAAM,UAAU,IAAI,GAAG,KAAK,MAAM,UAAU,YAAY;AAAA,IAC9D,CAAC,KAAK,MAAM,QAAQ,KAAK,GAAG;AAAA,EAC9B,CAAC;AAED,QAAM,cAAc,mCAAmC,QAAQ;AAC/D,MAAI,aAAa;AACf,SAAK,aAAa,KAAK,MAAM,SAAS,MAAM,WAAW;AAAA,EACzD;AAEA,yBAAuB,IAAI;AAC7B;AAKO,SAAS,8BACd,MACA,QAUM;AACN,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,IAAI;AAEJ,MAAI,cAAc,QAAW;AAC3B,SAAK,aAAa,KAAK,MAAM,QAAQ,WAAW,SAAS;AAAA,EAC3D;AACA,MAAI,qBAAqB,QAAW;AAClC,SAAK,aAAa,KAAK,MAAM,QAAQ,kBAAkB,gBAAgB;AAAA,EACzE;AACA,MAAI,oBAAoB,QAAW;AACjC,SAAK,aAAa,KAAK,MAAM,QAAQ,iBAAiB,eAAe;AAAA,EACvE;AACA,MAAI,gBAAgB,QAAW;AAC7B,SAAK,aAAa,KAAK,MAAM,QAAQ,aAAa,WAAW;AAAA,EAC/D;AACA,MAAI,SAAS,QAAW;AACtB,SAAK,aAAa,KAAK,MAAM,QAAQ,MAAM,IAAI;AAAA,EACjD;AACA,MAAI,SAAS,QAAW;AACtB,SAAK,aAAa,KAAK,MAAM,QAAQ,MAAM,IAAI;AAAA,EACjD;AACA,MAAI,SAAS,QAAW;AACtB,SAAK,aAAa,KAAK,MAAM,QAAQ,MAAM,IAAI;AAAA,EACjD;AACA,MAAI,iBAAiB,cAAc,SAAS,GAAG;AAC7C,SAAK,aAAa,KAAK,MAAM,QAAQ,eAAe,KAAK,UAAU,aAAa,CAAC;AAAA,EACnF;AACF;AAOO,SAAS,sBAAsB,YAAkB,eAA6B;AACnF,QAAM,SAAS,UAAU;AAGzB,QAAM,cAAcD,OAAM,QAAQE,SAAQ,OAAO,GAAG,UAAU;AAC9D,QAAM,YAAY,OAAO,UAAU,eAAe,QAAW,WAAW;AAExE,SAAO;AACT;AAKO,SAAS,kBAAkB,MAAY,KAAoB;AAEhE,MAAI,eAAe,OAAO;AACxB,SAAK,gBAAgB,GAAG;AAAA,EAC1B,OAAO;AAEL,SAAK,gBAAgB;AAAA,MACnB,SAAS,OAAO,GAAG;AAAA,MACnB,MAAM;AAAA,IACR,CAAC;AAAA,EACH;AAEA,OAAK,UAAU;AAAA,IACb,MAAMH,gBAAe;AAAA,IACrB,SAAS,eAAe,QAAQ,IAAI,UAAU,OAAO,GAAG;AAAA,EAC1D,CAAC;AAGD,QAAM,YAAY,cAAc,GAAG;AACnC,OAAK,aAAa,KAAK,MAAM,MAAM,aAAa,SAAS;AAGzD,MAAI,eAAe,SAAS,IAAI,SAAS;AACvC,SAAK,aAAa,KAAK,MAAM,SAAS,IAAI,OAAO;AAAA,EACnD;AAGA,MAAI,OAAO,OAAO,QAAQ,YAAY,YAAY,KAAK;AACrD,SAAK,aAAa,KAAK,KAAK,SAAS,YAAY,IAAI,MAAwB;AAAA,EAC/E;AACF;AAKA,eAAsB,iBACpB,SACA,WACY;AACZ,QAAM,MAAME,aAAY,iBAAiB;AACzC,QAAM,mBAAmB,KAAK,SAAS,oBAAoB,GAAG,UAAU;AAExE,QAAMC,WAA6B;AAAA,IACjC,gBAAgB,CAAC;AAAA,IACjB,SAAS;AAAA,EACX;AAEA,MAAI,kBAAkB;AAEpB,UAAM,aAAaF,OAAM,cAAc;AACvC,QAAI,CAAC,YAAY;AACf,YAAM,IAAI,MAAM,2CAA2C;AAAA,IAC7D;AACA,eAAW,WAAW,oBAAoB,KAAK,MAAM,UAAU,YAAY,MAAM,OAAO,CAAC;AAEzF,QAAI;AACF,aAAO,MAAM,UAAU,YAAYE,QAAO;AAAA,IAC5C,SAAS,KAAK;AAEZ,UAAI,eAAe,OAAO;AACxB,mBAAW,gBAAgB,GAAG;AAAA,MAChC,OAAO;AAEL,mBAAW,gBAAgB;AAAA,UACzB,SAAS,OAAO,GAAG;AAAA,UACnB,MAAM;AAAA,QACR,CAAC;AAAA,MACH;AAEA,iBAAW,UAAU;AAAA,QACnB,MAAMH,gBAAe;AAAA,QACrB,SAAS,eAAe,QAAQ,IAAI,UAAU,OAAO,GAAG;AAAA,MAC1D,CAAC;AAGD,YAAM,YAAY,cAAc,GAAG;AACnC,iBAAW,aAAa,KAAK,MAAM,MAAM,aAAa,SAAS;AAG/D,UAAI,eAAe,SAAS,IAAI,SAAS;AACvC,mBAAW,aAAa,KAAK,MAAM,SAAS,IAAI,OAAO;AAAA,MACzD;AAGA,UAAI,OAAO,OAAO,QAAQ,YAAY,YAAY,KAAK;AACrD,mBAAW,aAAa,KAAK,KAAK,SAAS,YAAY,IAAI,MAAwB;AAAA,MACrF;AAEA,YAAM;AAAA,IACR;AAAA,EACF,OAAO;AAEL,UAAM,SAAS,UAAU;AACzB,UAAM,kBAAkB,sBAAsB,MAAM;AACpD,UAAM,OAAO,oBAAoB,KAAK,MAAM,UAAU,YAAY,MAAM,OAAO;AAE/E,WAAO,gBAAgB,MAAM,MAAM,CAAC,SAAS,UAAU,MAAMG,QAAO,GAAG;AAAA,MACrE,SAAS,CAAC,KAAK,SAAS;AAGtB,cAAM,YAAY,cAAc,GAAG;AACnC,aAAK,aAAa,KAAK,MAAM,MAAM,aAAa,SAAS;AAGzD,YAAI,eAAe,SAAS,IAAI,SAAS;AACvC,eAAK,aAAa,KAAK,MAAM,SAAS,IAAI,OAAO;AAAA,QACnD;AAGA,YAAI,OAAO,OAAO,QAAQ,YAAY,YAAY,KAAK;AACrD,eAAK,aAAa,KAAK,KAAK,SAAS,YAAY,IAAI,MAAwB;AAAA,QAC/E;AAAA,MACF;AAAA,IACF,CAAC;AAAA,EACH;AACF;AA+CO,SAAS,sBAAsB,SAGf;AACrB,MAAI,QAAQ,gBAAgB,MAAM;AAChC,YAAQ,QAAQ,eAAe,MAAM;AAAA,MACnC,KAAK;AACH,eAAO,KAAK,MAAM,OAAO,YAAY;AAAA,MACvC,KAAK;AACH,eAAO,KAAK,MAAM,OAAO,YAAY;AAAA,IACzC;AAAA,EACF;AAEA,MAAI,QAAQ,MAAM,SAAS,iBAAiB,QAAQ,MAAM,SAAS,eAAe;AAChF,WAAO,KAAK,MAAM,OAAO,YAAY;AAAA,EACvC;AAEA,MAAI,QAAQ,MAAM,SAAS,WAAW;AACpC,WAAO,KAAK,MAAM,OAAO,YAAY;AAAA,EACvC;AAEA,SAAO;AACT;AAKO,SAAS,sBAAsB,SAEf;AACrB,MAAI,QAAQ,gBAAgB,MAAM;AAChC,YAAQ,QAAQ,eAAe,MAAM;AAAA,MACnC,KAAK;AACH,eAAO,KAAK,MAAM,OAAO,YAAY;AAAA,MACvC,KAAK;AACH,eAAO,KAAK,MAAM,OAAO,YAAY;AAAA,IACzC;AAAA,EACF;AAEA,SAAO;AACT;AAQO,SAAS,mCAAmC,mBAA+C;AAChG,MAAI,sBAAsB,qBAAqB;AAE7C,WAAO;AAAA,EACT;AAGA,UAAQ,mBAAmB;AAAA,IACzB,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AAAA,IACL,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AAAA,IACL,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AAAA,IACL,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AAAA,IACL,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AAAA,IACL,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AAAA,IACL,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA,IACzC,KAAK;AACH,aAAO,KAAK,MAAM,SAAS,YAAY;AAAA;AAAA,IAGzC,SAAS;AACP,UAAI,kBAAkB,WAAW,QAAQ,GAAG;AAC1C,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,WAAW,GAAG;AAC7C,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,SAAS,GAAG;AAC3C,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,YAAY,GAAG;AAC9C,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,WAAW,GAAG;AAC7C,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,aAAa,GAAG;AAC/C,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,MAAM,GAAG;AACxC,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,YAAY,GAAG;AAC9C,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,gBAAgB,GAAG;AAClD,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,OAAO,GAAG;AACzC,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,OAAO,GAAG;AACzC,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,OAAO,GAAG;AACzC,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,OAAO,GAAG;AACzC,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,UAAU,GAAG;AAC5C,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,SAAS,GAAG;AAC3C,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,SAAS,GAAG;AAC3C,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,mBAAmB,GAAG;AACrD,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AACA,UAAI,kBAAkB,WAAW,MAAM,GAAG;AACxC,eAAO,KAAK,MAAM,SAAS,YAAY;AAAA,MACzC;AAGA,YAAM,IAAI,kBAAkB,MAAM,GAAG;AACrC,UAAI,EAAE,WAAW,GAAG;AAClB,eAAO,EAAE,CAAC;AAAA,MACZ;AAGA,aAAO;AAAA,IACT;AAAA,EACF;AACF;;;ADriBO,SAAS,SACd,MACA,IACA,MAKiB;AACjB,QAAM,SAAS,MAAM,UAAU,UAAU;AAGzC,QAAM,OAAO,OAAO,UAAU,iBAAiB;AAC/C,QAAM,cAAcC,OAAM,QAAQC,SAAQ,OAAO,GAAG,IAAI;AAExD,SAAOA,SAAQ,KAAK,aAAa,YAAY;AAC3C,QAAI,CAAC,KAAK,YAAY,GAAG;AACvB,YAAM,WAAWD,OAAM,kBAAkB;AACzC,YAAM,iBAAiB,SAAS,YAAY,SAAS;AAGrD,UAAI,gBAAgB;AAClB,cAAM,QAAQ,QAAQ,IAAI,gBAAgB;AAC1C,YAAI,CAAC,OAAO;AACV,kBAAQ;AAAA,YACN;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,UAAM,MAAeE,aAAY,cAAc;AAAA,MAC7C,YAAY,EAAE,OAAO,KAAK,WAAW;AAAA,MACrC,MAAM,EAAE,OAAO,KAAK,KAAK;AAAA;AAAA,MAEzB,CAAC,oBAAoB,GAAG,EAAE,OAAO,OAAO;AAAA;AAAA;AAAA,MAExC,GAAI,MAAM,mBAAmB;AAAA,QAC3B,CAAC,6BAA6B,GAAG,EAAE,OAAO,KAAK,UAAU,KAAK,eAAe,EAAE;AAAA,MACjF;AAAA,IACF,CAAC;AAED,UAAM,MAAMA,aAAY,WAAWD,SAAQ,OAAO,GAAG,GAAG;AAExD,QAAI,YAAY;AAChB,UAAM,cAAc,MAAM;AACxB,UAAI,CAAC,WAAW;AACd,oBAAY;AACZ,aAAK,IAAI;AAAA,MACX;AAAA,IACF;AAGA,UAAM,YAAY,MAAM,aAAa;AACrC,UAAM,YAAY,WAAW,MAAM;AACjC,kBAAY;AAAA,IACd,GAAG,SAAS;AAEZ,QAAI;AACF,YAAM,SAAS,MAAMA,SAAQ,KAAK,KAAK,MAAM,GAAG,IAAI,CAAC;AAGrD,UAAI,kBAAkB,YAAY,OAAO,MAAM;AAE7C,YAAI,OAAO,KAAK,QAAQ;AACtB,kBAAQ,KAAK,qEAAqE;AAClF,uBAAa,SAAS;AACtB,sBAAY;AACZ,iBAAO;AAAA,QACT;AAEA,cAAM,iBAAiB,OAAO,KAAK,UAAU;AAC7C,cAAM,gBAAgB,IAAI,eAAe;AAAA,UACvC,MAAM,KAAK,YAAY;AACrB,gBAAI;AACF,oBAAM,EAAE,OAAO,KAAK,IAAI,MAAMA,SAAQ,KAAK,KAAK,MAAM,eAAe,KAAK,CAAC;AAC3E,kBAAI,MAAM;AACR,+BAAe,cAAc;AAC7B,6BAAa,SAAS;AACtB,qBAAK,UAAU,EAAE,MAAME,gBAAe,GAAG,CAAC;AAC1C,4BAAY;AACZ,2BAAW,MAAM;AAAA,cACnB,OAAO;AACL,2BAAW,QAAQ,KAAK;AAAA,cAC1B;AAAA,YACF,SAAS,KAAK;AACZ,6BAAe,cAAc;AAC7B,2BAAa,SAAS;AACtB,mBAAK,gBAAgB,GAAY;AACjC,mBAAK,UAAU;AAAA,gBACb,MAAMA,gBAAe;AAAA,gBACrB,SAAS,eAAe,QAAQ,IAAI,UAAU,OAAO,GAAG;AAAA,cAC1D,CAAC;AACD,0BAAY;AACZ,yBAAW,MAAM,GAAG;AAAA,YACtB;AAAA,UACF;AAAA,UACA,MAAM,OAAO,QAAiB;AAC5B,gBAAI;AACF,6BAAe,cAAc;AAC7B,2BAAa,SAAS;AACtB,kBAAI,kBAAkB,OAAO;AAC3B,qBAAK,gBAAgB,MAAM;AAAA,cAC7B,WAAW,QAAQ;AACjB,qBAAK,gBAAgB,EAAE,SAAS,OAAO,MAAM,GAAG,MAAM,cAAc,CAAC;AAAA,cACvE;AACA,mBAAK,UAAU;AAAA,gBACb,MAAMA,gBAAe;AAAA,gBACrB,SAAS,kBAAkB,QAAQ,OAAO,UAAU,OAAO,MAAM;AAAA,cACnE,CAAC;AACD,0BAAY;AACZ,oBAAM,eAAe,OAAO,MAAM;AAAA,YACpC,SAAS,MAAM;AAAA,YAEf;AAAA,UACF;AAAA,QACF,CAAC;AAED,eAAO,IAAI,SAAS,eAAe;AAAA,UACjC,QAAQ,OAAO;AAAA,UACf,YAAY,OAAO;AAAA,UACnB,SAAS,OAAO;AAAA,QAClB,CAAC;AAAA,MACH;AAGA,UAAI,UAAU,OAAO,WAAW,YAAY,gBAAgB,QAAQ;AAClE,gBAAQ;AAAA,UACN;AAAA,QACF;AACA,qBAAa,SAAS;AACtB,oBAAY;AACZ,eAAO;AAAA,MACT;AAGA,mBAAa,SAAS;AACtB,WAAK,UAAU,EAAE,MAAMA,gBAAe,GAAG,CAAC;AAC1C,kBAAY;AACZ,aAAO;AAAA,IACT,SAAS,KAAK;AACZ,mBAAa,SAAS;AACtB,WAAK,gBAAgB,GAAY;AACjC,WAAK,UAAU;AAAA,QACb,MAAMA,gBAAe;AAAA,QACrB,SAAS,eAAe,QAAQ,IAAI,UAAU,OAAO,GAAG;AAAA,MAC1D,CAAC;AACD,kBAAY;AACZ,YAAM;AAAA,IACR;AAAA,EACF,CAAC;AACH;;;AK9NA,OAA0B;;;ACf1B,SAAS,kBAAkB;AAa3B,SAAS,qBAAqB,KAA4B;AACxD,MAAI,IAAI,WAAW,OAAO,GAAG;AAE3B,UAAM,CAAC,QAAQ,UAAU,IAAI,IAAI,MAAM,GAAG;AAC1C,UAAM,cAAc,OAAO,MAAM,mBAAmB;AACpD,UAAM,SAAS,cAAc,CAAC;AAG9B,UAAM,YAAY,aAAa,KAAK,MAAO,WAAW,SAAS,IAAK,CAAC,IAAI;AAGzE,UAAM,OAAO,aACT,WAAW,QAAQ,EAAE,OAAO,UAAU,EAAE,OAAO,KAAK,EAAE,MAAM,GAAG,EAAE,IACjE;AAEJ,WAAO;AAAA,MACL;AAAA,MACA,YAAY;AAAA,MACZ;AAAA,MACA,aAAa;AAAA,IACf;AAAA,EACF,OAAO;AAEL,UAAM,OAAO,WAAW,QAAQ,EAAE,OAAO,GAAG,EAAE,OAAO,KAAK,EAAE,MAAM,GAAG,EAAE;AACvE,WAAO;AAAA,MACL;AAAA,MACA,aAAa;AAAA,IACf;AAAA,EACF;AACF;AAKA,SAAS,iBAAiB,KAAa,QAAiB;AACtD,QAAM,WAAW,qBAAqB,GAAG;AAEzC,MAAI,SAAS,aAAa;AAExB,UAAM,aAAa,SAAS,SAAS,IAAI,SAAS,MAAM,KAAK;AAC7D,UAAM,WAAW,SAAS,aAAa,IAAI,SAAS,UAAU,MAAM;AACpE,WAAO;AAAA,MACL,KAAK,SAAS,UAAU,GAAG,QAAQ,IAAI,SAAS,IAAI;AAAA,MACpD;AAAA,MACA,GAAG;AAAA,IACL;AAAA,EACF,OAAO;AAEL,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA,GAAG;AAAA,IACL;AAAA,EACF;AACF;AAQO,SAAS,0BAA6B,SAAiC;AAC5E,MAAI,MAAM,QAAQ,OAAO,GAAG;AAC1B,WAAO,QAAQ,IAAI,CAAC,SAAS;AAC3B,UAAI,QAAQ,OAAO,SAAS,YAAY,UAAU,QAAQ,KAAK,SAAS,aAAa;AACnF,cAAM,YAAY;AAClB,YAAI,UAAU,WAAW,KAAK;AAC5B,iBAAO;AAAA,YACL,GAAG;AAAA,YACH,WAAW,iBAAiB,UAAU,UAAU,KAAK,UAAU,UAAU,MAAM;AAAA,UACjF;AAAA,QACF;AAAA,MACF;AACA,aAAO;AAAA,IACT,CAAC;AAAA,EACH;AAEA,SAAO;AACT;;;ACwBO,SAAS,uBAAuB,EAAE,KAAK,GAAuC;AAEnF,QAAM,mBAA2C;AAAA,IAC/C,MAAM;AAAA,IACN,SAAS,QAAQ;AAAA,EACnB;AAEA,SAAO,CAAC,gBAAgB;AAC1B;;;AC7GO,SAAS,gBACd,QACA,WACA,aACA,kBACiB;AACjB,QAAM,gBAAgB,CAAC,GAAG,MAAM;AAGhC,gBAAc,KAAK;AAAA,IACjB,MAAM;AAAA,IACN,SAAS,oBAAoB;AAAA,IAC7B,YAAY,UAAU,IAAI,CAAC,cAAc;AAAA,MACvC,IAAI,SAAS;AAAA,MACb,UAAU;AAAA,QACR,MAAM,SAAS;AAAA,QACf,WACE,OAAO,SAAS,SAAS,WAAW,SAAS,OAAO,KAAK,UAAU,SAAS,IAAI;AAAA,MACpF;AAAA,MACA,MAAM;AAAA,IACR,EAAE;AAAA,EACJ,CAAC;AAGD,aAAW,YAAY,WAAW;AAChC,UAAM,iBAAiB,YAAY,IAAI,SAAS,QAAQ;AAExD,QAAI,gBAAgB;AAClB,oBAAc,KAAK;AAAA,QACjB,MAAM;AAAA,QACN,cAAc,SAAS;AAAA,QACvB,SAAS,KAAK,UAAU,cAAc;AAAA,MACxC,CAAC;AAAA,IACH;AAAA,EACF;AAEA,SAAO;AACT;AAcO,SAAS,gCAAgC,WAAwC;AACtF,QAAM,iBAAiB,oBAAI,IAAqB;AAEhD,MAAI,CAAC,MAAM,QAAQ,SAAS,GAAG;AAC7B,WAAO;AAAA,EACT;AAGA,aAAW,WAAW,WAAW;AAE/B,QAAI,SAAS,SAAS,UAAU,MAAM,QAAQ,QAAQ,KAAK,GAAG;AAC5D,iBAAW,QAAQ,QAAQ,OAAO;AAChC,YAAI,MAAM,kBAAkB;AAC1B,gBAAM,mBAAmB,KAAK;AAC9B,cAAI,iBAAiB,QAAQ,iBAAiB,UAAU;AAEtD,2BAAe;AAAA,cACb,iBAAiB;AAAA,cACjB,iBAAiB,SAAS,WAAW,iBAAiB;AAAA,YACxD;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAGA,QAAI,SAAS,SAAS,UAAU,SAAS,gBAAgB,SAAS,SAAS;AAAA,IAI3E;AAAA,EACF;AAEA,SAAO;AACT;AAYO,SAAS,+BACd,QACsB;AACtB,QAAM,WAAW,oBAAI,IAAoB;AACzC,QAAM,UAAU,oBAAI,IAAqB;AAGzC,aAAW,WAAW,QAAQ;AAC5B,QAAI,QAAQ,SAAS,eAAe,MAAM,QAAQ,QAAQ,OAAO,GAAG;AAClE,iBAAW,QAAQ,QAAQ,SAAS;AAClC,YAAI,KAAK,SAAS,aAAa;AAC7B,mBAAS,IAAI,KAAK,YAAY,KAAK,QAAQ;AAAA,QAC7C;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAGA,aAAW,WAAW,QAAQ;AAC5B,QAAI,QAAQ,SAAS,UAAU,MAAM,QAAQ,QAAQ,OAAO,GAAG;AAC7D,iBAAW,QAAQ,QAAQ,SAAS;AAElC,YAAI,KAAK,cAAc,KAAK,WAAW,QAAW;AAChD,gBAAM,WAAW,SAAS,IAAI,KAAK,UAAU;AAC7C,cAAI,UAAU;AACZ,oBAAQ,IAAI,UAAU,KAAK,MAAM;AAAA,UACnC;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;;;AC1GA,SAAS,oBAAoB,UAA+D;AAC1F,SAAO;AAAA,IACL,YAAY,SAAS;AAAA,IACrB,UAAU,SAAS;AAAA,IACnB,MAAM,OAAO,SAAS,SAAS,WAAW,SAAS,OAAO,KAAK,UAAU,SAAS,IAAI;AAAA,IACtF,cAAc;AAAA,EAChB;AACF;AAKA,SAAS,oBAAoB,UAAuD;AAClF,SAAO;AAAA,IACL,YAAY,SAAS;AAAA,IACrB,UAAU,SAAS;AAAA,IACnB,MACE,OAAO,SAAS,UAAU,WACtB,SAAS,MAAM,QAAQ,SAAS,GAAG,IACnC,KAAK,UAAU,SAAS,KAAK;AAAA,IACnC,cAAc;AAAA,EAChB;AACF;AAKO,SAAS,qBACd,WACsB;AACtB,SAAO,UAAU,IAAI,mBAAmB;AAC1C;AAKO,SAAS,qBAAqB,WAA4D;AAC/F,SAAO,UAAU,IAAI,mBAAmB;AAC1C;AAKO,SAAS,iBAAiB,QAAgD;AAC/E,QAAM,UAA2B,CAAC;AAElC,aAAW,WAAW,QAAQ;AAC5B,YAAQ,QAAQ,MAAM;AAAA,MACpB,KAAK;AACH,gBAAQ,KAAK;AAAA,UACX,MAAM;AAAA,UACN,SAAS,QAAQ;AAAA,QACnB,CAAC;AACD;AAAA,MAEF,KAAK;AACH,cAAM,WAAW,QAAQ,QAAQ,KAAK,CAAC,SAAS,KAAK,SAAS,MAAM;AAGpE,cAAM,gBAAgB,QAAQ,QAAQ;AAAA,UACpC,CAAC,SAAS,KAAK,SAAS;AAAA,QAC1B;AAEA,gBAAQ,KAAK;AAAA,UACX,MAAM;AAAA,UACN,SAAS,UAAU,QAAQ;AAAA,UAC3B,GAAI,cAAc,SAAS,IACvB;AAAA,YACE,YAAY,cAAc,IAAI,CAAC,UAAU;AAAA,cACvC,IAAI,KAAK;AAAA,cACT,UAAU;AAAA,gBACR,MAAM,KAAK;AAAA,gBACX,WAAW,KAAK,UAAU,KAAK,IAAI;AAAA,cACrC;AAAA,cACA,MAAM;AAAA,YACR,EAAE;AAAA,UACJ,IACA,CAAC;AAAA,QACP,CAAC;AACD;AAAA,MAEF,KAAK;AACH,gBAAQ,KAAK;AAAA,UACX,MAAM;AAAA,UACN,SAAS,QAAQ,QAAQ,IAAI,CAAC,SAA4B;AACxD,oBAAQ,KAAK,MAAM;AAAA,cACjB,KAAK;AACH,uBAAO;AAAA,kBACL,MAAM;AAAA,kBACN,MAAM,KAAK;AAAA,gBACb;AAAA,cACF,KAAK;AACH,uBAAO;AAAA,kBACL,MAAM;AAAA,kBACN,WAAW;AAAA,oBACT,KAAK,KAAK,MAAM,SAAS;AAAA,kBAC3B;AAAA,gBACF;AAAA,cACF;AAEE,uBAAO;AAAA,kBACL,MAAM;AAAA,kBACN,MACE,IAAI,KAAK,IAAI,OACZ,OAAO,SAAS,YAAY,SAAS,OAClC,KAAK,UAAU,IAAI,IACnB,OAAO,IAAI;AAAA,gBACnB;AAAA,YACJ;AAAA,UACF,CAAC;AAAA,QACH,CAAC;AACD;AAAA,MAEF,KAAK;AACH,mBAAW,QAAQ,QAAQ,SAAS;AAClC,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,cAAc,KAAK;AAAA,YACnB,SAAS,KAAK,UAAU,KAAK,MAAM;AAAA,UACrC,CAAC;AAAA,QACH;AACA;AAAA,IACJ;AAAA,EACF;AAEA,SAAO;AACT;AAKO,SAAS,iBAAiB,QAAgD;AAC/E,QAAM,UAA2B,CAAC;AAElC,aAAW,WAAW,QAAQ;AAC5B,YAAQ,QAAQ,MAAM;AAAA,MACpB,KAAK;AACH,gBAAQ,KAAK;AAAA,UACX,MAAM;AAAA,UACN,SAAS,QAAQ;AAAA,QACnB,CAAC;AACD;AAAA,MAEF,KAAK;AACH,cAAM,cAAc,QAAQ,QAAQ;AAAA,UAClC,CAAC,SAA0C,KAAK,SAAS;AAAA,QAC3D;AACA,cAAM,YAAY,QAAQ,QAAQ;AAAA,UAChC,CAAC,SAA8C,KAAK,SAAS;AAAA,QAC/D;AAEA,gBAAQ,KAAK;AAAA,UACX,MAAM;AAAA,UACN,SAAS,aAAa,QAAQ;AAAA,UAC9B,GAAI,UAAU,SAAS,IACnB;AAAA,YACE,YAAY,UAAU,IAAI,CAAC,UAAU;AAAA,cACnC,IAAI,KAAK;AAAA,cACT,UAAU;AAAA,gBACR,MAAM,KAAK;AAAA,gBACX,WACE,OAAO,KAAK,UAAU,WAAW,KAAK,QAAQ,KAAK,UAAU,KAAK,KAAK;AAAA,cAC3E;AAAA,cACA,MAAM;AAAA,YACR,EAAE;AAAA,UACJ,IACA,CAAC;AAAA,QACP,CAAC;AACD;AAAA,MAEF,KAAK;AACH,gBAAQ,KAAK;AAAA,UACX,MAAM;AAAA,UACN,SAAS,QAAQ,QAAQ,IAAI,CAAC,SAAc;AAC1C,oBAAQ,KAAK,MAAM;AAAA,cACjB,KAAK;AACH,uBAAO;AAAA,kBACL,MAAM;AAAA,kBACN,MAAM,KAAK;AAAA,gBACb;AAAA,cACF,KAAK;AACH,uBAAO;AAAA,kBACL,MAAM;AAAA,kBACN,WAAW;AAAA,oBACT,KAAK,KAAK,MAAM,SAAS;AAAA,kBAC3B;AAAA,gBACF;AAAA,cACF;AAEE,uBAAO;AAAA,YACX;AAAA,UACF,CAAC;AAAA,QACH,CAAC;AACD;AAAA,MAEF,KAAK;AACH,mBAAW,QAAQ,QAAQ,SAAS;AAClC,kBAAQ,KAAK;AAAA,YACX,MAAM;AAAA,YACN,cAAc,KAAK;AAAA,YACnB,SAAS,uBAAuB,KAAK,MAAM;AAAA,UAC7C,CAAC;AAAA,QACH;AACA;AAAA,IACJ;AAAA,EACF;AAEA,SAAO;AACT;AAEA,SAAS,uBAAuB,QAAyC;AACvE,UAAQ,OAAO,MAAM;AAAA,IACnB,KAAK;AACH,aAAO,OAAO;AAAA,IAChB,KAAK;AACH,aAAO,OAAO,OAAO,UAAU,WAAW,OAAO,QAAQ,KAAK,UAAU,OAAO,KAAK;AAAA,IACtF,KAAK;AACH,aAAO,OAAO;AAAA,IAChB,KAAK;AACH,aAAO,OAAO,OAAO,UAAU,WAAW,OAAO,QAAQ,KAAK,UAAU,OAAO,KAAK;AAAA,IACtF,KAAK;AACH,aAAO,KAAK,UAAU,OAAO,KAAK;AAAA,EACtC;AACF;;;AC3QO,SAAS,kBAA0B;AACxC,SAAO,KAAK,IAAI,IAAI;AACtB;;;ACeO,IAAM,qBAAN,MAAyB;AAAA,EAAzB;AACL,wBAAiB,SAAyD,CAAC;AAAA;AAAA,EAE3E,YAAY,OAAwC;AAClD,YAAQ,MAAM,MAAM;AAAA,MAClB,KAAK;AACH,aAAK,MAAM,MAAM,UAAU,IAAI;AAAA,UAC7B,cAAc,MAAM;AAAA,UACpB,YAAY,MAAM;AAAA,UAClB,UAAU,MAAM;AAAA,UAChB,MAAM,MAAM;AAAA,QACd;AACA;AAAA,MACF,KAAK;AACH,YAAI,CAAC,KAAK,MAAM,MAAM,UAAU,GAAG;AACjC,eAAK,MAAM,MAAM,UAAU,IAAI;AAAA,YAC7B,cAAc,MAAM;AAAA,YACpB,YAAY,MAAM;AAAA,YAClB,UAAU,MAAM;AAAA,YAChB,MAAM;AAAA,UACR;AAAA,QACF;AACA,aAAK,MAAM,MAAM,UAAU,EAAE,QAAQ,MAAM;AAC3C;AAAA,IACJ;AAAA,EACF;AAAA,EAEA,IAAI,SAA4C;AAC9C,WAAO,OAAO,OAAO,KAAK,KAAK;AAAA,EACjC;AACF;AAEO,IAAM,iBAAN,MAAqB;AAAA,EAArB;AACL,wBAAQ,WAAU;AAAA;AAAA,EAElB,KAAK,OAAwC;AAC3C,QAAI,MAAM,SAAS,cAAc;AAC/B,WAAK,WAAW,MAAM;AAAA,IACxB;AAAA,EACF;AAAA,EAEA,IAAI,OAA2B;AAC7B,WAAO,KAAK,WAAW;AAAA,EACzB;AACF;AAEO,IAAM,cAAN,MAAkB;AAAA,EAQvB,cAAc;AAPd,wBAAQ;AACR,wBAAQ;AACR,wBAAQ;AACR,wBAAQ;AACR,wBAAQ;AACR,wBAAQ;AAGN,SAAK,YAAY,gBAAgB;AAAA,EACnC;AAAA,EAEA,KAAK,OAAwC;AAE3C,QAAI,KAAK,qBAAqB,QAAW;AACvC,WAAK,mBAAmB,gBAAgB,IAAI,KAAK;AAAA,IACnD;AAEA,YAAQ,MAAM,MAAM;AAAA,MAClB,KAAK;AACH,YAAI,MAAM,IAAI;AACZ,eAAK,cAAc,MAAM;AAAA,QAC3B;AACA,YAAI,MAAM,SAAS;AACjB,eAAK,mBAAmB,MAAM;AAAA,QAChC;AAEA;AAAA,MACF,KAAK;AACH,aAAK,SAAS,MAAM;AACpB,aAAK,gBAAgB,MAAM;AAC3B;AAAA,IACJ;AAAA,EACF;AAAA,EAEA,IAAI,SAAS;AACX,WAAO;AAAA,MACL,UACE,KAAK,eAAe,KAAK,mBACrB;AAAA,QACE,IAAI,KAAK;AAAA,QACT,SAAS,KAAK;AAAA,MAChB,IACA;AAAA,MACN,cAAc,KAAK;AAAA,MACnB,OAAO,KAAK;AAAA,IACd;AAAA,EACF;AAAA,EAEA,IAAI,iBAAqC;AACvC,WAAO,KAAK;AAAA,EACd;AACF;AAGO,IAAM,uBAAN,MAA2B;AAAA,EAA3B;AACL,wBAAiB,SAAiD,CAAC;AAAA;AAAA,EAEnE,YAAY,OAAwC;AAClD,QAAI,MAAM,SAAS,aAAa;AAC9B,WAAK,MAAM,MAAM,UAAU,IAAI;AAAA,IACjC;AAAA,EACF;AAAA,EAEA,IAAI,SAAoC;AACtC,WAAO,OAAO,OAAO,KAAK,KAAK;AAAA,EACjC;AACF;AAEO,IAAM,mBAAN,MAAuB;AAAA,EAAvB;AACL,wBAAQ,WAAU;AAAA;AAAA,EAElB,KAAK,OAAwC;AAE3C,YAAQ,MAAM,MAAM;AAAA,MAClB,KAAK;AACH,aAAK,UAAU;AACf;AAAA,MACF,KAAK;AACH,aAAK,WAAW,MAAM;AACtB;AAAA,MACF,KAAK;AACH;AAAA,IACJ;AAAA,EACF;AAAA,EAEA,IAAI,OAA2B;AAC7B,WAAO,KAAK,WAAW;AAAA,EACzB;AACF;AAEO,IAAM,gBAAN,MAAoB;AAAA,EAOzB,cAAc;AANd,wBAAQ;AACR,wBAAQ;AACR,wBAAQ;AACR,wBAAQ;AACR,wBAAQ;AAGN,SAAK,YAAY,gBAAgB;AAAA,EACnC;AAAA,EAEA,KAAK,OAAwC;AAE3C,QAAI,KAAK,qBAAqB,QAAW;AACvC,WAAK,mBAAmB,gBAAgB,IAAI,KAAK;AAAA,IACnD;AAEA,YAAQ,MAAM,MAAM;AAAA,MAClB,KAAK;AACH,aAAK,oBAAoB;AAAA,UACvB,IAAI,MAAM;AAAA,UACV,SAAS,MAAM;AAAA,UACf,WAAW,MAAM;AAAA,QACnB;AACA;AAAA,MACF,KAAK;AACH,aAAK,SAAS,MAAM;AACpB,aAAK,gBAAgB,MAAM;AAC3B;AAAA,IACJ;AAAA,EACF;AAAA,EAEA,IAAI,SAAS;AACX,WAAO;AAAA,MACL,UAAU,KAAK;AAAA,MACf,cAAc,KAAK;AAAA,MACnB,OAAO,KAAK;AAAA,IACd;AAAA,EACF;AAAA,EAEA,IAAI,iBAAqC;AACvC,WAAO,KAAK;AAAA,EACd;AACF;;;AN1HA,IAAM,6BAA6B,CACjC,MACA,aACG;AACH,QAAM,cAAc,WAAW,SAAS,SAAS,CAAC;AAElD,MAAI;AAEJ,MAAI,sBAAsB,aAAa;AACrC,gBAAY,aAAa,kBAAkB;AAAA,EAC7C,WAAW,qBAAqB,aAAa;AAC3C,gBAAY,aAAa,iBAAiB;AAAA,EAC5C;AAEA,MAAI,WAAW;AACb,QAAI,UAAU,GAAI,MAAK,aAAa,KAAK,MAAM,eAAe,IAAI,UAAU,EAAE;AAC9E,QAAI,UAAU,KAAM,MAAK,aAAa,KAAK,MAAM,eAAe,MAAM,UAAU,IAAI;AACpF,QAAI,UAAU,KAAM,MAAK,aAAa,KAAK,MAAM,eAAe,MAAM,UAAU,IAAI;AACpF,QAAI,UAAU,QAAS,MAAK,aAAa,KAAK,MAAM,eAAe,SAAS,UAAU,OAAO;AAAA,EAC/F;AACF;AAKO,SAAS,sBAAqF;AACnG,SAAO;AAAA,IACL,cAAc,OAAO,EAAE,YAAY,QAAQ,MAAM,MAAM;AACrD,aAAO,iBAAiB,MAAM,SAAS,OAAO,MAAM,kBAAkB;AACpE,cAAMC,WAA8B;AAAA,UAClC,GAAG;AAAA,UACH,gBAAgB,CAAC;AAAA,UACjB,SAAS;AAAA,QACX;AAEA,mCAA2B,MAAM,OAAO,MAAM;AAG9C,2BAAmB,IAAI;AACvB,+BAAuB,MAAM,QAAQA,UAAS,KAAK;AAEnD,cAAM,MAAM,MAAM,WAAW;AAG7B,QAAAA,SAAQ,UAAU,IAAI;AAGtB,cAAM,wBAAwB,MAAM,KAAKA,UAAS,KAAK;AAEvD,eAAO;AAAA,MACT,CAAC;AAAA,IACH;AAAA,IAEA,YAAY,OAAO,EAAE,UAAU,QAAQ,MAAM,MAAM;AACjD,aAAO,iBAAiB,MAAM,SAAS,OAAO,MAAM,kBAAkB;AACpE,cAAMA,WAA8B;AAAA,UAClC,GAAG;AAAA,UACH,gBAAgB,CAAC;AAAA,UACjB,SAAS;AAAA,QACX;AAEA,mCAA2B,MAAM,OAAO,MAAM;AAG9C,2BAAmB,IAAI;AACvB,+BAAuB,MAAM,QAAQA,UAAS,KAAK;AAEnD,cAAM,EAAE,QAAQ,GAAG,KAAK,IAAI,MAAM,SAAS;AAG3C,cAAM,YAAY,sBAAsB,MAAM,QAAQ,MAAM,OAAO,SAAS;AAE5E,cAAM,QAAQ,IAAI,YAAY;AAC9B,cAAM,iBAAiB,IAAI,mBAAmB;AAC9C,cAAM,iBAAiB,IAAI,eAAe;AAE1C,eAAO;AAAA,UACL,GAAG;AAAA,UACH,QAAQ,OAAO;AAAA,YACb,IAAI,gBAAgB;AAAA,cAClB,UAAU,OAAkC,YAAY;AACtD,oBAAI;AACF,wBAAM,KAAK,KAAK;AAChB,iCAAe,YAAY,KAAK;AAChC,iCAAe,KAAK,KAAK;AAEzB,6BAAW,QAAQ,KAAK;AAAA,gBAC1B,SAAS,KAAK;AACZ,oCAAkB,WAAW,GAAG;AAChC,4BAAU,IAAI;AACd,6BAAW,MAAM,GAAG;AAAA,gBACtB;AAAA,cACF;AAAA,cACA,MAAM,MAAM,YAAY;AACtB,oBAAI;AACF,wBAAM;AAAA,oBACJ;AAAA,oBACA;AAAA,sBACE,GAAG;AAAA,sBACH,GAAG,MAAM;AAAA,sBACT,WACE,eAAe,OAAO,SAAS,IAAI,eAAe,SAAS;AAAA,sBAC7D,MAAM,eAAe;AAAA,oBACvB;AAAA,oBACAA;AAAA,oBACA;AAAA,kBACF;AAEA,4BAAU,IAAI;AACd,6BAAW,UAAU;AAAA,gBACvB,SAAS,KAAK;AACZ,oCAAkB,WAAW,GAAG;AAChC,4BAAU,IAAI;AACd,6BAAW,MAAM,GAAG;AAAA,gBACtB;AAAA,cACF;AAAA,YACF,CAAC;AAAA,UACH;AAAA,QACF;AAAA,MACF,CAAC;AAAA,IACH;AAAA,EACF;AACF;AAOO,SAAS,kBAAkB,QAAsD;AACtF,MAAI,OAAO,MAAM,yBAAyB,MAAM;AAC9C,WAAO,oBAAoB;AAAA,EAC7B,WAAW,OAAO,MAAM,yBAAyB,MAAM;AACrD,WAAO,oBAAoB;AAAA,EAC7B,OAAO;AACL,YAAQ;AAAA;AAAA,MAEN,4CAA4C,KAAK,UAAU,OAAO,MAAM,oBAAoB,CAAC;AAAA,IAC/F;AACA,WAAO,CAAC;AAAA,EACV;AACF;AAKO,SAAS,sBAAqF;AACnG,SAAO;AAAA,IACL,cAAc,OAAO,EAAE,YAAY,QAAQ,MAAM,MAAM;AACrD,aAAO,iBAAiB,MAAM,SAAS,OAAO,MAAM,kBAAkB;AACpE,cAAMA,WAA8B;AAAA,UAClC,GAAG;AAAA,UACH,gBAAgB,CAAC;AAAA,UACjB,kBAAkB,CAAC;AAAA,QACrB;AAEA,mCAA2B,MAAM,OAAO,MAAM;AAG9C,2BAAmB,IAAI;AACvB,+BAAuB,MAAM,QAAQA,UAAS,KAAK;AAEnD,cAAM,MAAM,MAAM,WAAW;AAG7B,cAAM,wBAAwB,MAAM,KAAKA,UAAS,KAAK;AAEvD,eAAO;AAAA,MACT,CAAC;AAAA,IACH;AAAA,IAEA,YAAY,OAAO,EAAE,UAAU,QAAQ,MAAM,MAAM;AACjD,aAAO,iBAAiB,MAAM,SAAS,OAAO,MAAM,kBAAkB;AACpE,cAAMA,WAA8B;AAAA,UAClC,GAAG;AAAA,UACH,gBAAgB,CAAC;AAAA,UACjB,kBAAkB,CAAC;AAAA,QACrB;AAEA,mCAA2B,MAAM,OAAO,MAAM;AAG9C,2BAAmB,IAAI;AACvB,+BAAuB,MAAM,QAAQA,UAAS,KAAK;AAEnD,cAAM,MAAM,MAAM,SAAS;AAG3B,cAAM,YAAY,sBAAsB,MAAM,QAAQ,MAAM,OAAO,SAAS;AAE5E,cAAM,QAAQ,IAAI,cAAc;AAChC,cAAM,iBAAiB,IAAI,qBAAqB;AAChD,cAAM,iBAAiB,IAAI,iBAAiB;AAE5C,eAAO;AAAA,UACL,GAAG;AAAA,UACH,QAAQ,IAAI,OAAO;AAAA,YACjB,IAAI,gBAAgB;AAAA,cAClB,UAAU,OAAkC,YAAY;AACtD,oBAAI;AACF,wBAAM,KAAK,KAAK;AAChB,iCAAe,YAAY,KAAK;AAChC,iCAAe,KAAK,KAAK;AAEzB,6BAAW,QAAQ,KAAK;AAAA,gBAC1B,SAAS,KAAK;AACZ,oCAAkB,WAAW,GAAG;AAChC,4BAAU,IAAI;AACd,6BAAW,MAAM,GAAG;AAAA,gBACtB;AAAA,cACF;AAAA,cACA,MAAM,MAAM,YAAY;AACtB,oBAAI;AACF,wBAAM,eAAe;AAAA,oBACnB,GAAG,MAAM;AAAA,oBACT,SAAS;AAAA,sBACP,GAAI,eAAe,OACf,CAAC,EAAE,MAAM,QAAiB,MAAM,eAAe,KAAK,CAAC,IACrD,CAAC;AAAA,sBACL,GAAG,eAAe;AAAA,oBACpB;AAAA,kBACF;AAEA,wBAAM,wBAAwB,MAAM,cAAcA,UAAS,KAAK;AAEhE,4BAAU,IAAI;AACd,6BAAW,UAAU;AAAA,gBACvB,SAAS,KAAK;AACZ,oCAAkB,WAAW,GAAG;AAChC,4BAAU,IAAI;AACd,6BAAW,MAAM,GAAG;AAAA,gBACtB;AAAA,cACF;AAAA,YACF,CAAC;AAAA,UACH;AAAA,QACF;AAAA,MACF,CAAC;AAAA,IACH;AAAA,EACF;AACF;AAGA,SAAS,uBACP,MACA,SACAA,UACA,OACA;AACA,QAAM,kBAAkB,mBAAmB;AAE3C,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,IAAI;AAGJ,QAAM,kBAAkB,iBAAiB,MAAM;AAC/C,EAAAA,SAAQ,iBAAiB;AAEzB;AAAA,IACE;AAAA,IACA,KAAK,MAAM,MAAM;AAAA,IACjB,KAAK,UAAU,0BAA0B,eAAe,CAAC;AAAA,IACzD,gBAAgB;AAAA,EAClB;AAEA,oBAAkB,MAAM,MAAM,UAAU,MAAM,OAAO;AAErD,QAAM,aAAa,sBAAsB,EAAE,gBAAgB,KAAK,CAAC;AACjE,MAAI,YAAY;AACd,SAAK,aAAa,KAAK,MAAM,OAAO,MAAM,UAAU;AAAA,EACtD;AAEA,gCAA8B,MAAM;AAAA,IAClC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,CAAC;AACH;AAEA,eAAe,wBACb,MACA,QACAA,UACA,QACA;AACA,QAAM,kBAAkB,mBAAmB;AAG3C,MAAI,OAAO,aAAa,OAAO,UAAU,SAAS,GAAG;AACnD,UAAM,iBAAiBA,SAAQ,kBAAkB,CAAC;AAGlD,UAAM,sBAAsB,qBAAqB,OAAO,SAAS;AAGjE,UAAM,iBAAiBA,SAAQ,SAAS,YACpC,gCAAgCA,SAAQ,QAAQ,SAAkB,IAClE,oBAAI,IAAI;AAEZ,UAAM,gBAAgB;AAAA,MACpB;AAAA,MACA;AAAA,MACA;AAAA,MACA,OAAO;AAAA,IACT;AAEA;AAAA,MACE;AAAA,MACA,KAAK,MAAM,MAAM;AAAA,MACjB,KAAK,UAAU,0BAA0B,aAAa,CAAC;AAAA,MACvD,gBAAgB;AAAA,IAClB;AAAA,EACF;AAGA,MAAI,OAAO,MAAM;AACf,UAAM,aAAa,uBAAuB;AAAA,MACxC,MAAM,OAAO;AAAA,IACf,CAAC;AACD;AAAA,MACE;AAAA,MACA,KAAK,MAAM,OAAO;AAAA,MAClB,KAAK,UAAU,UAAU;AAAA,MACzB,gBAAgB;AAAA,IAClB;AAAA,EACF;AAEA,MAAI,OAAO,UAAU,IAAI;AACvB,SAAK,aAAa,KAAK,MAAM,SAAS,IAAI,OAAO,SAAS,EAAE;AAAA,EAC9D;AACA,MAAI,OAAO,UAAU,SAAS;AAC5B,SAAK,aAAa,KAAK,MAAM,SAAS,OAAO,OAAO,SAAS,OAAO;AAAA,EACtE;AAEA,MAAI,OAAO,OAAO,cAAc;AAC9B,QAAI,OAAO,MAAM,OAAO,MAAM,YAAY,GAAG;AAC3C,cAAQ;AAAA,QACN;AAAA,QACA,OAAO,MAAM;AAAA,MACf;AAAA,IACF,OAAO;AACL,WAAK,aAAa,KAAK,MAAM,MAAM,aAAa,OAAO,MAAM,YAAY;AAAA,IAC3E;AAAA,EACF;AAEA,MAAI,OAAO,OAAO,kBAAkB;AAClC,QAAI,OAAO,MAAM,OAAO,MAAM,gBAAgB,GAAG;AAC/C,cAAQ;AAAA,QACN;AAAA,QACA,OAAO,MAAM;AAAA,MACf;AAAA,IACF,OAAO;AACL,WAAK,aAAa,KAAK,MAAM,MAAM,cAAc,OAAO,MAAM,gBAAgB;AAAA,IAChF;AAAA,EACF;AAEA,MAAI,OAAO,cAAc;AACvB,SAAK,aAAa,KAAK,MAAM,SAAS,eAAe,KAAK,UAAU,CAAC,OAAO,YAAY,CAAC,CAAC;AAAA,EAC5F;AACF;AAGA,SAAS,uBACP,MACA,SACAA,UACA,OACA;AACA,QAAM,kBAAkB,mBAAmB;AAE3C,oBAAkB,MAAM,MAAM,UAAU,MAAM,OAAO;AAErD,QAAM,aAAa,sBAAsB,OAAO;AAChD,MAAI,YAAY;AACd,SAAK,aAAa,KAAK,MAAM,OAAO,MAAM,UAAU;AAAA,EACtD;AAEA,gCAA8B,MAAM;AAAA,IAClC,WAAW,QAAQ;AAAA,IACnB,kBAAkB,QAAQ;AAAA,IAC1B,iBAAiB,QAAQ;AAAA,IACzB,aAAa,QAAQ;AAAA,IACrB,MAAM,QAAQ;AAAA,IACd,MAAM,QAAQ;AAAA,IACd,MAAM,QAAQ;AAAA,IACd,eAAe,QAAQ;AAAA,EACzB,CAAC;AAED,QAAM,kBAAkB,iBAAiB,QAAQ,MAAM;AAGvD,EAAAA,SAAQ,mBAAmB,QAAQ;AACnC,EAAAA,SAAQ,iBAAiB;AAEzB;AAAA,IACE;AAAA,IACA,KAAK,MAAM,MAAM;AAAA,IACjB,KAAK,UAAU,0BAA0B,eAAe,CAAC;AAAA,IACzD,gBAAgB;AAAA,EAClB;AACF;AAEA,eAAe,wBACb,MACA,QAMAA,UACA,QACA;AACA,QAAM,kBAAkB,mBAAmB;AAG3C,QAAM,YAAY,OAAO,SAAS;AAAA,IAChC,CAAC,MAAM,EAAE,SAAS;AAAA,EACpB;AAGA,QAAM,aAAc,KAAa,aAAa,KAAK,MAAM,SAAS,aAAa,MAAM;AAErF,MAAI,CAAC,YAAY;AACf,QAAI,OAAO,UAAU,IAAI;AACvB,WAAK,aAAa,KAAK,MAAM,SAAS,IAAI,OAAO,SAAS,EAAE;AAAA,IAC9D;AACA,QAAI,OAAO,UAAU,SAAS;AAC5B,WAAK,aAAa,KAAK,MAAM,SAAS,OAAO,OAAO,SAAS,OAAO;AAAA,IACtE;AAEA,QAAI,OAAO,OAAO,gBAAgB,QAAW;AAC3C,WAAK,aAAa,KAAK,MAAM,MAAM,aAAa,OAAO,MAAM,WAAW;AAAA,IAC1E;AACA,QAAI,OAAO,OAAO,iBAAiB,QAAW;AAC5C,WAAK,aAAa,KAAK,MAAM,MAAM,cAAc,OAAO,MAAM,YAAY;AAAA,IAC5E;AAAA,EACF;AAGA,MAAI,aAAa,UAAU,SAAS,GAAG;AACrC,UAAM,iBAAiBA,SAAQ,kBAAkB,CAAC;AAElD,UAAM,sBAAsB,qBAAqB,SAAS;AAG1D,UAAM,iBAAiB,+BAA+BA,SAAQ,oBAAoB,CAAC,CAAC;AAGpF,UAAM,cAAc,OAAO,SAAS,KAAK,CAAC,MAAM,EAAE,SAAS,MAAM;AACjE,UAAM,gBAAgB,aAAa,SAAS,SAAS,YAAY,OAAO;AAGxE,UAAM,gBAAgB;AAAA,MACpB;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAGA;AAAA,MACE;AAAA,MACA,KAAK,MAAM,MAAM;AAAA,MACjB,KAAK,UAAU,0BAA0B,aAAa,CAAC;AAAA,MACvD,gBAAgB;AAAA,IAClB;AAAA,EACF;AAGA,MAAI,OAAO,WAAW,OAAO,QAAQ,SAAS,GAAG;AAC/C,UAAM,iCAAiC,MAAM,OAAO,OAAO;AAAA,EAC7D,WAAW,OAAO,cAAc;AAE9B,UAAM,aAAa,uBAAuB;AAAA,MACxC,MAAM;AAAA,IACR,CAAC;AACD;AAAA,MACE;AAAA,MACA,KAAK,MAAM,OAAO;AAAA,MAClB,KAAK,UAAU,UAAU;AAAA,MACzB,gBAAgB;AAAA,IAClB;AAAA,EACF;AAGA,MAAI,OAAO,gBAAgB,CAAC,YAAY;AACtC,SAAK,aAAa,KAAK,MAAM,SAAS,eAAe,KAAK,UAAU,CAAC,OAAO,YAAY,CAAC,CAAC;AAAA,EAC5F;AACF;AAEA,eAAe,iCACb,YACA,SACe;AACf,QAAM,kBAAkB,mBAAmB;AAG3C,QAAM,cAAc,QAAQ,KAAK,CAAC,MAAM,EAAE,SAAS,MAAM;AACzD,QAAM,gBAAgB,aAAa,SAAS,SAAS,YAAY,OAAO;AACxE,QAAM,YAAY,QAAQ,OAAO,CAAC,MAAM,EAAE,SAAS,WAAW;AAG9D,MAAI,UAAU,WAAW,GAAG;AAE1B,UAAM,aAAa;AAAA,MACjB;AAAA,QACE,MAAM;AAAA,QACN,SAAS;AAAA,UACP,QAAQ,WAAW,KAAK,gBAAgB,gBAAgB;AAAA,QAC1D;AAAA,MACF;AAAA,IACF;AAGA;AAAA,MACE;AAAA,MACA,KAAK,MAAM,OAAO;AAAA,MAClB,KAAK,UAAU,UAAU;AAAA,MACzB,gBAAgB;AAAA,IAClB;AAAA,EACF;AACF;;;AOjmBO,SAAS,kBAAkB,OAA0C;AAC1E,SACE,SAAS,QACT,OAAO,UAAU,YACjB,0BAA0B,SAC1B,cAAc,SACd,aAAa,SACZ,MAAc,yBAAyB,QACxC,OAAQ,MAAc,aAAa,YACnC,OAAQ,MAAc,YAAY;AAEtC;AA0BO,IAAM,8BAAN,MAAkC;AAAA,EACvC,YAAY,OAAwB;AAClC,UAAM,aAAa,oBAAoB;AAGvC,WAAO;AAAA,MACL,sBAAsB,MAAM;AAAA,MAC5B,UAAU,MAAM;AAAA,MAChB,SAAS,MAAM;AAAA,MACf,6BAA6B,MAAM;AAAA,MACnC,mBAAmB,MAAM;AAAA,MACzB,2BAA2B,MAAM;AAAA,MACjC,aAAa,MAAM,aAAa,KAAK,KAAK;AAAA,MAE1C,YAAY,OAAO,WAAuC;AACxD,eAAO,WAAW,aAAc;AAAA,UAC9B,YAAY,MAAM,MAAM,WAAW,MAAM;AAAA,UACzC,UAAU,MAAM,MAAM,SAAS,MAAM;AAAA,UACrC;AAAA,UACA;AAAA,QACF,CAAC;AAAA,MACH;AAAA,MAEA,UAAU,OAAO,WAAuC;AACtD,eAAO,WAAW,WAAY;AAAA,UAC5B,YAAY,MAAM,MAAM,WAAW,MAAM;AAAA,UACzC,UAAU,MAAM,MAAM,SAAS,MAAM;AAAA,UACrC;AAAA,UACA;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF;AAAA,EACF;AACF;;;ACtEO,SAAS,kBAAkB,OAAsC;AACtE,SACE,OAAO,yBAAyB,QAChC,OAAO,OAAO,aAAa,YAC3B,OAAO,OAAO,YAAY;AAE9B;AA0BO,IAAM,8BAAN,MAAkC;AAAA,EACvC,YAAY,OAAwB;AAClC,UAAM,aAAa,oBAAoB;AAGvC,WAAO;AAAA,MACL,sBAAsB,MAAM;AAAA,MAC5B,UAAU,MAAM;AAAA,MAChB,SAAS,MAAM;AAAA,MACf,eAAe,MAAM;AAAA,MAErB,YAAY,OAAO,WAAuC;AACxD,eAAO,WAAW,aAAc;AAAA,UAC9B,YAAY,MAAM,MAAM,WAAW,MAAM;AAAA,UACzC,UAAU,MAAM,MAAM,SAAS,MAAM;AAAA,UACrC;AAAA,UACA;AAAA,QACF,CAAC;AAAA,MACH;AAAA,MAEA,UAAU,OAAO,WAAuC;AACtD,eAAO,WAAW,WAAY;AAAA,UAC5B,YAAY,MAAM,MAAM,WAAW,MAAM;AAAA,UACzC,UAAU,MAAM,MAAM,SAAS,MAAM;AAAA,UACrC;AAAA,UACA;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF;AAAA,EACF;AACF;;;ACnDO,SAAS,eAA4D,OAAa;AACvF,MAAI,kBAAkB,KAAK,GAAG;AAC5B,WAAO,IAAI,4BAA4B,KAAK;AAAA,EAC9C,WAAW,kBAAkB,KAAK,GAAG;AACnC,WAAO,IAAI,4BAA4B,KAAK;AAAA,EAC9C,OAAO;AACL,YAAQ,KAAK,yCAAyC;AACtD,WAAO;AAAA,EACT;AACF;","names":["context","propagation","trace","SpanStatusCode","trace","context","propagation","SpanStatusCode","SpanStatusCode","trace","propagation","context","trace","context","propagation","SpanStatusCode","context"]}